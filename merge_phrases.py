#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‹±ç†Ÿèªãƒ‡ãƒ¼ã‚¿ã‚’æ—¢å­˜ã®è‹±å˜èªCSVã«è¿½åŠ çµ±åˆã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ä½¿ç”¨æ–¹æ³•:
  python3 merge_phrases.py <ç†ŸèªCSVãƒ•ã‚¡ã‚¤ãƒ«>
  
ä¾‹:
  python3 merge_phrases.py public/data/sample-phrases-50.csv
"""

import csv
import sys
import os
from collections import Counter

def validate_csv_format(filepath):
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’æ¤œè¨¼"""
    required_columns = ['èªå¥', 'èª­ã¿', 'æ„å‘³', 'èªæºç­‰è§£èª¬', 'é–¢é€£èª', 'é–¢é€£åˆ†é‡', 'é›£æ˜“åº¦']
    
    with open(filepath, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        fieldnames = reader.fieldnames
        
        if not fieldnames:
            return False, "ãƒ˜ãƒƒãƒ€ãƒ¼è¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
        
        missing = set(required_columns) - set(fieldnames)
        if missing:
            return False, f"å¿…é ˆåˆ—ãŒä¸è¶³: {', '.join(missing)}"
        
        return True, "OK"

def load_csv(filepath):
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    rows = []
    with open(filepath, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            # None ã‚­ãƒ¼ã‚’å‰Šé™¤
            if None in row:
                del row[None]
            rows.append(row)
    return rows

def check_duplicates(existing_words, new_phrases):
    """é‡è¤‡ã‚’ãƒã‚§ãƒƒã‚¯"""
    existing_set = set(row['èªå¥'].lower().strip() for row in existing_words)
    duplicates = []
    
    for phrase in new_phrases:
        word = phrase['èªå¥'].lower().strip()
        if word in existing_set:
            duplicates.append(phrase['èªå¥'])
    
    return duplicates

def merge_and_save(words_file, phrases_file, output_file):
    """å˜èªã¨ç†Ÿèªã‚’ãƒãƒ¼ã‚¸ã—ã¦ä¿å­˜"""
    # æ¤œè¨¼
    print(f"ğŸ“‹ æ¤œè¨¼ä¸­...")
    valid, msg = validate_csv_format(words_file)
    if not valid:
        print(f"âŒ å˜èªãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼: {msg}")
        return False
    
    valid, msg = validate_csv_format(phrases_file)
    if not valid:
        print(f"âŒ ç†Ÿèªãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼: {msg}")
        return False
    
    # èª­ã¿è¾¼ã¿
    print(f"ğŸ“– èª­ã¿è¾¼ã¿ä¸­...")
    words = load_csv(words_file)
    phrases = load_csv(phrases_file)
    
    print(f"  å˜èª: {len(words)}ä»¶")
    print(f"  ç†Ÿèª: {len(phrases)}ä»¶")
    
    # é‡è¤‡ãƒã‚§ãƒƒã‚¯
    print(f"ğŸ” é‡è¤‡ãƒã‚§ãƒƒã‚¯ä¸­...")
    duplicates = check_duplicates(words, phrases)
    if duplicates:
        print(f"âš ï¸  è­¦å‘Š: {len(duplicates)}ä»¶ã®é‡è¤‡ã‚’æ¤œå‡º")
        for dup in duplicates[:5]:  # æœ€åˆã®5ä»¶ã®ã¿è¡¨ç¤º
            print(f"    - {dup}")
        if len(duplicates) > 5:
            print(f"    ... ä»– {len(duplicates) - 5}ä»¶")
        
        response = input("\nç¶šè¡Œã—ã¾ã™ã‹ï¼Ÿ (y/n): ")
        if response.lower() != 'y':
            print("âŒ ä¸­æ­¢ã—ã¾ã—ãŸ")
            return False
    
    # ãƒãƒ¼ã‚¸
    print(f"\nğŸ”— ãƒãƒ¼ã‚¸ä¸­...")
    merged = words + phrases
    
    # ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ†å¸ƒã‚’ç¢ºèª
    category_counts = Counter(row['é–¢é€£åˆ†é‡'] for row in merged)
    difficulty_counts = Counter(row['é›£æ˜“åº¦'] for row in merged)
    
    # ä¿å­˜
    print(f"ğŸ’¾ ä¿å­˜ä¸­: {output_file}")
    fieldnames = ['èªå¥', 'èª­ã¿', 'æ„å‘³', 'èªæºç­‰è§£èª¬', 'é–¢é€£èª', 'é–¢é€£åˆ†é‡', 'é›£æ˜“åº¦']
    
    with open(output_file, 'w', encoding='utf-8', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(merged)
    
    # ãƒ¬ãƒãƒ¼ãƒˆ
    print(f"\nâœ… ãƒãƒ¼ã‚¸å®Œäº†")
    print(f"\nã€çµ±è¨ˆæƒ…å ±ã€‘")
    print(f"  ç·é …ç›®æ•°: {len(merged)}ä»¶")
    print(f"    - å˜èª: {len(words)}ä»¶")
    print(f"    - ç†Ÿèª: {len(phrases)}ä»¶")
    
    print(f"\nã€ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥åˆ†å¸ƒã€‘")
    for cat, count in sorted(category_counts.items(), key=lambda x: x[1], reverse=True):
        percentage = count / len(merged) * 100
        print(f"  {cat}: {count}ä»¶ ({percentage:.1f}%)")
    
    print(f"\nã€é›£æ˜“åº¦åˆ¥åˆ†å¸ƒã€‘")
    for diff in ['åˆç´š', 'ä¸­ç´š', 'ä¸Šç´š']:
        count = difficulty_counts.get(diff, 0)
        percentage = count / len(merged) * 100
        print(f"  {diff}: {count}ä»¶ ({percentage:.1f}%)")
    
    return True

def main():
    if len(sys.argv) != 2:
        print("ä½¿ç”¨æ–¹æ³•: python3 merge_phrases.py <ç†ŸèªCSVãƒ•ã‚¡ã‚¤ãƒ«>")
        print("ä¾‹: python3 merge_phrases.py public/data/sample-phrases-50.csv")
        sys.exit(1)
    
    phrases_file = sys.argv[1]
    words_file = 'public/data/junior-high-entrance-words.csv'
    output_file = 'public/data/junior-high-entrance-words-with-phrases.csv'
    
    # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ãƒã‚§ãƒƒã‚¯
    if not os.path.exists(words_file):
        print(f"âŒ å˜èªãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {words_file}")
        sys.exit(1)
    
    if not os.path.exists(phrases_file):
        print(f"âŒ ç†Ÿèªãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {phrases_file}")
        sys.exit(1)
    
    print("=" * 60)
    print("  è‹±ç†Ÿèªçµ±åˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    print("=" * 60)
    print(f"\nå˜èªãƒ•ã‚¡ã‚¤ãƒ«: {words_file}")
    print(f"ç†Ÿèªãƒ•ã‚¡ã‚¤ãƒ«: {phrases_file}")
    print(f"å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {output_file}\n")
    
    success = merge_and_save(words_file, phrases_file, output_file)
    
    if success:
        print(f"\nâœ¨ æˆåŠŸï¼çµ±åˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„: {output_file}")
        print(f"\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print(f"  1. {output_file} ã®å†…å®¹ã‚’ç¢ºèª")
        print(f"  2. å•é¡Œãªã‘ã‚Œã°ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§æœ¬ç•ªé©ç”¨:")
        print(f"     mv {output_file} {words_file}")
    else:
        print(f"\nâŒ ãƒãƒ¼ã‚¸ã«å¤±æ•—ã—ã¾ã—ãŸ")
        sys.exit(1)

if __name__ == '__main__':
    main()
