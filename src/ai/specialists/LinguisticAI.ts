/**
 * ğŸ“š LinguisticAI - è¨€èªå­¦çš„AIï¼ˆPhase 4.5å¼·åŒ–ç‰ˆ + MLçµ±åˆï¼‰
 *
 * è²¬ä»»:
 * - èªå¥ã®å›ºæœ‰é›£æ˜“åº¦è©•ä¾¡
 * - éŸ³éŸ»çš„é¡ä¼¼æ€§ã®åˆ†æ
 * - æ„å‘³çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
 * - æ–‡æ³•è¤‡é›‘åº¦ã®åˆ¤å®š
 *
 * Phase 4.5 MLçµ±åˆ:
 * - TensorFlow.jsã«ã‚ˆã‚‹è¨€èªçš„é›£æ˜“åº¦äºˆæ¸¬
 * - ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰AIï¼ˆãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ + MLï¼‰
 */

import type { LinguisticSignal, AIAnalysisInput, StorageWordProgress } from '../types';
import { MLEnhancedSpecialistAI } from '../ml/MLEnhancedSpecialistAI';

export class LinguisticAI extends MLEnhancedSpecialistAI<LinguisticSignal> {
  readonly id = 'linguistic';
  readonly name = 'Linguistic AI';
  readonly icon = 'ğŸ“š';

  /**
   * Positionææ¡ˆï¼ˆçµ±åˆãƒ¬ã‚¤ãƒ¤ãƒ¼ç”¨ï¼‰
   *
   * è¨€èªå­¦AIã®ç«‹å ´: å˜èªã®è¨€èªå­¦çš„é›£æ˜“åº¦ã‹ã‚‰Positionã‚’ææ¡ˆ
   * - é•·ã„å˜èª â†’ Positioné«˜ï¼ˆè¦šãˆã«ãã„ï¼‰
   * - ä¸è¦å‰‡ãªç¶´ã‚Š â†’ Positioné«˜
   * - æ­£ç­”ç‡ãŒä½ã„ â†’ Positioné«˜ï¼ˆå®Ÿè¨¼æ¸ˆã¿ã®é›£æ˜“åº¦ï¼‰
   */
  proposePosition(progress: StorageWordProgress, accuracy: number): number {
    const word = progress.word || '';

    // === è¨€èªå­¦çš„é›£æ˜“åº¦ ===
    // å˜èªã®é•·ã•
    const lengthFactor = Math.min(word.length * 2, 20); // æœ€å¤§+20ç‚¹

    // ä¸è¦å‰‡ãªç¶´ã‚Šï¼ˆé€£ç¶šã™ã‚‹å­éŸ³ã€æ¯éŸ³ãªã©ï¼‰
    const irregularityFactor = this.calculateIrregularity(word);

    // === å®Ÿè¨¼æ¸ˆã¿é›£æ˜“åº¦ ===
    // æ­£ç­”ç‡ãŒä½ã„ = å®Ÿéš›ã«é›£ã—ã„
    const empiricalDifficulty = (1 - accuracy) * 30; // æœ€å¤§+30ç‚¹

    // === åŸºæº–Position ===
    const basePosition = 40; // ã‚„ã‚„ä½ã‚ï¼ˆè¨€èªå­¦çš„è¦å› ã¯è£œåŠ©çš„ï¼‰

    // === æœ€çµ‚ææ¡ˆ ===
    const proposedPosition = basePosition + lengthFactor + irregularityFactor + empiricalDifficulty;

    return Math.max(0, Math.min(100, proposedPosition));
  }

  private calculateIrregularity(word: string): number {
    // ç°¡æ˜“çš„ãªä¸è¦å‰‡æ€§è©•ä¾¡
    const hasDoubleConsonants = /([bcdfghjklmnpqrstvwxyz])\1/.test(word);
    const hasUnusualCombinations = /([qx]|[^aeiou]{4})/.test(word);

    return (hasDoubleConsonants ? 5 : 0) + (hasUnusualCombinations ? 10 : 0);
  }

  protected analyzeByRules(input: AIAnalysisInput): LinguisticSignal {
    const { word, allProgress } = input;

    const inherentDifficulty = this.calculateInherentDifficulty(word);
    const phoneticSimilarity = this.findPhoneticallySimilarWords(word, allProgress);
    const semanticCluster = this.findSemanticCluster(word, allProgress);
    const grammarComplexity = this.assessGrammarComplexity(word);

    return {
      aiId: 'linguistic',
      confidence: 0.8, // è¨€èªå­¦çš„åˆ†æã¯æ¯”è¼ƒçš„å®¢è¦³çš„ãªã®ã§é«˜ä¿¡é ¼åº¦
      timestamp: Date.now(),
      inherentDifficulty,
      phoneticSimilarity,
      semanticCluster,
      grammarComplexity,
    };
  }

  /**
   * å›ºæœ‰é›£æ˜“åº¦ã®è¨ˆç®—
   */
  private calculateInherentDifficulty(word: string): number {
    let difficulty = 0;

    // èªé•·ã«ã‚ˆã‚‹é›£æ˜“åº¦
    if (word.length > 12) difficulty += 0.3;
    else if (word.length > 8) difficulty += 0.2;
    else if (word.length > 5) difficulty += 0.1;

    // éŸ³ç¯€æ•°ã®æ¨å®šï¼ˆæ¯éŸ³ã®æ•°ã§ç°¡æ˜“åˆ¤å®šï¼‰
    const vowels = word.match(/[aeiou]/gi);
    const syllableCount = vowels ? vowels.length : 1;

    if (syllableCount > 4) difficulty += 0.2;
    else if (syllableCount > 3) difficulty += 0.1;

    // å­éŸ³ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®å­˜åœ¨
    if (/[bcdfghjklmnpqrstvwxyz]{3,}/i.test(word)) {
      difficulty += 0.2;
    }

    // ä¸è¦å‰‡ãªã‚¹ãƒšãƒªãƒ³ã‚°
    if (/gh|ph|th|ough|augh/i.test(word)) {
      difficulty += 0.1;
    }

    return Math.min(difficulty, 1);
  }

  /**
   * éŸ³éŸ»çš„ã«é¡ä¼¼ã—ãŸèªå¥ã®æ¤œç´¢
   */
  private findPhoneticallySimilarWords(
    word: string,
    allProgress: Record<string, WordProgress>
  ): string[] {
    const similarWords: string[] = [];

    // ç°¡æ˜“å®Ÿè£…: Levenshteinè·é›¢ã‚„ã‚µã‚¦ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½¿ã†ã¹ã
    // ã“ã“ã§ã¯å…ˆé ­ãƒ»æœ«å°¾ã®é¡ä¼¼æ€§ã§åˆ¤å®š

    Object.keys(allProgress).forEach((w) => {
      if (w === word) return;

      // å…ˆé ­3æ–‡å­—ã¾ãŸã¯æœ«å°¾3æ–‡å­—ãŒä¸€è‡´
      if (
        w.substring(0, 3) === word.substring(0, 3) ||
        w.substring(w.length - 3) === word.substring(word.length - 3)
      ) {
        similarWords.push(w);
      }
    });

    return similarWords.slice(0, 5); // æœ€å¤§5èª
  }

  /**
   * æ„å‘³çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®æ¤œç´¢
   */
  private findSemanticCluster(word: string, allProgress: Record<string, WordProgress>): string[] {
    // å®Ÿéš›ã«ã¯èªç¾©ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼ˆWordNetç­‰ï¼‰ã‚’ä½¿ç”¨ã™ã¹ã
    // ã“ã“ã§ã¯èªæ ¹ã®å…±é€šæ€§ã§ç°¡æ˜“åˆ¤å®š

    const cluster: string[] = [];
    const wordRoot = this.extractWordRoot(word);

    Object.keys(allProgress).forEach((w) => {
      if (w === word) return;

      const wRoot = this.extractWordRoot(w);
      if (wordRoot && wRoot && wordRoot === wRoot) {
        cluster.push(w);
      }
    });

    return cluster.slice(0, 5);
  }

  /**
   * èªæ ¹ã®æŠ½å‡ºï¼ˆç°¡æ˜“ç‰ˆï¼‰
   */
  private extractWordRoot(word: string): string {
    // æ¥å°¾è¾ã‚’å‰Šé™¤
    const suffixes = ['ing', 'ed', 'er', 'est', 'ly', 's', 'es', 'tion', 'ment'];

    for (const suffix of suffixes) {
      if (word.endsWith(suffix)) {
        return word.substring(0, word.length - suffix.length);
      }
    }

    return word;
  }

  /**
   * æ–‡æ³•è¤‡é›‘åº¦ã®è©•ä¾¡
   */
  private assessGrammarComplexity(word: string): number {
    let complexity = 0;

    // ä¸è¦å‰‡å‹•è©ã®åˆ¤å®šï¼ˆç°¡æ˜“ç‰ˆï¼‰
    const irregularVerbs = [
      'be',
      'have',
      'do',
      'go',
      'take',
      'get',
      'make',
      'know',
      'think',
      'see',
      'come',
      'want',
      'use',
      'find',
      'give',
    ];

    if (irregularVerbs.some((v) => word.includes(v))) {
      complexity += 0.3;
    }

    // è¤‡åˆèªã®åˆ¤å®š
    if (word.includes('-') || word.includes(' ')) {
      complexity += 0.2;
    }

    // æŠ½è±¡åè©ã®åˆ¤å®š
    if (word.endsWith('tion') || word.endsWith('ment') || word.endsWith('ness')) {
      complexity += 0.2;
    }

    return Math.min(complexity, 1);
  }

  validateSignal(signal: LinguisticSignal): boolean {
    if (!signal.aiId || signal.aiId !== 'linguistic') return false;
    if (signal.confidence < 0 || signal.confidence > 1) return false;
    if (signal.inherentDifficulty < 0 || signal.inherentDifficulty > 1) return false;
    if (signal.grammarComplexity < 0 || signal.grammarComplexity > 1) return false;
    if (!Array.isArray(signal.phoneticSimilarity)) return false;
    if (!Array.isArray(signal.semanticCluster)) return false;

    return true;
  }

  // ========================================
  // Phase 4.5: MLçµ±åˆãƒ¡ã‚½ãƒƒãƒ‰
  // ========================================

  protected async analyzeByML(input: AIAnalysisInput): Promise<LinguisticSignal> {
    const features = this.extractFeatures(input);
    const prediction = await this.predict(features);

    return {
      aiId: 'linguistic',
      confidence: prediction.confidence,
      timestamp: Date.now(),
      inherentDifficulty: prediction.values[0],
      phoneticSimilarity: [], // MLã§ã¯ç°¡ç•¥åŒ–
      semanticCluster: [], // MLã§ã¯ç°¡ç•¥åŒ–
      grammarComplexity: prediction.values[1],
    };
  }

  protected mergeSignals(
    ruleSignal: LinguisticSignal,
    mlSignal: LinguisticSignal,
    input: AIAnalysisInput
  ): LinguisticSignal {
    const totalWords = Object.keys(input.allProgress).length;
    const mlWeight = Math.min(Math.max((totalWords - 30) / 50, 0), 0.5);
    const ruleWeight = 1 - mlWeight;

    return {
      aiId: 'linguistic',
      confidence: (ruleSignal.confidence * ruleWeight) + (mlSignal.confidence * mlWeight),
      timestamp: Date.now(),
      inherentDifficulty:
        (ruleSignal.inherentDifficulty * ruleWeight) +
        (mlSignal.inherentDifficulty * mlWeight),
      phoneticSimilarity: ruleSignal.phoneticSimilarity,
      semanticCluster: ruleSignal.semanticCluster,
      grammarComplexity:
        (ruleSignal.grammarComplexity * ruleWeight) +
        (mlSignal.grammarComplexity * mlWeight),
    };
  }

  protected extractFeatures(input: AIAnalysisInput): number[] {
    const { word } = input;
    return [
      word.word.length / 15,
      word.meaning.split(',').length / 5,
      word.ipa ? word.ipa.length / 20 : 0,
      word.katakana ? word.katakana.length / 20 : 0,
      /[^aeiou]{3}/.test(word.word) ? 1 : 0,
      /([bcdfghjklmnpqrstvwxyz])\1/.test(word.word) ? 1 : 0,
      word.word.split('-').length / 3,
      word.word.includes(' ') ? 1 : 0,
      word.word.match(/[A-Z]/g)?.length || 0,
      /(tion|ment|ness|ing|ed)$/.test(word.word) ? 1 : 0,
    ];
  }

  protected getFeatureDimension(): number { return 10; }
  protected getOutputDimension(): number { return 2; }
}
