#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç†Ÿèªãƒ‡ãƒ¼ã‚¿å“è³ªæ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å“è³ªã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å•é¡Œç‚¹ã‚’å ±å‘Šã™ã‚‹
"""

import sys
import csv
import re
from typing import List, Dict, Tuple
from collections import Counter

# ã‚«ãƒ†ã‚´ãƒªãƒ¼å®šç¾©
VALID_CATEGORIES = [
    "è¨€èªåŸºæœ¬", "å­¦æ ¡ãƒ»å­¦ç¿’", "æ—¥å¸¸ç”Ÿæ´»", "äººãƒ»ç¤¾ä¼š", "è‡ªç„¶ãƒ»ç’°å¢ƒ",
    "é£Ÿãƒ»å¥åº·", "é‹å‹•ãƒ»å¨¯æ¥½", "å ´æ‰€ãƒ»ç§»å‹•", "æ™‚é–“ãƒ»æ•°é‡", "ç§‘å­¦ãƒ»æŠ€è¡“"
]

# é›£æ˜“åº¦å®šç¾©
VALID_DIFFICULTIES = ["åˆç´š", "ä¸­ç´š", "ä¸Šç´š"]

# å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
REQUIRED_FIELDS = ["èªå¥", "èª­ã¿", "æ„å‘³", "èªæºç­‰è§£èª¬", "é–¢é€£èª", "é–¢é€£åˆ†é‡", "é›£æ˜“åº¦"]

# ã‚¢ã‚¯ã‚»ãƒ³ãƒˆè¨˜å·ä»˜ãæ¯éŸ³
ACCENT_VOWELS = ['ã‚¢Ì', 'ã‚¤Ì', 'ã‚¦Ì', 'ã‚¨Ì', 'ã‚ªÌ']

class PhraseValidator:
    """ç†Ÿèªãƒ‡ãƒ¼ã‚¿ã®ãƒãƒªãƒ‡ãƒ¼ã‚¿ãƒ¼"""
    
    def __init__(self, csv_file: str, existing_phrases: List[str] = None):
        self.csv_file = csv_file
        self.existing_phrases = set(existing_phrases) if existing_phrases else set()
        self.errors = []
        self.warnings = []
        self.info = []
        self.phrases = []
    
    def load_csv(self) -> bool:
        """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
        try:
            with open(self.csv_file, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                
                # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ¤œè¨¼
                if not reader.fieldnames:
                    self.errors.append("ãƒ˜ãƒƒãƒ€ãƒ¼è¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                    return False
                
                missing_fields = set(REQUIRED_FIELDS) - set(reader.fieldnames)
                if missing_fields:
                    self.errors.append(f"å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒä¸è¶³: {', '.join(missing_fields)}")
                    return False
                
                self.phrases = list(reader)
                return True
        
        except FileNotFoundError:
            self.errors.append(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.csv_file}")
            return False
        except Exception as e:
            self.errors.append(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False
    
    def validate_all(self) -> Tuple[int, int, int]:
        """ã™ã¹ã¦ã®æ¤œè¨¼ã‚’å®Ÿè¡Œ"""
        if not self.load_csv():
            return 0, 0, 0
        
        for idx, phrase in enumerate(self.phrases, start=2):  # 2è¡Œç›®ã‹ã‚‰ï¼ˆ1è¡Œç›®ã¯ãƒ˜ãƒƒãƒ€ãƒ¼ï¼‰
            self._validate_phrase(phrase, idx)
        
        self._validate_duplicates()
        self._generate_statistics()
        
        return len(self.errors), len(self.warnings), len(self.info)
    
    def _validate_phrase(self, phrase: Dict, row_num: int):
        """å€‹åˆ¥ã®ç†Ÿèªãƒ‡ãƒ¼ã‚¿ã‚’æ¤œè¨¼"""
        
        # 1. èªå¥ã®æ¤œè¨¼
        word = phrase.get("èªå¥", "").strip()
        if not word:
            self.errors.append(f"è¡Œ{row_num}: èªå¥ãŒç©ºã§ã™")
        elif word.startswith("[TODO"):
            self.warnings.append(f"è¡Œ{row_num}: èªå¥ãŒæœªå…¥åŠ›ã§ã™ï¼ˆ{word}ï¼‰")
        elif not re.search(r'[a-zA-Z]', word):
            self.errors.append(f"è¡Œ{row_num}: èªå¥ã«è‹±å­—ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ï¼ˆ{word}ï¼‰")
        
        # 2. èª­ã¿ã®æ¤œè¨¼
        reading = phrase.get("èª­ã¿", "").strip()
        if not reading:
            self.errors.append(f"è¡Œ{row_num}: èª­ã¿ãŒç©ºã§ã™")
        elif reading.startswith("[TODO"):
            self.warnings.append(f"è¡Œ{row_num}: èª­ã¿ãŒæœªå…¥åŠ›ã§ã™")
        else:
            # ã‚¢ã‚¯ã‚»ãƒ³ãƒˆè¨˜å·ã®ãƒã‚§ãƒƒã‚¯
            has_accent = any(vowel in reading for vowel in ACCENT_VOWELS)
            if not has_accent:
                self.warnings.append(f"è¡Œ{row_num}: èª­ã¿ã«ã‚¢ã‚¯ã‚»ãƒ³ãƒˆè¨˜å·ãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆ{word}: {reading}ï¼‰")
            
            # ã‚«ã‚¿ã‚«ãƒŠãƒã‚§ãƒƒã‚¯
            if not re.match(r'^[ã‚¡-ãƒ´ãƒ¼Ì\s]+$', reading):
                self.errors.append(f"è¡Œ{row_num}: èª­ã¿ã«ä¸æ­£ãªæ–‡å­—ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ï¼ˆ{reading}ï¼‰")
        
        # 3. æ„å‘³ã®æ¤œè¨¼
        meaning = phrase.get("æ„å‘³", "").strip()
        if not meaning:
            self.errors.append(f"è¡Œ{row_num}: æ„å‘³ãŒç©ºã§ã™")
        elif meaning.startswith("[TODO"):
            self.warnings.append(f"è¡Œ{row_num}: æ„å‘³ãŒæœªå…¥åŠ›ã§ã™")
        elif len(meaning) < 3:
            self.warnings.append(f"è¡Œ{row_num}: æ„å‘³ãŒçŸ­ã™ãã¾ã™ï¼ˆ{word}: {meaning}ï¼‰")
        
        # 4. èªæºç­‰è§£èª¬ã®æ¤œè¨¼
        etymology = phrase.get("èªæºç­‰è§£èª¬", "").strip()
        if not etymology:
            self.errors.append(f"è¡Œ{row_num}: èªæºç­‰è§£èª¬ãŒç©ºã§ã™")
        elif etymology.startswith("[TODO"):
            self.warnings.append(f"è¡Œ{row_num}: èªæºç­‰è§£èª¬ãŒæœªå…¥åŠ›ã§ã™")
        elif len(etymology) < 20:
            self.warnings.append(f"è¡Œ{row_num}: èªæºç­‰è§£èª¬ãŒçŸ­ã™ãã¾ã™ï¼ˆ{word}ï¼‰")
        elif "çµ„ã¿åˆã‚ã›" not in etymology:
            self.info.append(f"è¡Œ{row_num}: èªæºè§£èª¬ã«ã€Œçµ„ã¿åˆã‚ã›ã€ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ï¼ˆ{word}ï¼‰")
        
        # 5. é–¢é€£èªã®æ¤œè¨¼
        related = phrase.get("é–¢é€£èª", "").strip()
        if not related:
            self.errors.append(f"è¡Œ{row_num}: é–¢é€£èªãŒç©ºã§ã™")
        elif related.startswith("[TODO"):
            self.warnings.append(f"è¡Œ{row_num}: é–¢é€£èªãŒæœªå…¥åŠ›ã§ã™")
        else:
            # é–¢é€£èªã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãƒã‚§ãƒƒã‚¯ï¼ˆæ‹¬å¼§ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ï¼‰
            if "(" not in related or ")" not in related:
                self.warnings.append(f"è¡Œ{row_num}: é–¢é€£èªã«èª­ã¿ä»®åãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ï¼ˆ{word}ï¼‰")
            
            # ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§2ã¤ä»¥ä¸Šã‚ã‚‹ã‹
            items = [item.strip() for item in related.split(",")]
            if len(items) < 2:
                self.info.append(f"è¡Œ{row_num}: é–¢é€£èªã¯2ã¤ä»¥ä¸Šæ¨å¥¨ã§ã™ï¼ˆ{word}ï¼‰")
        
        # 6. ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®æ¤œè¨¼
        category = phrase.get("é–¢é€£åˆ†é‡", "").strip()
        if not category:
            self.errors.append(f"è¡Œ{row_num}: é–¢é€£åˆ†é‡ãŒç©ºã§ã™")
        elif category not in VALID_CATEGORIES:
            self.errors.append(f"è¡Œ{row_num}: ç„¡åŠ¹ãªé–¢é€£åˆ†é‡ï¼ˆ{category}ï¼‰")
        
        # 7. é›£æ˜“åº¦ã®æ¤œè¨¼
        difficulty = phrase.get("é›£æ˜“åº¦", "").strip()
        if not difficulty:
            self.errors.append(f"è¡Œ{row_num}: é›£æ˜“åº¦ãŒç©ºã§ã™")
        elif difficulty not in VALID_DIFFICULTIES:
            self.errors.append(f"è¡Œ{row_num}: ç„¡åŠ¹ãªé›£æ˜“åº¦ï¼ˆ{difficulty}ï¼‰")
    
    def _validate_duplicates(self):
        """é‡è¤‡ãƒã‚§ãƒƒã‚¯"""
        word_counts = Counter(phrase.get("èªå¥", "").strip().lower() for phrase in self.phrases)
        duplicates = [(word, count) for word, count in word_counts.items() if count > 1]
        
        if duplicates:
            for word, count in duplicates:
                self.errors.append(f"èªå¥ã®é‡è¤‡: '{word}' ãŒ{count}å›å‡ºç¾")
        
        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã¨ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯
        if self.existing_phrases:
            for phrase in self.phrases:
                word = phrase.get("èªå¥", "").strip().lower()
                if word in self.existing_phrases:
                    self.errors.append(f"æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã¨é‡è¤‡: '{word}'")
    
    def _generate_statistics(self):
        """çµ±è¨ˆæƒ…å ±ã‚’ç”Ÿæˆ"""
        if not self.phrases:
            return
        
        # ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ†å¸ƒ
        categories = Counter(phrase.get("é–¢é€£åˆ†é‡", "") for phrase in self.phrases)
        self.info.append(f"\nã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ†å¸ƒ:")
        for cat, count in categories.most_common():
            self.info.append(f"  {cat}: {count}ä»¶")
        
        # é›£æ˜“åº¦åˆ†å¸ƒ
        difficulties = Counter(phrase.get("é›£æ˜“åº¦", "") for phrase in self.phrases)
        self.info.append(f"\né›£æ˜“åº¦åˆ†å¸ƒ:")
        for diff, count in difficulties.most_common():
            self.info.append(f"  {diff}: {count}ä»¶")
        
        # TODOä»¶æ•°
        todo_count = sum(1 for phrase in self.phrases 
                        if any("[TODO" in str(v) for v in phrase.values()))
        if todo_count > 0:
            self.warnings.append(f"\nTODOæ®‹ã‚Š: {todo_count}ä»¶")
    
    def print_report(self):
        """æ¤œè¨¼çµæœã‚’è¡¨ç¤º"""
        print("\n" + "=" * 70)
        print(f"  ç†Ÿèªãƒ‡ãƒ¼ã‚¿å“è³ªæ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆ: {self.csv_file}")
        print("=" * 70)
        
        print(f"\nğŸ“Š åŸºæœ¬æƒ…å ±")
        print(f"  ç·ä»¶æ•°: {len(self.phrases)}ä»¶")
        
        # ã‚¨ãƒ©ãƒ¼
        if self.errors:
            print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ ({len(self.errors)}ä»¶):")
            for error in self.errors[:20]:  # æœ€åˆã®20ä»¶ã®ã¿è¡¨ç¤º
                print(f"  â€¢ {error}")
            if len(self.errors) > 20:
                print(f"  ... ä»–{len(self.errors) - 20}ä»¶")
        
        # è­¦å‘Š
        if self.warnings:
            print(f"\nâš ï¸  è­¦å‘Š ({len(self.warnings)}ä»¶):")
            for warning in self.warnings[:20]:
                print(f"  â€¢ {warning}")
            if len(self.warnings) > 20:
                print(f"  ... ä»–{len(self.warnings) - 20}ä»¶")
        
        # æƒ…å ±
        if self.info:
            print(f"\nâ„¹ï¸  æƒ…å ±:")
            for info in self.info:
                print(f"  {info}")
        
        # ç·è©•
        print(f"\n{'='*70}")
        if not self.errors and not self.warnings:
            print("âœ… æ¤œè¨¼å®Œäº†: å•é¡Œã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        elif not self.errors:
            print(f"âœ… ã‚¨ãƒ©ãƒ¼ãªã—ï¼ˆè­¦å‘Š {len(self.warnings)}ä»¶ï¼‰")
        else:
            print(f"âŒ æ¤œè¨¼å¤±æ•—: {len(self.errors)}ä»¶ã®ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Šã¾ã™")
        print("=" * 70)

def load_existing_phrases(csv_file: str) -> List[str]:
    """æ—¢å­˜ã®ç†Ÿèªãƒªã‚¹ãƒˆã‚’èª­ã¿è¾¼ã‚€"""
    phrases = []
    try:
        with open(csv_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            phrases = [row.get("èªå¥", "").strip().lower() for row in reader if row.get("èªå¥")]
    except FileNotFoundError:
        pass
    return phrases

def main():
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  python3 validate_phrases.py <CSVãƒ•ã‚¡ã‚¤ãƒ«> [æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«]")
        print("\nä¾‹:")
        print("  python3 validate_phrases.py phrases-template-è¨€èªåŸºæœ¬-åˆç´š-20.csv")
        print("  python3 validate_phrases.py new-phrases.csv public/data/junior-high-entrance-words.csv")
        sys.exit(1)
    
    csv_file = sys.argv[1]
    existing_file = sys.argv[2] if len(sys.argv) > 2 else None
    
    # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    existing_phrases = []
    if existing_file:
        print(f"æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­: {existing_file}")
        existing_phrases = load_existing_phrases(existing_file)
        print(f"  æ—¢å­˜ç†Ÿèªæ•°: {len(existing_phrases)}ä»¶\n")
    
    # æ¤œè¨¼å®Ÿè¡Œ
    validator = PhraseValidator(csv_file, existing_phrases)
    error_count, warning_count, info_count = validator.validate_all()
    validator.print_report()
    
    # çµ‚äº†ã‚³ãƒ¼ãƒ‰
    if error_count > 0:
        sys.exit(1)
    else:
        sys.exit(0)

if __name__ == "__main__":
    main()
