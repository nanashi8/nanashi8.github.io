---
title: コンテンツ品質を保つ作成ワークフロー（手動AI・差分修正・バッチ・検証）
created: 2025-12-26
updated: 2025-12-26
status: implemented
tags: [process, content, quality, ai]
---

# コンテンツ品質を保つ作成ワークフロー（手動AI・差分修正・バッチ・検証）

## 目的

このガイドは、文法問題の解説・問題文（日本語）・翻訳など、学習効果に直結する「文章系コンテンツ」を、**品質を落とさずに効率的に作成する**ための手順と考え方をまとめます。

- 「スクリプト＝手抜き」ではなく、**人とAIの思考コストを“良い場所”に集中**させるための仕組み化が目的です。
- 生成（AI）と検証（スクリプト）と最終判断（人）の役割を分けます。

## 前提（参照すべき基準）

- 品質原則: `docs/quality/CONTENT_QUALITY_PRINCIPLES.md`
- 文法データ品質: `docs/guidelines/GRAMMAR_DATA_QUALITY_GUIDELINES.md`
- 文法解説の品質（ビルドゲート）: `docs/processes/EXPLANATION_QUALITY_GUIDE.md`
- 語彙データ仕様: `docs/specifications/19-junior-high-vocabulary.md`
- 熟語データ仕様: `docs/specifications/20-junior-high-phrases.md`
- 長文作成ガイド: `docs/guidelines/passage/PASSAGE_CREATION_GUIDELINES.md`

本ガイドは「上記を守るための作り方（工程）」に焦点を当てます。

---

## 基本設計：人・AI・スクリプトの役割分担

### 人が決める（毎回ブレると品質が落ちる）

- 対象（学年/単元）と到達レベル
- 解説の構造（必須セクション）
- 口調・文字数目安・禁止事項
- 「この問題で教えたい一点（狙い）」

### AIに任せる（狙いが決まっていると強い）

- 問題固有の「なぜそれが正解か」
- 学習者が引っかかるポイント（誤解）
- 中学生レベルの例文・言い換え

### スクリプトに任せる（人がやると遅い・漏れる）

- 必須項目/文字数/キーワードの検証
- 形式事故（JSON破損、フィールド欠落、空文字など）の検知
- 重複・プレースホルダーの検出

---

## 方法別の作成手順（いつ使うか・工程・注意点）

### 方法A: 完全手動（人が書き下ろす）

**向いている**
- 重要なサンプル問題・代表例（見本を作る）
- ルールの“原文”を作る（AIの参照元になる文章）

**工程（最小）**
1. 狙い（1行）と誤答理由（1行）を先に書く
1. 解説を構造どおりに書く
1. 検証コマンドを実行して、形式不備を潰す

**落とし穴**
- 人でも「説明の抜け（誤答理由/用語定義）」が起きる

---

### 方法B: 手動AI（構造指示 + 書き下ろし）

**向いている**
- 丁寧な解説を増やしたいが、品質は落としたくない
- “毎回文章は新しくしたい”が、観点は揃えたい

**工程（推奨）**
1. 入力をテンプレに埋める（問題文/選択肢/正解/狙い/誤答ポイント）
1. まず「要点だけ（箇条書き）」を出させる
1. 次に「指定の構造・文字数・口調」で清書
1. 自動検証で落ちたら、差分修正（方法C）へ

**品質を守るコツ**
- 「何を書くか（観点）」は固定し、文章表現だけを毎回変える
- AIの自由度を下げる（構造、字数、禁止事項、範囲）ほど平均品質が上がりやすい

---

### 方法C: 差分修正（最短で品質を上げる）

**向いている**
- 既に内容の芯は合っているが、
  - キーワード不足
  - 説明が浅い
  - 例文が難しい
  - 断定が強すぎる
  などの“局所”だけ直したい

**工程（推奨）**
1. 変更範囲を固定する（例：理由段落だけ、例文だけ）
1. 目的を1つに絞る（例：誤答理由を1文追加、語彙を中学生に）
1. 最後に「整合性チェックを1回だけ」させる

**落とし穴（品質低下の原因）**
- 「もっと良くして」など曖昧な指示 → 全面改変されて矛盾が増える
- 範囲を指定しない → 正解理由まで勝手に変わる

---

### 方法D: バッチ処理（小さく回して品質を落とさない）

**向いている**
- 同一文法・同一狙いの問題がまとまっている
- 5〜10問ずつ、人が検品できるサイズで回したい

**工程（推奨）**
1. バッチ単位を揃える（同じ文法ポイント + 同じ狙い）
1. 1バッチ5〜10問までにする
1. バッチ出力 → 自動検証 → 落ちたものだけ差分修正

**落とし穴**
- 「似てるようで違う問題」を同じ狙いで流す → 解説がズレる
- 1回に20問以上 → 後半が雑になりやすく、検品が破綻

---

### 方法E: スクリプト補助（生成ではなく“品質ゲート”として使う）

**向いている**
- 人が書く/AIが書く、どちらの方法でも必須
- 形式事故をゼロにしたい

**工程（推奨）**
1. 作成・修正
1. 自動検証（失敗したら差分修正へ戻す）
1. 最後に `npm run build` まで通す

---

## 推奨の全体工程（文法解説を例に）

### 0. 準備（1問あたり数十秒で済むようにする）

- 解説の構造（必須セクション）と字数レンジを決める
- 「狙い（1行）」と「誤答しやすい理由（1行）」を書く

### 1. 生成（方法B or A）

- 方法Bを使う場合は、まず箇条書き→清書の2段階にする

### 2. 自動検証（必須）

- 文法解説の品質チェック:

```bash
npm run validate:grammar:explanations
```

- 文法データの総合チェック（重複や基本整合性）:

```bash
npm run check:grammar-quality
```

### 3. 修正

- エラーが出たものだけ、方法C（差分修正）で直す
- 直したら、必ず同じ検証をもう一度通す

### 4. 最終ゲート

```bash
npm run build
```

（`prebuild` で解説品質チェックが走るため、ビルドが通ることが“最低ライン”になります）

---

## コンテンツ別の作成方法（語彙 / 文法 / 長文）

この章は、学習者の体験（暗記・和訳・スペル・文法・長文）に直結する観点で、作成時に何を固定し、どこをAIに任せ、何を自動検証するかを整理します。

### 1) 語彙（暗記・和訳・スペル）

**前提（このアプリの学習設計）**
- **暗記 / 和訳 / スペルは出題元が共通**で、同じ語彙CSVを参照します
- ターゲットは **中学履修内容〜難関高入試レベル** を含む範囲です

**対象データ（実運用）**
- `junior-high-intermediate`（中学履修内容）
  - 単語: `public/data/vocabulary/junior-high-intermediate-words.csv`
  - 熟語: `public/data/vocabulary/junior-high-intermediate-phrases.csv`
- `high-school-entrance`（中学履修内容〜難関高入試レベルまでを含む）
  - 単語: `public/data/vocabulary/high-school-entrance-words.csv`
  - 熟語: `public/data/vocabulary/high-school-entrance-phrases.csv`

※ 実装上は `src/App.tsx` で上記4ファイルを読み込み、すべて統合して出題プールにします。

**学習品質の定義（落ちやすいポイント）**
- 3タブ共通で、次を満たす（タブ別に別基準を作らない）
  - `語句`: 誤字・表記ゆれ・余計な記号がない（スペル入力に耐える）
  - `読み`: 仕様どおり（IPA等）で、カタカナ読みを含む形式が崩れない
  - `意味`: 学習者が瞬時に想起できる粒度で、不自然な日本語にならない
  - `関連分野`/`難易度`: 仕様に完全一致（カテゴリ表記ゆれがない）
  - `語源等解説`/`関連語`: 「覚えやすさ」に寄与し、ノイズ（無関係な蘊蓄）にならない

**補足: `all-words.csv` について**
- `public/data/vocabulary/all-words.csv` は **統合語彙リスト**で、行末に `source` 列を持つ（8列）形式です
- 主に **長文パッセージの語彙カバレッジ計測**で参照されます（例: `scripts/vocab_coverage_report.py --vocab ../public/data/vocabulary/all-words.csv`）
- その副産物として、`scripts/output/vocab_unused_all-words.txt` や `scripts/output/vocab_coverage_report_all-words.txt` のようなレポートが生成されます
- 一方で、アプリの語彙読み込み（`src/utils.ts` の `parseCSV()`）は **語彙クイズ用の7列CSVを前提**にしているため、`all-words.csv` をそのまま出題元として差し替える用途には向きません

**注意（命名の混在）**
- `docs/` や一部スクリプトでは `junior-high-entrance-*` / `intermediate-*` のような **レガシー命名**が登場することがあります
- 実運用（アプリで出題され、語彙の品質テスト対象にもなっている）のは、この章で挙げた `high-school-entrance-*` / `junior-high-intermediate-*` です

**作成工程（推奨）**
1. まず仕様を固定する（7列、10カテゴリ、難易度）
1. 追加する語を5〜20件程度に絞り、同一テーマ（カテゴリ）でまとめる
1. 1件ごとに「語句/読み/意味」を最優先で作り、語源等解説・関連語は後から埋める
1. テストで機械的に落ちたものだけを差分修正（方法C）する

**品質ゲート（必須）**
```bash
# 語彙CSV品質テスト
npm run test:unit -- tests/content/vocabulary-quality-validator.test.ts
```

**手動AIで作るときのコツ（テンプレ感を減らす）**
- `意味` は「学習者が日本語で瞬時に想起できる粒度」を固定し、言い換えでブレさせない
- `読み` は「アクセント記号・表記ルール」を先に固定し、例外だけ人が決める
- `語源等解説` は“知識披露”より「覚えやすさに直結する一言」を優先する

---

### 2) 文法（問題文・ヒント・解説）

**対象データ（例）**
- `public/data/fill-in-blank-questions-grade*.json`
- `public/data/verb-form-questions-grade*.json`
- `public/data/sentence-ordering-grade*.json`

**学習品質の定義（落ちやすいポイント）**
- 解説が「正解の根拠」を言語化できている（正答を言い換えただけにならない）
- 誤答の理由が1つ具体的に書かれている（なぜ引っかかるのか）
- 例文が中学生レベルの語彙・状況である

**作成工程（推奨）**
- 方法B（手動AI）→ 自動検証 → 落ちたものだけ方法C（差分修正）

**品質ゲート（必須）**
```bash
npm run validate:grammar:explanations
npm run check:grammar-quality
```

---

### 3) 長文（読解・フレーズ学習）

**対象データ（現行）**
- 原文（整形済み）: `public/data/passages/*.txt`
- 日本語（整形済み）: `public/data/passages-translations/*-ja.txt`
- フレーズ学習JSON: `public/data/passages-phrase-learning/*.json`

**学習品質の定義（落ちやすいポイント）**
- 英文が自然で、学習者にとって教育的（不自然な口語/硬すぎる学術調に偏らない）
- phrase-based の改行が「意味単位」として妥当（細切れで理解が壊れない）
- 原文・翻訳・JSONの対応関係が崩れていない（ファイル欠落・不一致）

**作成工程（推奨）**
1. `docs/guidelines/passage/PASSAGE_CREATION_GUIDELINES.md` のフォーマット（phrase-based line breaks）に従って原文を作る
1. 同じ分割ルールで日本語訳を作る（段落/見出しの扱いも揃える）
1. フレーズ学習JSONを生成する（既存スクリプトを使い、差分修正は小さく）
1. 対応ファイルの存在と整合性をチェックする

**品質ゲート（推奨）**
```bash
# 生成（例: 既存21本を一括更新する場合）
bash scripts/generate_all_phrase_jsons.sh

# 対応関係（passages-for-phrase-work / passages-phrase-learning / passages-translations）の整合性
bash scripts/check_passage_consistency.sh
```

**メタデータ付与（任意 / 重いので最後）**
フレーズ学習JSONに lemma 等を付与するスクリプトがあります（APIキーが必要になるため、運用方針を決めてから使います）。

```bash
python3 scripts/add_lemma_metadata.py
```

---

## コピペ用テンプレ（手動AI）

### 生成テンプレ（構造 + 書き下ろし）

下記の入力を与え、**構造を固定して、文章は書き下ろし**させます。

```
あなたは中学生向け学習教材の編集者です。
次の問題について、学習者が納得できる丁寧な解説を書いてください。

【制約】
- 日本語、です・ます調
- 200〜350字（必要なら+100字まで可）
- 余計な派生文法には寄り道しない
- 専門用語を出す場合は一言で定義する

【出力構造（見出しは不要、文章中で自然に）】
1) 正解の結論（〜が正解です）
2) 理由（この文では〜なので）
3) 文法ルール（一般化して1〜2文）
4) 間違えやすい点（誤答の理由を1つ）
5) ミニ例文（1つ、語彙は中学生レベル）

【入力】
- 学年/単元:
- 問題文（日本語）:
- 英文/空所:
- 選択肢:
- 正解:
- 狙い（この問題で教えたい一点）:
- 学習者がやりがちな誤り:
```

### 差分修正テンプレ（変更範囲固定）

```
次の解説のうち、【変更範囲】だけを修正してください。
他の文は一字も変えないでください。

【変更範囲】
- （例）「間違えやすい点」相当の1文のみ

【目的】
- （例）誤答の理由を具体化して1文追加（合計2文まで）

【追加制約】
- 最後に、正解・理由・文法ルール・例文が矛盾していないか1回だけ確認し、矛盾があればその1点だけ直す

【元の解説】
...
```

---

## よくある失敗パターンと対策

- **テンプレ感が強い**: 構造は固定しつつ「この文のどこが根拠か」を必ず1箇所指摘させる
- **寄り道して長い**: 「派生文法に寄り道しない」「この問題で必要な範囲のみ」と明記する
- **矛盾が混入**: 修正後の“整合性チェック1回”を毎回入れる
- **検品が破綻**: バッチは5〜10問までにし、落ちたものだけ差分修正する

---

## 関連リンク（このリポジトリ内）

- 文法解説の品質ゲート: `docs/processes/EXPLANATION_QUALITY_GUIDE.md`
- 文法データ品質ガイド: `docs/guidelines/GRAMMAR_DATA_QUALITY_GUIDELINES.md`
- 文法品質パイプライン（重複/整合性）: `docs/guidelines/grammar/GRAMMAR_QUALITY_PIPELINE.md`
- 全体品質自動化（全コンテンツ）: `docs/quality/QUALITY_AUTOMATION_GUIDE.md`
- コンテンツ品質テスト（語彙/文法）: `docs/quality/CONTENT_QUALITY_TESTING.md`
- 長文ガイド（索引）: `docs/guidelines/passage/README.md`
