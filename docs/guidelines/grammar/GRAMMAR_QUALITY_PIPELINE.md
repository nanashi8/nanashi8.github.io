# æ–‡æ³•å•é¡Œä½œæˆ å“è³ªä¿è¨¼ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

## æ¦‚è¦
G1/G2/G3ã®æ–‡æ³•å•é¡Œä½œæˆã§åŸ¹ã£ãŸå“è³ªä¿è¨¼ã®ä»•çµ„ã¿ã¨ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã‚’ä½“ç³»åŒ–ã—ãŸã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã€‚

---

## ğŸ“Š é”æˆã—ãŸå“è³ªæŒ‡æ¨™

### æœ€çµ‚çµæœ
- **G1 (ä¸­1)**: 600å•ã€é‡è¤‡0ä»¶ (100%å“è³ª)
- **G2 (ä¸­2)**: 600å•ã€é‡è¤‡0ä»¶ (100%å“è³ª)
- **G3 (ä¸­3)**: 600å•ã€é‡è¤‡2ä»¶ (99.8%å“è³ª)

### æ”¹å–„å®Ÿç¸¾
- **G3**: 160xé‡è¤‡ â†’ 2xé‡è¤‡ (98.75%æ”¹å–„)
- **G2**: 90%ãƒ‡ãƒ¼ã‚¿ç ´æ â†’ 100%å®Œå…¨å¾©æ—§
- **G1**: 2xé‡è¤‡ â†’ 0xé‡è¤‡ (100%é”æˆ)

---

## ğŸ”§ å“è³ªä¿è¨¼ã®5æ®µéšãƒ—ãƒ­ã‚»ã‚¹

### 1. ãƒ‡ãƒ¼ã‚¿è¨­è¨ˆãƒ•ã‚§ãƒ¼ã‚º

#### å¿…é ˆã‚¹ã‚­ãƒ¼ãƒå®šç¾©
```json
{
  "id": "vf-g{grade}-u{unit}-{number:03d}",
  "japanese": "å¿…é ˆ: æ—¥æœ¬èªè¨³ (ç©ºæ–‡å­—åˆ—ç¦æ­¢)",
  "sentence": "å¿…é ˆ: è‹±æ–‡ (ãƒ¦ãƒ‹ãƒ¼ã‚¯æ€§å¿…é ˆ)",
  "verb": "æ–‡æ³•ã‚¿ã‚¤ãƒ—",
  "choices": ["é¸æŠè‚¢é…åˆ—"],
  "correctAnswer": "æ­£è§£",
  "difficulty": "intermediate/basic/advanced",
  "explanation": "æ–‡æ³•èª¬æ˜",
  "grammarPoint": "æ–‡æ³•ãƒã‚¤ãƒ³ãƒˆ"
}
```

#### è¨­è¨ˆåŸå‰‡
1. **ãƒ¦ãƒ‹ãƒ¼ã‚¯æ€§**: å…¨å•é¡Œã§è‹±æ–‡ãŒãƒ¦ãƒ‹ãƒ¼ã‚¯ã§ã‚ã‚‹ã“ã¨
1. **å®Œå…¨æ€§**: å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ç©ºæ–‡å­—åˆ—ã‚’è¨±å¯ã—ãªã„
1. **ä¸€è²«æ€§**: Unité–“ã§é‡è¤‡ãŒãªã„ã“ã¨
1. **å¤šæ§˜æ€§**: åŒã˜æ–‡æ³•ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã‚‚ç•°ãªã‚‹èªå½™ã‚’ä½¿ç”¨

---

### 2. ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ•ã‚§ãƒ¼ã‚º

#### ã‚¹ã‚¯ãƒªãƒ—ãƒˆæ§‹é€ ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

```python
def build_unit_questions():
    """
    ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹:
    1. å„Unitã§20å•ã‚’ç”Ÿæˆ
    1. ãƒ‘ã‚¿ãƒ¼ãƒ³é…åˆ—ã§ç®¡ç† (japanese, sentence, answer)
    1. èªå½™ã®å¤šæ§˜æ€§ã‚’ç¢ºä¿
    1. åŒã˜ä¸»èª/å‹•è©ã®é€£ç¶šä½¿ç”¨ã‚’é¿ã‘ã‚‹
    """
    patterns = [
        ("æ—¥æœ¬èªè¨³1", "English sentence 1 ____.", "answer1"),
        ("æ—¥æœ¬èªè¨³2", "English sentence 2 ____.", "answer2"),
        # ... 20ãƒ‘ã‚¿ãƒ¼ãƒ³
    ]
    
    return [
        {
            "id": f"vf-g{grade}-u{unit}-{i+1:03d}",
            "japanese": ja,
            "sentence": en,
            # ... ä»–ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
        }
        for i, (ja, en, ans) in enumerate(patterns)
    ]
```

#### é¿ã‘ã‚‹ã¹ãã‚¢ãƒ³ãƒãƒ‘ã‚¿ãƒ¼ãƒ³
âŒ **åŒã˜æ–‡æ§‹é€ ã®ç¹°ã‚Šè¿”ã—**
```python
# æ‚ªã„ä¾‹
("ç§ã¯å­¦ç”Ÿã§ã™", "I ____ a student.", "am"),
("ã‚ãªãŸã¯å­¦ç”Ÿã§ã™", "You ____ a student.", "are"),
("å½¼ã¯å­¦ç”Ÿã§ã™", "He ____ a student.", "is"),
```

âœ… **å¤šæ§˜ãªæ–‡è„ˆã§ã®ä½¿ç”¨**
```python
# è‰¯ã„ä¾‹
("ç§ã¯å­¦ç”Ÿã§ã™", "I ____ a student.", "am"),
("ã‚ãªãŸã¯ä»Šæ—¥å¿™ã—ã„ã§ã™", "You ____ busy today.", "are"),
("å½¼ã¯å…ˆç”Ÿã§ã™", "He ____ a teacher.", "is"),
```

---

### 3. æ¤œè¨¼ãƒ•ã‚§ãƒ¼ã‚º

#### 3å±¤æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ 

##### Level 1: ã‚¹ã‚­ãƒ¼ãƒæ¤œè¨¼
```python
def validate_schema(question):
    """å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å­˜åœ¨ã¨å‹ã‚’ãƒã‚§ãƒƒã‚¯"""
    required_fields = ['id', 'japanese', 'sentence', 'correctAnswer']
    for field in required_fields:
        if field not in question:
            raise ValueError(f"Missing field: {field}")
        if not question[field] or question[field].strip() == '':
            raise ValueError(f"Empty field: {field}")
```

##### Level 2: é‡è¤‡æ¤œå‡º
```python
def detect_duplicates(questions):
    """
    é‡è¤‡ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º:
    1. å®Œå…¨ä¸€è‡´ (sentence)
    1. æ—¥æœ¬èªé‡è¤‡ (japanese)
    1. IDé‡è¤‡ (id)
    """
    from collections import Counter
    
    sentences = [q['sentence'] for q in questions]
    duplicates = {k: v for k, v in Counter(sentences).items() if v > 1}
    
    if duplicates:
        return f"Found {len(duplicates)} duplicate patterns"
    return "OK"
```

##### Level 3: ã‚¯ãƒ­ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«æ•´åˆæ€§
```python
def validate_cross_files(vf_data, fb_data, so_data):
    """
    3ãƒ•ã‚¡ã‚¤ãƒ«é–“ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯:
    1. IDä¸€è‡´ (vf-xxx â†’ fb-xxx â†’ so-xxx)
    1. æ—¥æœ¬èªä¸€è‡´
    1. å•é¡Œæ•°ä¸€è‡´
    """
    for i, (vf, fb, so) in enumerate(zip(vf_units, fb_units, so_units)):
        assert vf['japanese'] == fb['japanese'] == so['japanese']
        assert vf['id'].replace('vf-', '') == fb['id'].replace('fb-', '')
```

---

### 4. å•é¡Œä¿®æ­£ãƒ•ã‚§ãƒ¼ã‚º

#### é‡è¤‡è§£æ¶ˆã®å„ªå…ˆé †ä½

**Priority 1: æ–‡è„ˆã‚’å¤‰ãˆã‚‹**
```python
# Before
"He is taller than me."
"He is younger than me."
"He is stronger than me."

# After
"He is taller than me."
"He looks younger than before."  # æ–‡è„ˆå¤‰æ›´
"My brother is stronger than me."  # ä¸»èªå¤‰æ›´
```

**Priority 2: èªå½™ã‚’å¤‰ãˆã‚‹**
```python
# Before
"This is the best."
"This is the cheapest."

# After
"This is the best."
"This shirt is the cheapest."  # ä¸»èªã‚’å…·ä½“åŒ–
```

**Priority 3: æ–‡æ³•æ§‹é€ ã‚’å¤‰ãˆã‚‹**
```python
# Before (ç–‘å•æ–‡ã®é‡è¤‡)
"Are you happy?"
"Are you ready?"

# After
"Are you happy?"
"You are ready, aren't you?"  # ä»˜åŠ ç–‘å•æ–‡ã«å¤‰æ›´
```

---

### 5. ç¶™ç¶šçš„æ”¹å–„ãƒ•ã‚§ãƒ¼ã‚º

#### å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¿½è·¡

```python
def calculate_quality_metrics(data):
    """
    å“è³ªæŒ‡æ¨™:
    1. ãƒ¦ãƒ‹ãƒ¼ã‚¯åº¦ = unique_sentences / total_sentences * 100
    1. å®Œå…¨æ€§ = filled_fields / total_fields * 100
    1. å¤šæ§˜æ€§ = unique_vocabulary / total_vocabulary * 100
    """
    total = len(all_sentences)
    unique = len(set(all_sentences))
    uniqueness = unique / total * 100
    
    return {
        "total": total,
        "unique": unique,
        "uniqueness": f"{uniqueness:.1f}%",
        "duplicates": total - unique
    }
```

---

## ğŸ“‹ ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

### ç”Ÿæˆå‰ãƒã‚§ãƒƒã‚¯
- [ ] æ–‡æ³•ãƒã‚¤ãƒ³ãƒˆãŒæ˜ç¢ºã«å®šç¾©ã•ã‚Œã¦ã„ã‚‹
- [ ] å„Unitã§20å•åˆ†ã®å¤šæ§˜ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç”¨æ„
- [ ] èªå½™ãƒªã‚¹ãƒˆã‚’ä½œæˆæ¸ˆã¿ï¼ˆé‡è¤‡å›é¿ç”¨ï¼‰

### ç”Ÿæˆå¾Œãƒã‚§ãƒƒã‚¯
- [ ] å…¨å•é¡Œã«japaneseãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒå­˜åœ¨
- [ ] å…¨å•é¡Œã«sentenceãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒå­˜åœ¨
- [ ] IDãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãŒæ­£ã—ã„ (vf-g{grade}-u{unit}-{number:03d})
- [ ] choicesé…åˆ—ãŒ4ã¤ã®é¸æŠè‚¢ã‚’å«ã‚€

### æ¤œè¨¼ãƒã‚§ãƒƒã‚¯
- [ ] validate_grammar_v2.pyã§OKåˆ¤å®š
- [ ] ãƒ¦ãƒ‹ãƒ¼ã‚¯åº¦ãŒ95%ä»¥ä¸Š
- [ ] æ—¥æœ¬èªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å……è¶³ç‡100%
- [ ] ã‚¯ãƒ­ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«æ•´åˆæ€§ç¢ºèª

### ãƒ‡ãƒ—ãƒ­ã‚¤å‰ãƒã‚§ãƒƒã‚¯
- [ ] Git commit ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒå…·ä½“çš„
- [ ] å¤‰æ›´å†…å®¹ã‚’æ•°å€¤ã§è¨˜è¼‰ (ä¾‹: 98.75%æ”¹å–„)
- [ ] å…¨3ãƒ•ã‚¡ã‚¤ãƒ« (verb-form, fill-in-blank, sentence-ordering) æ›´æ–°æ¸ˆã¿

---

## ğŸš¨ å¤±æ•—ã‹ã‚‰å­¦ã‚“ã æ•™è¨“

### æ•™è¨“1: æ¤œè¨¼ãƒ„ãƒ¼ãƒ«ã®è½ã¨ã—ç©´
**å•é¡Œ**: ç©ºãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒ"é‡è¤‡ãªã—"ã¨åˆ¤å®šã•ã‚Œã‚‹
```python
# ãƒã‚°ã®ã‚ã‚‹æ¤œè¨¼ãƒ­ã‚¸ãƒƒã‚¯
if q['japanese'] == q2['japanese']:  # ä¸¡æ–¹ç©ºãªã‚‰ä¸€è‡´ã—ãªã„
    duplicates += 1
```

**è§£æ±ºç­–**: ç©ºãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’äº‹å‰ã«æ¤œå‡º
```python
# æ”¹å–„å¾Œ
if not q['japanese'].strip():
    raise ValueError(f"Empty japanese field in {q['id']}")
```

### æ•™è¨“2: ãƒ‡ãƒ¼ã‚¿ç ´æã®æ—©æœŸç™ºè¦‹
**å•é¡Œ**: G2ã®90%ãŒç©ºãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã ã£ãŸãŒæ°—ã¥ã‹ãªã‹ã£ãŸ

**è§£æ±ºç­–**: ç”Ÿæˆç›´å¾Œã«å……è¶³ç‡ãƒã‚§ãƒƒã‚¯
```python
def check_completeness(data):
    filled = sum(1 for q in questions if q['japanese'].strip())
    total = len(questions)
    rate = filled / total * 100
    
    if rate < 100:
        raise Warning(f"Completeness: {rate}% (expected 100%)")
```

### æ•™è¨“3: Unité–“ã®é‡è¤‡è¦‹è½ã¨ã—
**å•é¡Œ**: åŒã˜Unitã§ç•°ãªã‚‹å•é¡ŒIDãªã®ã«åŒã˜è‹±æ–‡

**è§£æ±ºç­–**: Unitå†…é‡è¤‡ã¨Unité–“é‡è¤‡ã‚’åˆ†ã‘ã¦æ¤œå‡º
```python
def detect_intra_unit_duplicates(unit):
    """Unitå†…é‡è¤‡"""
    sentences = [q['sentence'] for q in unit['questions']]
    return len(sentences) - len(set(sentences))

def detect_inter_unit_duplicates(all_units):
    """Unité–“é‡è¤‡"""
    all_sentences = []
    for unit in all_units:
        all_sentences.extend([q['sentence'] for q in unit['questions']])
    return len(all_sentences) - len(set(all_sentences))
```

---

## ğŸ› ï¸ æ¨å¥¨ãƒ„ãƒ¼ãƒ«æ§‹æˆ

### 1. ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
```bash
scripts/
â”œâ”€â”€ build_grade1_complete.py      # G1å…¨å•é¡Œç”Ÿæˆ
â”œâ”€â”€ build_grade2_complete.py      # G2å…¨å•é¡Œç”Ÿæˆ
â”œâ”€â”€ build_grade3_complete.py      # G3å…¨å•é¡Œç”Ÿæˆ
â””â”€â”€ rebuild_grade2_complete.py    # G2å†æ§‹ç¯‰ç”¨
```

### 2. æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
```bash
scripts/
â”œâ”€â”€ validate_grammar_v2.py        # é‡è¤‡ãƒ»ã‚¹ã‚­ãƒ¼ãƒæ¤œè¨¼
â”œâ”€â”€ check_completeness.py         # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å……è¶³ç‡
â””â”€â”€ cross_file_validator.py       # ãƒ•ã‚¡ã‚¤ãƒ«é–“æ•´åˆæ€§
```

### 3. ä¿®æ­£ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
```bash
scripts/
â”œâ”€â”€ fix_duplicates.py             # é‡è¤‡è‡ªå‹•ä¿®æ­£
â”œâ”€â”€ add_japanese_fields.py        # æ—¥æœ¬èªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰è¿½åŠ 
â””â”€â”€ diversify_patterns.py         # ãƒ‘ã‚¿ãƒ¼ãƒ³å¤šæ§˜åŒ–
```

---

## ğŸ“ˆ å“è³ªå‘ä¸Šã®è»Œè·¡

### Phase 1: åˆæœŸç”Ÿæˆ
- G1/G2/G3ã‚’ä¸€æ‹¬ç”Ÿæˆ
- å•é¡Œ: é‡è¤‡å¤šæ•°ã€ä¸€éƒ¨ãƒ‡ãƒ¼ã‚¿ç ´æ

### Phase 2: G3æ”¹å–„
- 160xé‡è¤‡ã‚’æ¤œå‡º
- Units 3-9ã‚’å¤šæ§˜åŒ–
- çµæœ: 98.75%æ”¹å–„ (160x â†’ 2x)

### Phase 3: G1å®Œå…¨åŒ–
- 2xé‡è¤‡ã‚’å€‹åˆ¥ä¿®æ­£
- é¡ä¼¼æ–‡ã‚’å®Œå…¨ã«åˆ¥ã®ä¾‹æ–‡ã«å¤‰æ›´
- çµæœ: 100%å“è³ªé”æˆ (0é‡è¤‡)

### Phase 4: G2å¾©æ—§
- 90%ãƒ‡ãƒ¼ã‚¿ç ´æã‚’ç™ºè¦‹
- å®Œå…¨å†æ§‹ç¯‰ (600å•ç”Ÿæˆ)
- Unit 5ã®5ç®‡æ‰€é‡è¤‡ã‚’ä¿®æ­£
- çµæœ: 100%å“è³ªé”æˆ

### æœ€çµ‚çŠ¶æ…‹
- **G1**: 0é‡è¤‡ (100%)
- **G2**: 0é‡è¤‡ (100%)
- **G3**: 2é‡è¤‡ (99.8%)
- **ç·è¨ˆ**: 1800å•ä¸­2é‡è¤‡ (99.9%å“è³ª)

---

## ğŸ¯ ä»Šå¾Œã®å±•é–‹

### è‡ªå‹•åŒ–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
```yaml
# CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä¾‹
grammar_quality_pipeline:
  stages:
    - generate:
        script: python3 scripts/build_grade{1-3}_complete.py
        
    - validate:
        script: |
          python3 scripts/validate_grammar_v2.py
          python3 scripts/check_completeness.py
          
    - quality_gate:
        rules:
          - uniqueness >= 99%
          - completeness == 100%
          - duplicates <= 5
          
    - deploy:
        on_success:
          - git commit -m "Auto-generated grammar questions"
          - git push origin main
```

### AIã‚¢ã‚·ã‚¹ãƒˆç”Ÿæˆ
```python
def generate_with_llm(grammar_point, count=20):
    """
    LLMã‚’ä½¿ã£ãŸå•é¡Œç”Ÿæˆ:
    1. æ–‡æ³•ãƒã‚¤ãƒ³ãƒˆã‚’æŒ‡å®š
    1. å¤šæ§˜æ€§ã®åˆ¶ç´„ã‚’è¿½åŠ 
    1. æ—¢å­˜å•é¡Œã¨ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯
    1. å“è³ªæ¤œè¨¼å¾Œã«æ¡ç”¨
    """
    prompt = f"""
    Create {count} unique English grammar questions for {grammar_point}.
    Requirements:
    - All sentences must be unique
    - Use diverse vocabulary
    - Avoid similar sentence structures
    - Include Japanese translations
    """
    # LLMå‘¼ã³å‡ºã— + æ¤œè¨¼
```

---

## ğŸ“š å‚è€ƒè³‡æ–™

### æˆåŠŸäº‹ä¾‹
- [G3 Units 3-9å¤šæ§˜åŒ–](../scripts/diversify_g3_units_8to9.py)
- [G1é‡è¤‡è§£æ¶ˆ](git show 1f50ccb)
- [G2å®Œå…¨å†æ§‹ç¯‰](../scripts/rebuild_grade2_complete.py)

### å¤±æ•—äº‹ä¾‹ã¨å¯¾ç­–
- G2ãƒ‡ãƒ¼ã‚¿ç ´æ â†’ å……è¶³ç‡ãƒã‚§ãƒƒã‚¯ã®è¿½åŠ 
- æ¤œè¨¼ãƒ„ãƒ¼ãƒ«ã®ç›²ç‚¹ â†’ ç©ºãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ¤œå‡ºã®å¼·åŒ–
- Unité–“é‡è¤‡ â†’ ã‚¯ãƒ­ã‚¹ãƒ¦ãƒ‹ãƒƒãƒˆæ¤œè¨¼ã®å®Ÿè£…

---

## âœ… ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆã‚¬ã‚¤ãƒ‰

### æ–°ã—ã„æ–‡æ³•å•é¡Œã‚’ä½œæˆã™ã‚‹å ´åˆ

1. **ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ã‚³ãƒ”ãƒ¼**
```bash
cp scripts/rebuild_grade2_complete.py scripts/build_new_grammar.py
```

1. **æ–‡æ³•ãƒã‚¤ãƒ³ãƒˆã‚’å®šç¾©**
```python
def build_unit0_your_grammar():
    patterns = [
        ("æ—¥æœ¬èª1", "English 1 ____.", "answer1"),
        # ... 20ãƒ‘ã‚¿ãƒ¼ãƒ³
    ]
```

1. **ç”Ÿæˆå®Ÿè¡Œ**
```bash
python3 scripts/build_new_grammar.py
```

1. **æ¤œè¨¼å®Ÿè¡Œ**
```bash
python3 scripts/validate_grammar_v2.py public/data/your-grammar.json
```

1. **å“è³ªç¢ºèª**
- ãƒ¦ãƒ‹ãƒ¼ã‚¯åº¦ â‰¥ 99%
- å®Œå…¨æ€§ = 100%
- é‡è¤‡ â‰¤ 2

1. **ãƒ‡ãƒ—ãƒ­ã‚¤**
```bash
git add public/data/your-grammar.json
git commit -m "Add new grammar: [æ–‡æ³•å] ([å•é¡Œæ•°]å•, [ãƒ¦ãƒ‹ãƒ¼ã‚¯åº¦]%)"
git push
```

---

## ğŸ” ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### Q1: é‡è¤‡ãŒå¤šã„å ´åˆ
**å¯¾ç­–**: èªå½™ãƒªã‚¹ãƒˆã‚’æ‹¡å……ã—ã€æ–‡è„ˆã‚’å¤šæ§˜åŒ–
```python
subjects = ["I", "You", "He", "She", "We", "They", "Tom", "Mary", "The dog", ...]
verbs = ["study", "work", "play", "read", "write", "sing", ...]
```

### Q2: æ—¥æœ¬èªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒç©ºã®å ´åˆ
**å¯¾ç­–**: ãƒ‘ã‚¿ãƒ¼ãƒ³é…åˆ—ã«å¿…ãšæ—¥æœ¬èªã‚’å«ã‚ã‚‹
```python
# å¿…ãš3è¦ç´ ã‚¿ãƒ—ãƒ«
patterns = [
    ("æ—¥æœ¬èª", "English", "answer"),  # âœ“ æ­£ã—ã„
    ("English", "answer"),            # âœ— é–“é•ã„
]
```

### Q3: ãƒ•ã‚¡ã‚¤ãƒ«é–“ã§ä¸æ•´åˆãŒç™ºç”Ÿ
**å¯¾ç­–**: verb-formã‚’ãƒã‚¹ã‚¿ãƒ¼ã¨ã—ã€ä»–ã‚’è‡ªå‹•ç”Ÿæˆ
```python
fb_data = create_fill_in_blank_from_verb_form(vf_data)
so_data = create_sentence_ordering_from_verb_form(vf_data)
```

---

## ğŸ“Š å“è³ªãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ (ä¾‹)

```
=== Grammar Quality Report ===

G1 (ä¸­1):
  âœ“ Total: 600 questions
  âœ“ Unique: 600/600 (100.0%)
  âœ“ Completeness: 100%
  âœ“ Status: EXCELLENT

G2 (ä¸­2):
  âœ“ Total: 600 questions
  âœ“ Unique: 600/600 (100.0%)
  âœ“ Completeness: 100%
  âœ“ Status: EXCELLENT

G3 (ä¸­3):
  âœ“ Total: 600 questions
  âœ“ Unique: 598/600 (99.8%)
  âœ“ Completeness: 100%
  âš  Status: VERY GOOD (2 duplicates)

Overall:
  âœ“ Total: 1800 questions
  âœ“ Unique: 1798/1800 (99.9%)
  âœ“ Completeness: 100%
  âœ“ Status: EXCELLENT
```

---

## ğŸ“ ã¾ã¨ã‚

ã“ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§:
1. **é«˜å“è³ªãªå•é¡Œã‚’åŠ¹ç‡çš„ã«ç”Ÿæˆ**ã§ãã‚‹
1. **ãƒ‡ãƒ¼ã‚¿ç ´æã‚’æ—©æœŸã«æ¤œå‡º**ã§ãã‚‹
1. **ç¶™ç¶šçš„ãªå“è³ªæ”¹å–„**ãŒå¯èƒ½
1. **å†ç¾å¯èƒ½ãªãƒ—ãƒ­ã‚»ã‚¹**ã‚’ç¢ºç«‹

**å“è³ªã®éµ**: ç”Ÿæˆ â†’ æ¤œè¨¼ â†’ ä¿®æ­£ â†’ å†æ¤œè¨¼ã®ã‚µã‚¤ã‚¯ãƒ«ã‚’å¾¹åº•ã™ã‚‹ã“ã¨
