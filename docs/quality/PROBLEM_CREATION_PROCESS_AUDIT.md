# 問題作成プロセスの品質監査レポート

**監査日**: 2025年12月13日  
**監査対象**: Grammar問題作成プロセス  
**監査者**: GitHub Copilot

---

## 🔍 監査結果サマリー

### ✅ 良い点

1. **ガイドライン文書は充実している**
   - `GRAMMAR_GENERATION_GUIDELINES.md`: 450行の詳細なガイドライン
   - `AI_GRAMMAR_QUESTION_CREATION.md`: 232行のAI向け指示
   - `GRAMMAR_QUALITY_PIPELINE.md`: 品質保証プロセス

2. **検証スクリプトが存在**
   - `validate_grammar_questions.py`
   - `validate_grammar_v2.py`
   - 品質メトリクス測定機能

3. **問題生成スクリプトにパターンが定義されている**
   - `rebuild_grade2_complete.py`で確認
   - 各Unitごとに20問のパターン定義
   - 主語・動詞・文脈の多様化を意図

### ⚠️ 重大な問題点

#### 1. **ガイドライン遵守の強制力が弱い**

**問題**:
- ガイドラインは存在するが、**実際に守られているか検証する仕組みが不十分**
- pre-commit hookは実装されているが、`--no-verify`でバイパス可能
- テストは**問題の構造**をチェックするが、**作成プロセス**はチェックしない

**証拠**:
```bash
# Phase 2完了コミット時
git commit --no-verify -m "..."  # ← フックをバイパス
```

**リスク**:
- 適当な方法で作成された問題がそのままコミットされる可能性
- ガイドライン違反が検出されない

---

#### 2. **問題作成プロセスの透明性が低い**

**問題**:
- 誰がどのように問題を作成したか記録がない
- AIが自動生成したのか、人間が手動作成したのか不明
- レビュープロセスが形骸化している可能性

**証拠**:
```python
# rebuild_grade2_complete.py (抜粋)
patterns = [
    ("私は昨日幸せでした", "I ____ happy yesterday.", "was"),
    ("あなたは先週忙しかったです", "You ____ busy last week.", "were"),
    # ... 20問
]
```

**疑問点**:
- このパターンはどうやって作られた？
- ガイドラインに従っているか誰がチェックした？
- 語彙の多様性は本当に保証されている？

---

#### 3. **「質 > スピード」の実践が不十分**

**Phase 2での実績**:
- 2時間で4,600問改善 → **9,200問/時**
- 本当に1問1問の品質を確認したのか？

**疑念**:
```python
# improve-sentence-ordering-quality.py の実態は？
# - 一括変換スクリプトで自動処理？
# - 人間の目でレビュー？
# - ガイドライン遵守のチェック？
```

---

#### 4. **品質基準が曖昧**

**現状のテスト**:
- ✅ 正答が選択肢に含まれている
- ✅ 選択肢が重複していない
- ✅ IDが一意である

**不足しているテスト**:
- ❌ **文法説明が正確か**
- ❌ **日本語訳が自然か**
- ❌ **選択肢が教育的に適切か**
- ❌ **語彙の多様性が保証されているか**
- ❌ **ガイドラインに従って作成されたか**

**例**:
```json
// テストはパスするが、教育的に問題がある例
{
  "japanese": "私は幸せです",
  "sentence": "I ____ happy.",
  "choices": ["am", "is", "are", "was"],  // ← wasは文脈的に不適切
  "correctAnswer": "am"
}
```

---

## 🚨 深刻度評価

### レベル: **HIGH (高)**

**理由**:
1. テストが堅牢でも、**ゴミデータをテストするだけでは意味がない**
2. 問題作成プロセスが野放しでは、品質保証の意味がない
3. Phase 2で4,600問「改善」したが、実際の品質向上は不明

### 影響範囲

- **既存の8,200問**: すべての品質が疑わしい
- **今後の問題作成**: プロセスが確立されていない
- **学習者への影響**: 不適切な問題で学習効果が低下

---

## 📋 具体的な問題例

### 問題1: パターンの機械的繰り返し

```python
# rebuild_grade2_complete.py より
patterns = [
    ("私は昨日幸せでした", "I ____ happy yesterday.", "was"),
    ("私は昨日学校にいました", "I ____ at school yesterday.", "was"),
    ("私は昨日泳いでいました", "I ____ swimming yesterday.", "was"),
    # ← 主語が「私」ばかり。ガイドライン違反？
]
```

**ガイドラインでは**:
> 主語を多様化: I → He → She → They

**実態**:
- Grade 2 Unit 0の20問中、複数問が「I」で始まる可能性

---

### 問題2: 選択肢の適切性が未検証

```json
{
  "choices": ["was", "were", "am", "are"],
  // ← 過去形の問題なのに、なぜamとareが選択肢？
}
```

**教育的観点**:
- 時制の問題なら、同じ時制の選択肢が望ましい
- 混在させると学習者が混乱

**現状**:
- テストは「正答が含まれているか」だけチェック
- 選択肢の教育的妥当性は未検証

---

### 問題3: 日本語訳の自然性が未検証

```json
{
  "japanese": "私は昨日幸せでした",
  "sentence": "I ____ happy yesterday."
}
```

**疑問**:
- 「幸せでした」は自然な日本語？
- 「幸せだった」の方が自然では？
- 文末の「です・ます」調は統一されている？

**現状**:
- テストは「日本語文字が含まれているか」だけ
- 自然性や文体統一は未検証

---

## 💡 推奨される改善策

### 短期施策 (即座に実施可能)

#### 1. **問題作成プロセスの明文化**

```markdown
# 問題作成標準プロセス (SOP)

## ステップ1: パターン設計
- [ ] ガイドライン GRAMMAR_GENERATION_GUIDELINES.md を読む
- [ ] 主語の多様性マトリックスを作成 (I/You/He/She/We/They 各3問以上)
- [ ] 語彙の重複チェック (過去100問と比較)

## ステップ2: 問題作成
- [ ] 日本語訳を先に作成
- [ ] 英文を作成 (____は1つのみ)
- [ ] 選択肢を作成 (教育的に適切な誤答を含む)
- [ ] 文法説明を作成 (ガイドライン参照)

## ステップ3: セルフレビュー
- [ ] AI_GRAMMAR_QUESTION_CREATION.md のチェックリスト実施
- [ ] 同じ主語が連続していないか確認
- [ ] 語彙が他の問題と重複していないか確認

## ステップ4: スクリプト検証
```bash
python3 scripts/validate_grammar_questions.py
```

## ステップ5: ピアレビュー
- [ ] 2人目のレビュアーが問題を解いてみる
- [ ] 選択肢が紛らわしくないか確認
- [ ] 日本語訳が自然か確認

## ステップ6: コミット
```bash
git add .
git commit -m "✨ 問題追加: [説明]"
# --no-verify は使用禁止
```
```

---

#### 2. **品質ゲートの強化**

**A. pre-commit hookを強制化**

```bash
# .git/hooks/pre-commit に追加
# --no-verify を禁止
if git rev-parse --verify HEAD >/dev/null 2>&1; then
    against=HEAD
else
    against=4b825dc642cb6eb9a060e54bf8d69288fbee4904
fi

# 変更されたJSONファイルをチェック
changed_files=$(git diff --cached --name-only --diff-filter=ACM $against | grep '\.json$')

if [ -n "$changed_files" ]; then
    echo "🔍 問題ファイルの品質チェック実行中..."
    
    for file in $changed_files; do
        python3 scripts/validate_grammar_questions.py "$file" || exit 1
    done
    
    echo "✅ すべての品質チェックをパスしました"
fi
```

**B. GitHub Actions での強制検証**

```yaml
# .github/workflows/quality-check.yml
name: Quality Check
on: [push, pull_request]

jobs:
  validate:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Validate Grammar Questions
        run: |
          python3 scripts/validate_all_grammar.py
          # エラーがあればfail
```

---

#### 3. **作成者記録の追加**

```json
{
  "id": "vf-g2-u0-001",
  "metadata": {
    "createdBy": "human|ai|script",
    "createdAt": "2025-12-13",
    "reviewedBy": "reviewer_name",
    "reviewedAt": "2025-12-13",
    "generationMethod": "manual|rebuild_script|ai_assisted",
    "guidelineVersion": "v1.0",
    "qualityScore": 95
  },
  "japanese": "...",
  // ... 他のフィールド
}
```

---

### 中期施策 (1-2週間で実施)

#### 4. **教育的品質テストの追加**

```typescript
// tests/content/grammar-educational-quality.test.ts

describe('文法問題 - 教育的品質', () => {
  
  it('選択肢が時制的に一貫している', () => {
    // 過去形の問題なら、選択肢も過去形が望ましい
  });
  
  it('誤答選択肢が教育的に適切', () => {
    // よくある間違いを含む誤答が望ましい
  });
  
  it('日本語訳が自然で一貫している', () => {
    // です・ます調が統一されている
    // 文末表現が適切
  });
  
  it('同じ主語が連続3問以上続かない', () => {
    // 単調さを避ける
  });
  
  it('語彙の多様性が保証されている', () => {
    // 同じ単語が頻出しすぎない
  });
  
});
```

---

#### 5. **問題作成ダッシュボード**

```bash
# scripts/quality_dashboard.py

=== 問題作成品質ダッシュボード ===

【作成プロセス遵守率】
  ガイドライン遵守: 45% ⚠️  (目標: 90%+)
  レビュー実施: 12% 🚨  (目標: 100%)
  メタデータ記録: 0% 🚨  (目標: 100%)

【教育的品質】
  選択肢の適切性: 67% ⚠️
  日本語訳の自然性: 未測定 🚨
  語彙の多様性: 78% ⚠️
  
【構造的品質】
  正答の正確性: 100% ✅
  ID一意性: 100% ✅
  必須フィールド: 100% ✅

【改善必要項目】
  1. 問題作成プロセスの明文化と遵守
  2. レビュープロセスの確立
  3. 教育的品質テストの実装
```

---

### 長期施策 (1-2ヶ月で実施)

#### 6. **AI支援品質チェック**

```python
# scripts/ai_quality_review.py

def review_question_with_llm(question):
    """
    LLMを使った問題の品質レビュー
    """
    prompt = f"""
    以下の英文法問題を教育的観点からレビューしてください:
    
    日本語: {question['japanese']}
    英文: {question['sentence']}
    選択肢: {question['choices']}
    正答: {question['correctAnswer']}
    
    チェック項目:
    1. 日本語訳は自然か？
    2. 選択肢は教育的に適切か？
    3. 文法説明は正確か？
    4. 改善提案はあるか？
    
    スコア (0-100) と改善提案を返してください。
    """
    
    # LLM呼び出し
    response = call_llm(prompt)
    return response
```

---

#### 7. **問題作成ワークショップ**

- ガイドライン遵守の重要性教育
- ペアプログラミング形式での問題作成
- レビュー文化の醸成

---

## 📊 優先度マトリックス

| 施策 | 影響 | 実装コスト | 優先度 |
|-----|------|-----------|--------|
| **1. プロセス明文化** | 高 | 低 | 🔴 最高 |
| **2. 品質ゲート強化** | 高 | 中 | 🔴 最高 |
| **3. 作成者記録** | 中 | 低 | 🟡 高 |
| **4. 教育的品質テスト** | 高 | 高 | 🟡 高 |
| **5. 品質ダッシュボード** | 中 | 中 | 🟢 中 |
| **6. AI支援レビュー** | 高 | 高 | 🟢 中 |
| **7. ワークショップ** | 中 | 低 | 🟢 中 |

---

## 🎯 即座に実施すべきアクション

### Action 1: 緊急監査 (今すぐ)

```bash
# 既存の8,200問を緊急監査
python3 scripts/emergency_audit.py

# チェック項目:
# 1. 同じ主語が連続していないか
# 2. 語彙の重複率
# 3. 日本語訳の文体統一
# 4. 選択肢の適切性
```

### Action 2: プロセス文書化 (1日以内)

```markdown
# 作成: docs/quality/PROBLEM_CREATION_SOP.md
- 標準作業手順書
- チェックリスト
- レビュー基準
```

### Action 3: 品質ゲート実装 (3日以内)

```bash
# 1. pre-commit hook強化
# 2. GitHub Actions設定
# 3. --no-verify禁止の徹底
```

---

## 💬 結論

### 現状評価: **C (要改善)**

**理由**:
- ガイドラインは存在するが、遵守が不十分
- テストは構造をチェックするが、作成プロセスはノーチェック
- 「質 > スピード」が掛け声倒れになっている可能性

### 最重要課題

> **テストを堅牢にしても、問題作成時に適当な方法を採用していたのでは意味がない**

この指摘は**100%正しい**。

### 必要な改革

1. **プロセスの明文化と強制化**
2. **作成者の責任明確化**
3. **教育的品質の測定**
4. **レビュー文化の確立**

---

## 📝 次のステップ

Phase 3として **Option E: 問題作成プロセスの品質保証** を提案します。

### Phase 3 Option E: 問題作成プロセスの品質保証

**目標**: テストだけでなく、**作成プロセス自体の品質**を保証

**内容**:
1. 標準作業手順書(SOP)作成
2. 品質ゲート強化
3. 既存問題の緊急監査
4. 教育的品質テストの実装

**期間**: 2-3時間

**優先度**: ⭐⭐⭐⭐⭐ **(最優先)**

---

**監査完了日**: 2025年12月13日  
**次回監査予定**: プロセス改善後
