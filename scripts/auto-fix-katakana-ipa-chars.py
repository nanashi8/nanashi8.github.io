#!/usr/bin/env python3
"""
ã‚«ã‚¿ã‚«ãƒŠãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‹ã‚‰IPAè¨˜å·ã‚’é™¤å»ã™ã‚‹è‡ªå‹•ä¿®æ­£ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

KATAKANA_INVALID_CHARSã‚¨ãƒ©ãƒ¼ã‚’ä¿®æ­£:
- ã‚«ã‚¿ã‚«ãƒŠç™ºéŸ³ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«å«ã¾ã‚Œã‚‹IPAè¨˜å·ã‚’é™¤å»
- IPAè¨˜å·ãŒæ··å…¥ã—ã¦ã„ã‚‹å ´åˆã€ãã®æ–‡å­—ã‚’å‰Šé™¤ã—ã¦æ­£ã—ã„ã‚«ã‚¿ã‚«ãƒŠã®ã¿ã«ä¿®æ­£
"""

import csv
import re
from pathlib import Path

# IPAè¨˜å·ã®ã‚»ãƒƒãƒˆï¼ˆã‚«ã‚¿ã‚«ãƒŠã«å«ã¾ã‚Œã¦ã¯ã„ã‘ãªã„æ–‡å­—ï¼‰
IPA_SYMBOLS = set('É‘Ã¦É™É›ÉªÊŠÊŒaeiouÉ”ÉœÊ‰É’ÉÉÉšÉ˜É¨Ã¤ÅÉµÉËËˆËŒÎ¸Ã°ÊƒÊ’Å‹tdkgpbfvszmnlrjwhxyc Ê”É¹É¡É¾É«Ê.\\-[]() Ì©Ì¯Ì ÌªÌ¬Ì¥ÌÌˆÌŠÌšÍ¡Ê°Ê·')

def clean_katakana_field(katakana_text):
    """
    ã‚«ã‚¿ã‚«ãƒŠãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‹ã‚‰IPAè¨˜å·ã‚’é™¤å»
    
    Args:
        katakana_text: å…ƒã®ã‚«ã‚¿ã‚«ãƒŠãƒ†ã‚­ã‚¹ãƒˆ
    
    Returns:
        tuple: (cleaned_text, was_modified, removed_chars)
    """
    if not katakana_text:
        return katakana_text, False, set()
    
    original = katakana_text
    removed_chars = set()
    
    # å„æ–‡å­—ã‚’ãƒã‚§ãƒƒã‚¯
    cleaned = []
    for char in katakana_text:
        # IPAè¨˜å·ã®å ´åˆã®ã¿é™¤å»
        # ã‚«ã‚¿ã‚«ãƒŠã€ã‚¢ã‚¯ã‚»ãƒ³ãƒˆè¨˜å·ï¼ˆÌï¼‰ã€æ‹¬å¼§ã€ã‚¹ãƒšãƒ¼ã‚¹ã€ãƒã‚¤ãƒ•ãƒ³ã¯ä¿æŒ
        if char in IPA_SYMBOLS and char not in '() -':
            removed_chars.add(char)
            # IPAè¨˜å·ã¯å‰Šé™¤
            continue
        else:
            # ã‚«ã‚¿ã‚«ãƒŠã‚„è¨±å®¹æ–‡å­—ã¯ä¿æŒ
            cleaned.append(char)
    
    cleaned_text = ''.join(cleaned)
    was_modified = cleaned_text != original
    
    return cleaned_text, was_modified, removed_chars


def fix_katakana_ipa_chars(csv_path):
    """
    CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚«ã‚¿ã‚«ãƒŠãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‹ã‚‰IPAè¨˜å·ã‚’é™¤å»
    
    Args:
        csv_path: CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    
    Returns:
        int: ä¿®æ­£ã—ãŸè¡Œæ•°
    """
    csv_file = Path(csv_path)
    if not csv_file.exists():
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_path}")
        return 0
    
    # CSVã‚’èª­ã¿è¾¼ã¿
    with open(csv_file, 'r', encoding='utf-8') as f:
        rows = list(csv.reader(f))
    
    if len(rows) < 2:
        print(f"âš ï¸  ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {csv_path}")
        return 0
    
    header = rows[0]
    modified_count = 0
    modifications = []
    
    # å„è¡Œã‚’ãƒã‚§ãƒƒã‚¯
    for i, row in enumerate(rows[1:], start=2):
        if len(row) < 3:
            continue
        
        word = row[0]
        reading = row[1]
        meaning = row[2] if len(row) > 2 else ""
        
        # èª­ã¿ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‹ã‚‰æ‹¬å¼§å†…ã®ã‚«ã‚¿ã‚«ãƒŠã‚’æŠ½å‡º
        # å½¢å¼: "IPA (ã‚«ã‚¿ã‚«ãƒŠÌ)" ã¾ãŸã¯ "ã‚«ã‚¿ã‚«ãƒŠÌ"
        katakana_match = re.search(r'\(([^)]+)\)', reading)
        if katakana_match:
            katakana_part = katakana_match.group(1)
            cleaned, was_modified, removed = clean_katakana_field(katakana_part)
            
            if was_modified:
                # æ‹¬å¼§å†…ã®ã‚«ã‚¿ã‚«ãƒŠã‚’ç½®æ›
                new_reading = reading.replace(f'({katakana_part})', f'({cleaned})')
                rows[i-1][1] = new_reading
                modified_count += 1
                modifications.append({
                    'line': i,
                    'word': word,
                    'old': katakana_part,
                    'new': cleaned,
                    'removed': removed
                })
    
    if modified_count > 0:
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆ
        backup_file = csv_file.with_suffix('.csv.backup-ipa-chars')
        with open(backup_file, 'w', encoding='utf-8', newline='') as f:
            writer = csv.writer(f)
            writer.writerows(rows[:modified_count + 1] if modified_count < len(rows) else rows)
        
        # ä¿®æ­£å¾Œã®CSVã‚’æ›¸ãè¾¼ã¿
        with open(csv_file, 'w', encoding='utf-8', newline='') as f:
            writer = csv.writer(f)
            writer.writerows(rows)
        
        print(f"âœ… {csv_file.name}: {modified_count}ä»¶ä¿®æ­£")
        print(f"ğŸ“‹ ä¿®æ­£è©³ç´°:")
        for mod in modifications[:10]:  # æœ€åˆã®10ä»¶ã®ã¿è¡¨ç¤º
            removed_str = ', '.join(sorted(mod['removed']))
            print(f"  è¡Œ{mod['line']}: {mod['word']}")
            print(f"    å‰Šé™¤æ–‡å­—: {removed_str}")
            print(f"    å¤‰æ›´å‰: ({mod['old']})")
            print(f"    å¤‰æ›´å¾Œ: ({mod['new']})")
        
        if len(modifications) > 10:
            print(f"  ... ä»–{len(modifications) - 10}ä»¶")
    else:
        print(f"â„¹ï¸  {csv_file.name}: ä¿®æ­£ä¸è¦")
    
    return modified_count


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    base_dir = Path(__file__).parent.parent
    vocab_dir = base_dir / 'public' / 'data' / 'vocabulary'
    
    csv_files = [
        'high-school-entrance-words.csv',
        'high-school-entrance-phrases.csv',
        'high-school-intermediate-words.csv',
        'high-school-intermediate-phrases.csv'
    ]
    
    total_fixed = 0
    
    print("=" * 60)
    print("ã‚«ã‚¿ã‚«ãƒŠãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰IPAè¨˜å·é™¤å»ãƒ„ãƒ¼ãƒ«")
    print("=" * 60)
    print()
    
    for csv_file in csv_files:
        csv_path = vocab_dir / csv_file
        fixed = fix_katakana_ipa_chars(csv_path)
        total_fixed += fixed
        print()
    
    print("=" * 60)
    print(f"âœ… å®Œäº†: åˆè¨ˆ {total_fixed}ä»¶ ä¿®æ­£")
    print("=" * 60)


if __name__ == '__main__':
    main()
