#!/usr/bin/env python3
"""
ä¸­é »åº¦å˜èª(3-4å›å‡ºç¾)ã‚’ä¿®æ­£

æ‰‹å‹•ã§ä½œæˆã—ãŸè¾æ›¸ã‚’ä½¿ç”¨ã—ã¦ã€ä¸­é »åº¦ã®(è¦ç¢ºèª)å˜èªã‚’ä¿®æ­£ã—ã¾ã™ã€‚
"""

import json
from pathlib import Path

# ä¸­é »åº¦å˜èªã®è¾æ›¸ï¼ˆ3-4å›å‡ºç¾ï¼‰
MEDIUM_FREQUENCY_DICT = {
    # å‹•è©å½¢
    'greeting': 'æŒ¨æ‹¶ã™ã‚‹ãƒ»æŒ¨æ‹¶',
    'frightening': 'æã‚ã—ã„ãƒ»æ€–ãŒã‚‰ã›ã‚‹',
    'confused': 'æ··ä¹±ã—ãŸ',
    'donated': 'å¯„ä»˜ã—ãŸ',
    'chorused': 'åˆå”±ã—ãŸãƒ»å£°ã‚’æƒãˆã¦è¨€ã£ãŸ',
    'selected': 'é¸ã°ã‚ŒãŸ',
    'declared': 'å®£è¨€ã—ãŸ',
    'warning': 'è­¦å‘Šãƒ»è­¦å‘Šã™ã‚‹',
    'designated': 'æŒ‡å®šã•ã‚ŒãŸ',
    'frustrating': 'ã‚¤ãƒ©ã‚¤ãƒ©ã•ã›ã‚‹',
    'thrilled': 'ã‚ãã‚ãã—ãŸãƒ»èˆˆå¥®ã—ãŸ',
    'whispered': 'ã•ã•ã‚„ã„ãŸ',
    'recovered': 'å›å¾©ã—ãŸ',
    'spilled': 'ã“ã¼ã—ãŸ',
    'sighed': 'ãŸã‚æ¯ã‚’ã¤ã„ãŸ',
    'advised': 'åŠ©è¨€ã—ãŸ',
    'anticipated': 'äºˆæƒ³ã—ãŸ',
    'remarked': 'è¿°ã¹ãŸãƒ»æ„è¦‹ã‚’è¨€ã£ãŸ',
    'prompted': 'ä¿ƒã—ãŸ',
    'exemplified': 'ä¾‹è¨¼ã—ãŸ',
    'orbiting': 'è»Œé“ã‚’å›ã‚‹',
    'grabbing': 'ã¤ã‹ã‚€',
    'hiking': 'ãƒã‚¤ã‚­ãƒ³ã‚°ãƒ»ãƒã‚¤ã‚­ãƒ³ã‚°ã™ã‚‹',
    'published': 'å‡ºç‰ˆã•ã‚ŒãŸ',
    'pickled': 'æ¼¬ã‘ãŸãƒ»ãƒ”ã‚¯ãƒ«ã‚¹ã«ã—ãŸ',
    'concluded': 'çµè«–ã‚’å‡ºã—ãŸ',
    'enforced': 'æ–½è¡Œã—ãŸãƒ»å¼·åˆ¶ã—ãŸ',
    'accounting': 'ä¼šè¨ˆãƒ»èª¬æ˜',
    'proceed': 'é€²ã‚€ãƒ»ç¶šã‘ã‚‹',
    'elevated': 'é«˜ãã—ãŸãƒ»ä¸Šæ˜‡ã—ãŸ',
    
    # åè©å½¢
    'desserts': 'ãƒ‡ã‚¶ãƒ¼ãƒˆ',
    'decoration': 'è£…é£¾',
    'balls': 'ãƒœãƒ¼ãƒ«ãƒ»èˆè¸ä¼š',
    'transformation': 'å¤‰åŒ–ãƒ»å¤‰èº«',
    'kilometers': 'ã‚­ãƒ­ãƒ¡ãƒ¼ãƒˆãƒ«',
    'vegetation': 'æ¤ç”Ÿ',
    'destruction': 'ç ´å£Š',
    'champions': 'ãƒãƒ£ãƒ³ãƒ”ã‚ªãƒ³ãƒ»å„ªå‹è€…',
    'drivers': 'é‹è»¢æ‰‹ãƒ»æ¨é€²åŠ›',
    'prosperity': 'ç¹æ „',
    'branches': 'æãƒ»æ”¯åº—',
    'attempts': 'è©¦ã¿',
    'ideals': 'ç†æƒ³',
    'genius': 'å¤©æ‰',
    "humanity's": 'äººé¡ã®',
    'equations': 'æ–¹ç¨‹å¼',
    'colonization': 'æ¤æ°‘åœ°åŒ–',
    'collection': 'åé›†ãƒ»ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³',
    'preparedness': 'æº–å‚™æ…‹å‹¢',
    'permission': 'è¨±å¯',
    'crutches': 'æ¾è‘‰æ–',
    'hazards': 'å±é™º',
    'profession': 'è·æ¥­',
    'priority': 'å„ªå…ˆäº‹é …',
    'encompasses': 'åŒ…å«ã™ã‚‹',
    'publicity': 'å®£ä¼ãƒ»åºƒå ±',
    'props': 'å°é“å…·',
    'dozens': 'æ•°å',
    'nervousness': 'ç·Šå¼µ',
    "people's": 'äººã€…ã®',
    "who's": 'èª°ãŒ',
    'exhibition': 'å±•ç¤ºä¼š',
    'recognition': 'èªè­˜ãƒ»æ‰¿èª',
    'mirrors': 'é¡',
    'rockets': 'ãƒ­ã‚±ãƒƒãƒˆ',
    'lungs': 'è‚º',
    'circuits': 'å›è·¯',
    'scarcity': 'ä¸è¶³',
    'agencies': 'æ©Ÿé–¢ãƒ»ä»£ç†åº—',
    'fans': 'ãƒ•ã‚¡ãƒ³ãƒ»æ‰‡é¢¨æ©Ÿ',
    
    # å½¢å®¹è©å½¢
    'instant': 'å³åº§ã®',
    'destructive': 'ç ´å£Šçš„ãª',
    'rigorous': 'å³æ ¼ãª',
    'supportive': 'æ”¯æ´çš„ãª',
    'unpredictable': 'äºˆæ¸¬ã§ããªã„',
    'radioactive': 'æ”¾å°„æ€§ã®',
    'productive': 'ç”Ÿç”£çš„ãª',
    'resistant': 'è€æ€§ã®ã‚ã‚‹',
    'reliable': 'ä¿¡é ¼ã§ãã‚‹',
    'investment': 'æŠ•è³‡',
    'impressive': 'å°è±¡çš„ãª',
    'initiative': 'ä¸»å°æ¨©ãƒ»ç‡å…ˆ',
    'incurable': 'æ²»ç™‚ä¸å¯èƒ½ãª',
    'permanent': 'æ°¸ç¶šçš„ãª',
    'accountant': 'ä¼šè¨ˆå£«',
    'inevitable': 'é¿ã‘ã‚‰ã‚Œãªã„',
    'dependent': 'ä¾å­˜ã—ã¦ã„ã‚‹',
    'sensitive': 'æ•æ„Ÿãª',
    'predictable': 'äºˆæ¸¬å¯èƒ½ãª',
    'pleasant': 'å¿«é©ãª',
    
    # å‰¯è©å½¢
    'briefly': 'ç°¡æ½”ã«',
    'casually': 'ä½•æ°—ãªã',
    'intensely': 'æ¿€ã—ã',
    'overwhelmingly': 'åœ§å€’çš„ã«',
    'sympathetically': 'åŒæƒ…çš„ã«',
    'roughly': 'ãŠãŠã‚ˆã',
    
    # ãã®ä»–é‡è¦èª
    'narrator': 'èªã‚Šæ‰‹',
    'forgot': 'å¿˜ã‚ŒãŸ',
    'furniture': 'å®¶å…·',
    'gray': 'ç°è‰²',
    'hidden': 'éš ã‚ŒãŸ',
    'donate': 'å¯„ä»˜ã™ã‚‹',
    'perseverance': 'å¿è€',
    'theoretical': 'ç†è«–çš„ãª',
    'invisible': 'è¦‹ãˆãªã„',
    'cultivate': 'æ ½åŸ¹ã™ã‚‹ãƒ»é¤Šã†',
    'identical': 'åŒä¸€ã®',
    'melt': 'æº¶ã‘ã‚‹',
    'harm': 'å®³',
    'interact': 'ç›¸äº’ä½œç”¨ã™ã‚‹',
    'biological': 'ç”Ÿç‰©å­¦çš„ãª',
    'reinforce': 'å¼·åŒ–ã™ã‚‹',
    'discovery': 'ç™ºè¦‹',
    'lighter': 'ã‚ˆã‚Šè»½ã„',
    'photography': 'å†™çœŸæ’®å½±',
    'birth': 'èª•ç”Ÿ',
    'sustain': 'ç¶­æŒã™ã‚‹',
    'uncertainty': 'ä¸ç¢ºå®Ÿæ€§',
    'network': 'ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯',
    'respiratory': 'å‘¼å¸ã®',
    'absolute': 'çµ¶å¯¾çš„ãª',
    'promote': 'ä¿ƒé€²ã™ã‚‹',
    'military': 'è»ã®',
    'died': 'æ­»ã‚“ã ',
    'difficulty': 'å›°é›£',
    'historic': 'æ­´å²çš„ãª',
    'eager': 'ç†±å¿ƒãª',
    'update': 'æ›´æ–°',
    'flavor': 'é¢¨å‘³',
    'psychological': 'å¿ƒç†çš„ãª',
    'anytime': 'ã„ã¤ã§ã‚‚',
    'failure': 'å¤±æ•—',
    'fairy': 'å¦–ç²¾',
    'prop': 'æ”¯ãˆãƒ»å°é“å…·',
    'broke': 'å£Šã‚ŒãŸ',
    'onto': 'ã€œã®ä¸Šã«',
    'dramatic': 'åŠ‡çš„ãª',
    'chaotic': 'æ··æ²Œã¨ã—ãŸ',
    'discomfort': 'ä¸å¿«',
    'simulate': 'ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã™ã‚‹',
    'closer': 'ã‚ˆã‚Šè¿‘ã„',
    'galaxy': 'éŠ€æ²³',
    'ecology': 'ç”Ÿæ…‹å­¦',
    'rainforest': 'ç†±å¸¯é›¨æ—',
    'underwater': 'æ°´ä¸­ã®',
    'algae': 'è—»é¡',
}

def update_dictionary():
    """è¾æ›¸ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°"""
    dict_path = Path('public/data/dictionaries/reading-passages-dictionary.json')
    
    with open(dict_path, encoding='utf-8') as f:
        dictionary = json.load(f)
    
    updated = 0
    added = 0
    
    for word, meaning in MEDIUM_FREQUENCY_DICT.items():
        if word in dictionary:
            if dictionary[word].get('meaning') == '(è¦ç¢ºèª)':
                dictionary[word]['meaning'] = meaning
                dictionary[word]['source'] = 'medium-frequency-manual'
                updated += 1
        else:
            dictionary[word] = {
                'meaning': meaning,
                'source': 'medium-frequency-manual'
            }
            added += 1
    
    # ä¿å­˜
    with open(dict_path, 'w', encoding='utf-8') as f:
        json.dump(dictionary, f, ensure_ascii=False, indent=2)
    
    print(f'ğŸ“š è¾æ›¸æ›´æ–°: {updated}èª, æ–°è¦è¿½åŠ : {added}èª')
    return updated + added

def update_passage_files():
    """å…¨ãƒ‘ãƒƒã‚»ãƒ¼ã‚¸ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°"""
    passages_dir = Path('public/data/passages-phrase-learning')
    total_updates = 0
    file_count = 0
    
    for passage_file in sorted(passages_dir.glob('*.json')):
        with open(passage_file, encoding='utf-8') as f:
            data = json.load(f)
        
        file_updates = 0
        for phrase in data.get('phrases', []):
            for segment in phrase.get('segments', []):
                word = segment.get('word', '')
                
                if segment.get('meaning') == '(è¦ç¢ºèª)' and word in MEDIUM_FREQUENCY_DICT:
                    segment['meaning'] = MEDIUM_FREQUENCY_DICT[word]
                    file_updates += 1
        
        if file_updates > 0:
            # ä¿å­˜
            with open(passage_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            total_updates += file_updates
            file_count += 1
            print(f'  âœ… {passage_file.name}: {file_updates}ç®‡æ‰€')
    
    print(f'\nğŸ“„ ãƒ‘ãƒƒã‚»ãƒ¼ã‚¸æ›´æ–°: {file_count}ãƒ•ã‚¡ã‚¤ãƒ«, {total_updates}ç®‡æ‰€')
    return total_updates

def analyze_remaining():
    """æ®‹ã‚Šã®(è¦ç¢ºèª)ã‚’åˆ†æ"""
    dict_path = Path('public/data/dictionaries/reading-passages-dictionary.json')
    
    with open(dict_path, encoding='utf-8') as f:
        dictionary = json.load(f)
    
    total = len(dictionary)
    confirmed = sum(1 for word_entry in dictionary.values() if word_entry.get('meaning') != '(è¦ç¢ºèª)')
    unconfirmed = total - confirmed
    
    print(f'\nğŸ“Š è¾æ›¸ã®çŠ¶æ…‹:')
    print(f'  ç·å˜èªæ•°: {total}èª')
    print(f'  æ„å‘³ç¢ºå®š: {confirmed}èª ({confirmed/total*100:.1f}%)')
    print(f'  (è¦ç¢ºèª): {unconfirmed}èª ({unconfirmed/total*100:.1f}%)')
    
    # ãƒ‘ãƒƒã‚»ãƒ¼ã‚¸ã®çŠ¶æ…‹
    passages_dir = Path('public/data/passages-phrase-learning')
    unconfirmed_count = 0
    
    for f in passages_dir.glob('*.json'):
        data = json.load(open(f, encoding='utf-8'))
        for p in data.get('phrases', []):
            for s in p.get('segments', []):
                if s.get('meaning', '') == '(è¦ç¢ºèª)':
                    unconfirmed_count += 1
    
    print(f'\nğŸ“„ ãƒ‘ãƒƒã‚»ãƒ¼ã‚¸ã®çŠ¶æ…‹:')
    print(f'  (è¦ç¢ºèª)ç®‡æ‰€: {unconfirmed_count}ç®‡æ‰€')

def main():
    print('=' * 60)
    print('ä¸­é »åº¦å˜èª(3-4å›å‡ºç¾)ã‚’ä¿®æ­£')
    print('=' * 60)
    print()
    
    print(f'å¯¾è±¡: {len(MEDIUM_FREQUENCY_DICT)}èª\n')
    
    # è¾æ›¸ã‚’æ›´æ–°
    dict_updates = update_dictionary()
    print()
    
    # ãƒ‘ãƒƒã‚»ãƒ¼ã‚¸ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°
    passage_updates = update_passage_files()
    
    # çµæœåˆ†æ
    analyze_remaining()
    
    print()
    print('=' * 60)
    print(f'âœ… å®Œäº†: è¾æ›¸{dict_updates}èªã€ãƒ‘ãƒƒã‚»ãƒ¼ã‚¸{passage_updates}ç®‡æ‰€ã‚’æ›´æ–°')
    print('=' * 60)

if __name__ == '__main__':
    main()
