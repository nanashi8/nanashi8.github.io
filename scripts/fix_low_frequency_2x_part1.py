#!/usr/bin/env python3
"""
ä½é »åº¦å˜èª(2å›å‡ºç¾)ã‚’ä¿®æ­£ - Part 1

2å›å‡ºç¾ã®382èªã®ã†ã¡ã€æœ€åˆã®150èªã‚’å‡¦ç†ã—ã¾ã™ã€‚
"""

import json
from pathlib import Path

# 2å›å‡ºç¾å˜èªã®è¾æ›¸ Part 1 (150èª)
LOW_FREQUENCY_2X_PART1_DICT = {
    'adaptable': 'é©å¿œã§ãã‚‹',
    'administered': 'å®Ÿæ–½ã•ã‚ŒãŸãƒ»ç®¡ç†ã•ã‚ŒãŸ',
    'advancement': 'é€²æ­©',
    'advises': 'åŠ©è¨€ã™ã‚‹',
    'advisor': 'é¡§å•ãƒ»ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼',
    'advocated': 'ä¸»å¼µã—ãŸ',
    'aimed': 'ç›®æŒ‡ã—ãŸ',
    'aims': 'ç›®æŒ‡ã™ãƒ»ç›®çš„',
    'allegedly': 'ä¼ãˆã‚‰ã‚Œã‚‹ã¨ã“ã‚ã§ã¯',
    'amendments': 'ä¿®æ­£ãƒ»æ”¹æ­£',
    'anatomy': 'è§£å‰–å­¦',
    'apprenticeship': 'è¦‹ç¿’ã„åˆ¶åº¦',
    'approvingly': 'è³›æˆã—ã¦',
    'aptitude': 'é©æ€§',
    'arguably': 'ãŠãã‚‰ã',
    'argued': 'ä¸»å¼µã—ãŸ',
    'aristocratic': 'è²´æ—çš„ãª',
    'arose': 'ç”Ÿã˜ãŸ',
    'arrivals': 'åˆ°ç€',
    'asphalt': 'ã‚¢ã‚¹ãƒ•ã‚¡ãƒ«ãƒˆ',
    'assignments': 'èª²é¡Œ',
    'attainment': 'é”æˆ',
    'attentively': 'æ³¨æ„æ·±ã',
    'attorneys': 'å¼è­·å£«',
    'autonomy': 'è‡ªæ²»ãƒ»è‡ªå¾‹',
    "bachelor's": 'å­¦å£«å·',
    'backstage': 'èˆå°è£',
    'bell': 'é˜ãƒ»ãƒ™ãƒ«',
    'belt': 'ãƒ™ãƒ«ãƒˆ',
    'bins': 'ã‚´ãƒŸç®±',
    'births': 'å‡ºç”Ÿ',
    'bleaching': 'æ¼‚ç™½',
    'blessed': 'æµã¾ã‚ŒãŸ',
    'bloodstream': 'è¡€æµ',
    "body's": 'ä½“ã®',
    'booth': 'ãƒ–ãƒ¼ã‚¹',
    'boycotts': 'ãƒœã‚¤ã‚³ãƒƒãƒˆ',
    'broadened': 'åºƒã’ãŸ',
    'broth': 'ã‚¹ãƒ¼ãƒ—',
    'burdens': 'è² æ‹…',
    'cakes': 'ã‚±ãƒ¼ã‚­',
    'campfire': 'ã‚­ãƒ£ãƒ³ãƒ—ãƒ•ã‚¡ã‚¤ãƒ¤ãƒ¼',
    'campus': 'ã‚­ãƒ£ãƒ³ãƒ‘ã‚¹',
    'canals': 'é‹æ²³',
    'cancerous': 'ç™Œã®',
    'capacities': 'èƒ½åŠ›ãƒ»å®¹é‡',
    'cardboard': 'æ®µãƒœãƒ¼ãƒ«',
    'cashless': 'ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ¬ã‚¹',
    'caution': 'æ³¨æ„',
    'cheers': 'æ­“å£°ãƒ»ä¹¾æ¯',
    "children's": 'å­ä¾›ã®',
    'chips': 'ãƒãƒƒãƒ—ã‚¹ãƒ»ç ´ç‰‡',
    'chosen': 'é¸ã°ã‚ŒãŸ',
    'cleanliness': 'æ¸…æ½”ã•',
    'clicked': 'ã‚¯ãƒªãƒƒã‚¯ã—ãŸ',
    'closest': 'æœ€ã‚‚è¿‘ã„',
    'compensated': 'è£œå„Ÿã•ã‚ŒãŸ',
    'complained': 'ä¸å¹³ã‚’è¨€ã£ãŸ',
    'components': 'éƒ¨å“',
    'conclusions': 'çµè«–',
    'confronted': 'ç›´é¢ã—ãŸ',
    'connectivity': 'æ¥ç¶šæ€§',
    'considerations': 'è€ƒæ…®äº‹é …',
    'contaminated': 'æ±šæŸ“ã•ã‚ŒãŸ',
    'contemplated': 'ç†Ÿè€ƒã—ãŸ',
    'corridors': 'å»Šä¸‹',
    'cosmic': 'å®‡å®™ã®',
    'cows': 'ç‰›',
    'crazy': 'ç‹‚ã£ãŸãƒ»ãŠã‹ã—ã„',
    'criticized': 'æ‰¹åˆ¤ã—ãŸ',
    'curators': 'å­¦èŠ¸å“¡',
    'daunting': 'æ°—åŠ›ã‚’ãã˜ã',
    'daytime': 'æ˜¼é–“',
    'debris': 'ç ´ç‰‡ãƒ»ãŒã‚Œã',
    'decent': 'ã¾ã¨ã‚‚ãª',
    'decorative': 'è£…é£¾çš„ãª',
    'deer': 'é¹¿',
    'defeat': 'æ•—åŒ—',
    'degrade': 'åŠ£åŒ–ã•ã›ã‚‹',
    'deliberation': 'ç†Ÿè€ƒ',
    'delicate': 'ç¹Šç´°ãª',
    'delighted': 'å–œã‚“ã ',
    'depicting': 'æå†™ã™ã‚‹',
    'depression': 'æ†‚é¬±ãƒ»ä¸æ™¯æ°—',
    'depth': 'æ·±ã•',
    'describing': 'èª¬æ˜ã™ã‚‹',
    'desu': 'ã§ã™',
    'diagnosis': 'è¨ºæ–­',
    'dimension': 'æ¬¡å…ƒ',
    'disadvantage': 'ä¸åˆ©',
    'disappointing': 'ãŒã£ã‹ã‚Šã•ã›ã‚‹',
    'dismissing': 'å´ä¸‹ã™ã‚‹',
    'dispersed': 'åˆ†æ•£ã—ãŸ',
    'displace': 'ç§»å‹•ã•ã›ã‚‹',
    'disposable': 'ä½¿ã„æ¨ã¦ã®',
    'disrespectful': 'ç„¡ç¤¼ãª',
    'distinct': 'æ˜ç¢ºãª',
    'distinguish': 'åŒºåˆ¥ã™ã‚‹',
    'disturbances': 'å¦¨å®³',
    'divorce': 'é›¢å©š',
    'doctorates': 'åšå£«å·',
    'dominant': 'æ”¯é…çš„ãª',
    'dominate': 'æ”¯é…ã™ã‚‹',
    'drills': 'è¨“ç·´ãƒ»ãƒ‰ãƒªãƒ«',
    'dumplings': 'é¤ƒå­',
    'earned': 'ç¨¼ã„ã ',
    'economically': 'çµŒæ¸ˆçš„ã«',
    'educators': 'æ•™è‚²è€…',
    'effectiveness': 'æœ‰åŠ¹æ€§',
    'elders': 'å¹´é•·è€…',
    'elephants': 'è±¡',
    'elusive': 'ã¤ã‹ã¿ã©ã“ã‚ã®ãªã„',
    'encouragement': 'åŠ±ã¾ã—',
    'endured': 'è€ãˆãŸ',
    'engine': 'ã‚¨ãƒ³ã‚¸ãƒ³',
    'engineered': 'è¨­è¨ˆã•ã‚ŒãŸ',
    'envision': 'æƒ³åƒã™ã‚‹',
    'equitable': 'å…¬å¹³ãª',
    'esports': 'eã‚¹ãƒãƒ¼ãƒ„',
    'evil': 'æ‚ª',
    'examination': 'æ¤œæŸ»',
    'examined': 'èª¿ã¹ãŸ',
    'examines': 'èª¿ã¹ã‚‹',
    'exceeded': 'è¶…ãˆãŸ',
    'exceptional': 'ä¸¦å¤–ã‚ŒãŸ',
    'exile': 'è¿½æ”¾',
    'expectancies': 'æœŸå¾…',
    'expenses': 'è²»ç”¨',
    'experiential': 'çµŒé¨“çš„ãª',
    'experiment': 'å®Ÿé¨“',
    'external': 'å¤–éƒ¨ã®',
    'extraordinarily': 'ä¸¦å¤–ã‚Œã¦',
    'extraordinary': 'ä¸¦å¤–ã‚ŒãŸ',
    'fabric': 'ç¹”ç‰©',
    'fatal': 'è‡´å‘½çš„ãª',
    'feet': 'è¶³',
    'festive': 'ç¥ç¥­ã®',
    'fifteenth': '15ç•ªç›®',
    'fitness': 'ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹',
    'fixtures': 'å‚™å“',
    'flour': 'å°éº¦ç²‰',
    'flourish': 'ç¹æ „ã™ã‚‹',
    'fluid': 'æµä½“',
    'followers': 'ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼',
    'forehead': 'é¡',
    'forestry': 'æ—æ¥­',
    'fortunate': 'å¹¸é‹ãª',
    'fossilized': 'åŒ–çŸ³åŒ–ã—ãŸ',
    'fractured': 'éª¨æŠ˜ã—ãŸ',
    'fragments': 'ç ´ç‰‡',
    'framed': 'é¡ã«å…¥ã‚ŒãŸ',
}

def update_dictionary():
    """è¾æ›¸ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°"""
    dict_path = Path('public/data/dictionaries/reading-passages-dictionary.json')
    
    with open(dict_path, encoding='utf-8') as f:
        dictionary = json.load(f)
    
    updated = 0
    added = 0
    
    for word, meaning in LOW_FREQUENCY_2X_PART1_DICT.items():
        if word in dictionary:
            if dictionary[word].get('meaning') == '(è¦ç¢ºèª)':
                dictionary[word]['meaning'] = meaning
                dictionary[word]['source'] = 'low-frequency-2x-manual'
                updated += 1
        else:
            dictionary[word] = {
                'meaning': meaning,
                'source': 'low-frequency-2x-manual'
            }
            added += 1
    
    # ä¿å­˜
    with open(dict_path, 'w', encoding='utf-8') as f:
        json.dump(dictionary, f, ensure_ascii=False, indent=2)
    
    print(f'ğŸ“š è¾æ›¸æ›´æ–°: {updated}èª, æ–°è¦è¿½åŠ : {added}èª')
    return updated + added

def update_passage_files():
    """å…¨ãƒ‘ãƒƒã‚»ãƒ¼ã‚¸ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°"""
    passages_dir = Path('public/data/passages-phrase-learning')
    total_updates = 0
    file_count = 0
    
    for passage_file in sorted(passages_dir.glob('*.json')):
        with open(passage_file, encoding='utf-8') as f:
            data = json.load(f)
        
        file_updates = 0
        for phrase in data.get('phrases', []):
            for segment in phrase.get('segments', []):
                word = segment.get('word', '')
                
                if segment.get('meaning') == '(è¦ç¢ºèª)' and word in LOW_FREQUENCY_2X_PART1_DICT:
                    segment['meaning'] = LOW_FREQUENCY_2X_PART1_DICT[word]
                    file_updates += 1
        
        if file_updates > 0:
            # ä¿å­˜
            with open(passage_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            total_updates += file_updates
            file_count += 1
            print(f'  âœ… {passage_file.name}: {file_updates}ç®‡æ‰€')
    
    print(f'\nğŸ“„ ãƒ‘ãƒƒã‚»ãƒ¼ã‚¸æ›´æ–°: {file_count}ãƒ•ã‚¡ã‚¤ãƒ«, {total_updates}ç®‡æ‰€')
    return total_updates

def analyze_remaining():
    """æ®‹ã‚Šã®(è¦ç¢ºèª)ã‚’åˆ†æ"""
    dict_path = Path('public/data/dictionaries/reading-passages-dictionary.json')
    
    with open(dict_path, encoding='utf-8') as f:
        dictionary = json.load(f)
    
    total = len(dictionary)
    confirmed = sum(1 for entry in dictionary.values() if entry.get('meaning') != '(è¦ç¢ºèª)')
    unconfirmed = total - confirmed
    
    print(f'\nğŸ“Š è¾æ›¸ã®çŠ¶æ…‹:')
    print(f'  ç·å˜èªæ•°: {total}èª')
    print(f'  æ„å‘³ç¢ºå®š: {confirmed}èª ({confirmed/total*100:.1f}%)')
    print(f'  (è¦ç¢ºèª): {unconfirmed}èª ({unconfirmed/total*100:.1f}%)')
    
    # ç›®æ¨™é”æˆçŠ¶æ³
    target_95 = int(total * 0.95)
    shortage = target_95 - confirmed
    print(f'\nğŸ¯ ç›®æ¨™é”æˆçŠ¶æ³:')
    print(f'  ç›®æ¨™(95%): {target_95}èª')
    print(f'  ä¸è¶³: {shortage}èª')
    print(f'  é”æˆç‡: {confirmed/target_95*100:.1f}%')

def main():
    print('=' * 60)
    print('ä½é »åº¦å˜èª(2å›å‡ºç¾) Part 1/3')
    print('=' * 60)
    print()
    
    print(f'å¯¾è±¡: {len(LOW_FREQUENCY_2X_PART1_DICT)}èª\n')
    
    # è¾æ›¸ã‚’æ›´æ–°
    dict_updates = update_dictionary()
    print()
    
    # ãƒ‘ãƒƒã‚»ãƒ¼ã‚¸ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°
    passage_updates = update_passage_files()
    
    # çµæœåˆ†æ
    analyze_remaining()
    
    print()
    print('=' * 60)
    print(f'âœ… å®Œäº†: è¾æ›¸{dict_updates}èªã€ãƒ‘ãƒƒã‚»ãƒ¼ã‚¸{passage_updates}ç®‡æ‰€ã‚’æ›´æ–°')
    print('=' * 60)

if __name__ == '__main__':
    main()
