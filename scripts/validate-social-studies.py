#!/usr/bin/env python3
"""
ç¤¾ä¼šç§‘æ•™æCSVãƒ•ã‚¡ã‚¤ãƒ«ã®å“è³ªæ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ç”¨é€”ï¼š
- CSVãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®æ¤œè¨¼
- å¿…é ˆåˆ—ã®å­˜åœ¨ç¢ºèª
- å¹´ä»£å½¢å¼ã®æ¤œè¨¼ï¼ˆæ­´å²ã®ã¿å¿…é ˆï¼‰
- é›£æ˜“åº¦å€¤ã®å¦¥å½“æ€§ç¢ºèª
- é‡è¤‡ãƒã‚§ãƒƒã‚¯
- é–¢é€£åˆ†é‡ã®ä¸€è²«æ€§ç¢ºèª
- èª­ã¿ä»®åã®å¦¥å½“æ€§ç¢ºèª

ä½¿ç”¨ä¾‹ï¼š
python3 scripts/validate-social-studies.py local-data-packs/social-studies-sample.csv
python3 scripts/validate-social-studies.py local-data-packs/social-studies-sample.csv --verbose
python3 scripts/validate-social-studies.py local-data-packs/social-studies-sample.csv --output report.json
"""

import csv
import json
import re
import sys
from typing import List, Dict, Tuple
from dataclasses import dataclass, asdict
from pathlib import Path

# ===== å®šæ•° =====

REQUIRED_COLUMNS = [
    'èªå¥', 'èª­ã¿', 'äº‹é …', 'å•é¡Œæ–‡', 'èª¬æ˜', 'é–¢é€£äº‹é …',
    'é–¢é€£åˆ†é‡', 'é›£æ˜“åº¦', 'source', 'å¹´ä»£', 'é¸æŠè‚¢ç”Ÿæˆãƒ’ãƒ³ãƒˆ'
]

VALID_DIFFICULTIES = ['1', '2', '3', '4', '5']

VALID_RELATED_FIELDS = [
    'æ­´å²-å¤ä»£', 'æ­´å²-ä¸­ä¸–', 'æ­´å²-è¿‘ä¸–', 'æ­´å²-è¿‘ä»£', 'æ­´å²-ç¾ä»£',
    'åœ°ç†-æ—¥æœ¬', 'åœ°ç†-ä¸–ç•Œ', 'åœ°ç†-ç”£æ¥­', 'åœ°ç†-ç’°å¢ƒ',
    'å…¬æ°‘-æ”¿æ²»', 'å…¬æ°‘-çµŒæ¸ˆ', 'å…¬æ°‘-å›½éš›', 'å…¬æ°‘-äººæ¨©'
]

HIRAGANA_PATTERN = re.compile(r'^[ã-ã‚“ãƒ¼ã€ã€‚]+$')
YEAR_PATTERN = re.compile(r'^\d{4}$')

# ===== ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹ =====

@dataclass
class ValidationIssue:
    severity: str  # 'error', 'warning', 'info'
    line: int
    field: str
    message: str
    value: str = ''

@dataclass
class ValidationReport:
    file_path: str
    total_rows: int
    valid_rows: int
    issues: List[ValidationIssue]
    quality_score: int
    passed: bool

# ===== æ¤œè¨¼é–¢æ•° =====

def validate_headers(headers: List[str]) -> List[ValidationIssue]:
    """ãƒ˜ãƒƒãƒ€ãƒ¼æ¤œè¨¼"""
    issues = []
    
    # å¿…é ˆåˆ—ã®å­˜åœ¨ç¢ºèª
    for col in REQUIRED_COLUMNS:
        if col not in headers:
            issues.append(ValidationIssue(
                severity='error',
                line=1,
                field='header',
                message=f'å¿…é ˆåˆ—ã€Œ{col}ã€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“'
            ))
    
    # åˆ—é †ã®ç¢ºèªï¼ˆæ¨å¥¨ï¼‰
    for index, col in enumerate(REQUIRED_COLUMNS):
        if index < len(headers) and headers[index] != col:
            issues.append(ValidationIssue(
                severity='warning',
                line=1,
                field='header',
                message=f'åˆ—ã®é †åºãŒæ¨å¥¨ã¨ç•°ãªã‚Šã¾ã™ã€‚æœŸå¾…: {col}, å®Ÿéš›: {headers[index]}'
            ))
    
    return issues

def validate_row(row: Dict[str, str], line_number: int, all_rows: List[Dict[str, str]]) -> List[ValidationIssue]:
    """è¡Œãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼"""
    issues = []
    
    # 1. å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å­˜åœ¨ç¢ºèª
    if not row.get('èªå¥', '').strip():
        issues.append(ValidationIssue('error', line_number, 'èªå¥', 'èªå¥ãŒç©ºã§ã™'))
    
    if not row.get('å•é¡Œæ–‡', '').strip():
        issues.append(ValidationIssue('error', line_number, 'å•é¡Œæ–‡', 'å•é¡Œæ–‡ãŒç©ºã§ã™'))
    
    if not row.get('èª¬æ˜', '').strip():
        issues.append(ValidationIssue('error', line_number, 'èª¬æ˜', 'èª¬æ˜ãŒç©ºã§ã™'))
    
    # 2. èª­ã¿ä»®åã®æ¤œè¨¼
    yomi = row.get('èª­ã¿', '').strip()
    if yomi:
        if not HIRAGANA_PATTERN.match(yomi):
            issues.append(ValidationIssue(
                'warning', line_number, 'èª­ã¿',
                'èª­ã¿ä»®åã«ã²ã‚‰ãŒãªä»¥å¤–ã®æ–‡å­—ãŒå«ã¾ã‚Œã¦ã„ã¾ã™',
                yomi
            ))
    else:
        issues.append(ValidationIssue('warning', line_number, 'èª­ã¿', 'èª­ã¿ä»®åãŒç©ºã§ã™'))
    
    # 3. é›£æ˜“åº¦ã®æ¤œè¨¼
    difficulty = row.get('é›£æ˜“åº¦', '').strip()
    if difficulty not in VALID_DIFFICULTIES:
        issues.append(ValidationIssue(
            'error', line_number, 'é›£æ˜“åº¦',
            f'é›£æ˜“åº¦ã¯1-5ã®æ•´æ•°ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™',
            difficulty
        ))
    
    # 4. é–¢é€£åˆ†é‡ã®æ¤œè¨¼
    related_fields = row.get('é–¢é€£åˆ†é‡', '').strip()
    if related_fields:
        fields = [f.strip() for f in related_fields.split('|')]
        for field in fields:
            if field not in VALID_RELATED_FIELDS:
                issues.append(ValidationIssue(
                    'warning', line_number, 'é–¢é€£åˆ†é‡',
                    f'ä¸æ˜ãªé–¢é€£åˆ†é‡: {field}',
                    field
                ))
        
        # æ­´å²åˆ†é‡ã®å ´åˆã€å¹´ä»£ãŒå¿…é ˆ
        is_history = any(f.startswith('æ­´å²-') for f in fields)
        if is_history:
            year = row.get('å¹´ä»£', '').strip()
            if not year:
                issues.append(ValidationIssue(
                    'error', line_number, 'å¹´ä»£',
                    'æ­´å²åˆ†é‡ã®å•é¡Œã«ã¯å¹´ä»£ï¼ˆ4æ¡è¥¿æš¦ï¼‰ãŒå¿…é ˆã§ã™'
                ))
            elif not YEAR_PATTERN.match(year):
                issues.append(ValidationIssue(
                    'error', line_number, 'å¹´ä»£',
                    'å¹´ä»£ã¯4æ¡ã®è¥¿æš¦ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™',
                    year
                ))
            else:
                year_int = int(year)
                if year_int < 500 or year_int > 2100:
                    issues.append(ValidationIssue(
                        'warning', line_number, 'å¹´ä»£',
                        'å¹´ä»£ãŒæ¥µç«¯ãªå€¤ã§ã™ã€‚ç¢ºèªã—ã¦ãã ã•ã„',
                        year
                    ))
    else:
        issues.append(ValidationIssue('error', line_number, 'é–¢é€£åˆ†é‡', 'é–¢é€£åˆ†é‡ãŒç©ºã§ã™'))
    
    # 5. å•é¡Œæ–‡ã®å“è³ªãƒã‚§ãƒƒã‚¯
    question = row.get('å•é¡Œæ–‡', '')
    if len(question) < 10:
        issues.append(ValidationIssue(
            'warning', line_number, 'å•é¡Œæ–‡',
            'å•é¡Œæ–‡ãŒçŸ­ã™ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼ˆ10æ–‡å­—æœªæº€ï¼‰',
            question
        ))
    
    if 'ï¼Ÿ' not in question and '?' not in question:
        issues.append(ValidationIssue(
            'info', line_number, 'å•é¡Œæ–‡',
            'å•é¡Œæ–‡ã«ç–‘å•ç¬¦ï¼ˆï¼Ÿï¼‰ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“'
        ))
    
    # 6. èª¬æ˜æ–‡ã®å“è³ªãƒã‚§ãƒƒã‚¯
    explanation = row.get('èª¬æ˜', '')
    if len(explanation) < 20:
        issues.append(ValidationIssue(
            'warning', line_number, 'èª¬æ˜',
            'èª¬æ˜ãŒçŸ­ã™ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼ˆ20æ–‡å­—æœªæº€ï¼‰',
            explanation
        ))
    
    # 7. èªå¥ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯
    term = row.get('èªå¥', '')
    duplicates = [r for r in all_rows if r.get('èªå¥') == term]
    if len(duplicates) > 1:
        issues.append(ValidationIssue(
            'warning', line_number, 'èªå¥',
            f'èªå¥ã€Œ{term}ã€ãŒé‡è¤‡ã—ã¦ã„ã¾ã™ï¼ˆ{len(duplicates)}ä»¶ï¼‰'
        ))
    
    # 8. é¸æŠè‚¢ç”Ÿæˆãƒ’ãƒ³ãƒˆã®æ¤œè¨¼
    hints = row.get('é¸æŠè‚¢ç”Ÿæˆãƒ’ãƒ³ãƒˆ', '').strip()
    if hints:
        hint_list = [h.strip() for h in hints.split('|')]
        if len(hint_list) < 2:
            issues.append(ValidationIssue(
                'info', line_number, 'é¸æŠè‚¢ç”Ÿæˆãƒ’ãƒ³ãƒˆ',
                'é¸æŠè‚¢ç”Ÿæˆãƒ’ãƒ³ãƒˆã¯2ã¤ä»¥ä¸Šæ¨å¥¨ã§ã™ï¼ˆ|åŒºåˆ‡ã‚Šï¼‰'
            ))
    
    # 9. èªå¥ã¨èª¬æ˜ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
    if term and term not in explanation:
        issues.append(ValidationIssue(
            'info', line_number, 'èª¬æ˜',
            f'èª¬æ˜ã«èªå¥ã€Œ{term}ã€ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ï¼ˆç¢ºèªæ¨å¥¨ï¼‰'
        ))
    
    return issues

def calculate_quality_score(total_rows: int, errors: int, warnings: int, infos: int) -> int:
    """å“è³ªã‚¹ã‚³ã‚¢ã®è¨ˆç®—ï¼ˆ100ç‚¹æº€ç‚¹ï¼‰"""
    if total_rows == 0:
        return 0
    
    score = 100
    score -= errors * 10
    score -= warnings * 3
    score -= infos * 1
    
    return max(0, score)

def validate_file(file_path: str) -> ValidationReport:
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼"""
    issues = []
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            headers = reader.fieldnames or []
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼æ¤œè¨¼
            header_issues = validate_headers(headers)
            issues.extend(header_issues)
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Œã°ä¸­æ–­
            if any(i.severity == 'error' for i in header_issues):
                return ValidationReport(
                    file_path=file_path,
                    total_rows=0,
                    valid_rows=0,
                    issues=issues,
                    quality_score=0,
                    passed=False
                )
            
            # è¡Œãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨æ¤œè¨¼
            rows = list(reader)
            valid_rows = 0
            
            for index, row in enumerate(rows, start=2):  # ãƒ˜ãƒƒãƒ€ãƒ¼ãŒ1è¡Œç›®
                row_issues = validate_row(row, index, rows)
                issues.extend(row_issues)
                
                if not any(i.severity == 'error' for i in row_issues):
                    valid_rows += 1
            
            # ã‚µãƒãƒªãƒ¼è¨ˆç®—
            errors = sum(1 for i in issues if i.severity == 'error')
            warnings = sum(1 for i in issues if i.severity == 'warning')
            infos = sum(1 for i in issues if i.severity == 'info')
            
            quality_score = calculate_quality_score(len(rows), errors, warnings, infos)
            passed = quality_score >= 80 and errors == 0
            
            return ValidationReport(
                file_path=file_path,
                total_rows=len(rows),
                valid_rows=valid_rows,
                issues=issues,
                quality_score=quality_score,
                passed=passed
            )
    
    except Exception as e:
        issues.append(ValidationIssue('error', 0, 'file', f'ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}'))
        return ValidationReport(
            file_path=file_path,
            total_rows=0,
            valid_rows=0,
            issues=issues,
            quality_score=0,
            passed=False
        )

def display_report(report: ValidationReport, verbose: bool = False):
    """ãƒ¬ãƒãƒ¼ãƒˆã®è¡¨ç¤º"""
    print('=' * 42)
    print('ç¤¾ä¼šç§‘æ•™æå“è³ªæ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆ')
    print('=' * 42)
    print()
    print(f'ãƒ•ã‚¡ã‚¤ãƒ«: {report.file_path}')
    print(f'ç·è¡Œæ•°: {report.total_rows}')
    print(f'æœ‰åŠ¹è¡Œæ•°: {report.valid_rows}')
    print()
    
    errors = [i for i in report.issues if i.severity == 'error']
    warnings = [i for i in report.issues if i.severity == 'warning']
    infos = [i for i in report.issues if i.severity == 'info']
    
    print('å•é¡Œã‚µãƒãƒªãƒ¼:')
    print(f'  ã‚¨ãƒ©ãƒ¼: {len(errors)}')
    print(f'  è­¦å‘Š: {len(warnings)}')
    print(f'  æƒ…å ±: {len(infos)}')
    print()
    print(f'å“è³ªã‚¹ã‚³ã‚¢: {report.quality_score}/100')
    print(f'åˆ¤å®š: {"âœ… åˆæ ¼ï¼ˆ80ç‚¹ä»¥ä¸Šï¼‰" if report.passed else "âŒ ä¸åˆæ ¼ï¼ˆ80ç‚¹æœªæº€ã¾ãŸã¯ã‚¨ãƒ©ãƒ¼ã‚ã‚Šï¼‰"}')
    print()
    
    if report.issues:
        print('è©³ç´°:')
        print('-' * 42)
        
        if errors:
            print('\nğŸ”´ ã‚¨ãƒ©ãƒ¼:')
            for issue in errors:
                print(f'  [è¡Œ{issue.line}] {issue.field}: {issue.message}')
                if issue.value and verbose:
                    print(f'    å€¤: "{issue.value}"')
        
        if warnings:
            print('\nğŸŸ¡ è­¦å‘Š:')
            for issue in warnings:
                print(f'  [è¡Œ{issue.line}] {issue.field}: {issue.message}')
                if issue.value and verbose:
                    print(f'    å€¤: "{issue.value}"')
        
        if infos and verbose:
            print('\nâ„¹ï¸ æƒ…å ±:')
            for issue in infos:
                print(f'  [è¡Œ{issue.line}] {issue.field}: {issue.message}')
                if issue.value:
                    print(f'    å€¤: "{issue.value}"')
    else:
        print('âœ… å•é¡Œã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼')
    
    print()
    print('=' * 42)

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ç¤¾ä¼šç§‘æ•™æCSVãƒ•ã‚¡ã‚¤ãƒ«ã®å“è³ªæ¤œè¨¼')
    parser.add_argument('file', help='æ¤œè¨¼ã™ã‚‹CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹')
    parser.add_argument('--verbose', '-v', action='store_true', help='è©³ç´°è¡¨ç¤ºï¼ˆæƒ…å ±ãƒ¬ãƒ™ãƒ«ã®å•é¡Œã‚‚è¡¨ç¤ºï¼‰')
    parser.add_argument('--output', '-o', help='JSONå½¢å¼ã§ãƒ¬ãƒãƒ¼ãƒˆã‚’å‡ºåŠ›ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹')
    parser.add_argument('--strict', action='store_true', help='å³æ ¼ãƒ¢ãƒ¼ãƒ‰ï¼ˆè­¦å‘Šã‚‚ã‚¨ãƒ©ãƒ¼ã¨ã—ã¦æ‰±ã†ï¼‰')
    
    args = parser.parse_args()
    
    if not Path(args.file).exists():
        print(f'ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.file}', file=sys.stderr)
        sys.exit(1)
    
    report = validate_file(args.file)
    display_report(report, args.verbose)
    
    if args.output:
        output_data = {
            'file_path': report.file_path,
            'total_rows': report.total_rows,
            'valid_rows': report.valid_rows,
            'quality_score': report.quality_score,
            'passed': report.passed,
            'summary': {
                'errors': len([i for i in report.issues if i.severity == 'error']),
                'warnings': len([i for i in report.issues if i.severity == 'warning']),
                'infos': len([i for i in report.issues if i.severity == 'info'])
            },
            'issues': [asdict(i) for i in report.issues]
        }
        
        with open(args.output, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        print(f'ãƒ¬ãƒãƒ¼ãƒˆã‚’å‡ºåŠ›ã—ã¾ã—ãŸ: {args.output}')
    
    # çµ‚äº†ã‚³ãƒ¼ãƒ‰ï¼ˆCIã§ä½¿ç”¨å¯èƒ½ï¼‰
    if not report.passed:
        sys.exit(1)

if __name__ == '__main__':
    main()
