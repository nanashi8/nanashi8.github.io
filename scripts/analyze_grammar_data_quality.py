#!/usr/bin/env python3
"""
æ–‡æ³•å•é¡Œãƒ‡ãƒ¼ã‚¿ã®å“è³ªåˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ

çµ±è¨ˆæƒ…å ±ã‚’åé›†ã—ã€å“è³ªãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚
"""

import json
import re
from pathlib import Path
from collections import defaultdict
from typing import Dict, List

class GrammarDataQualityAnalyzer:
    def __init__(self):
        self.stats = {
            'total_files': 0,
            'enabled_files': 0,
            'disabled_files': 0,
            'total_questions': 0,
            'issues_found': 0,
            'issue_types': defaultdict(int),
            'files_with_issues': [],
        }
        
        # æ–‡æ³•ç”¨èªãƒ‘ã‚¿ãƒ¼ãƒ³
        self.grammar_term_patterns = [
            r'éå»é€²è¡Œå½¢', r'éå»å½¢', r'ç¾åœ¨é€²è¡Œå½¢', r'æœªæ¥å½¢',
            r'ä¸è¦å‰‡å‹•è©', r'ä¸€èˆ¬å‹•è©', r'beå‹•è©',
            r'åŠ©å‹•è©', r'ç–‘å•è©', r'æ¯”è¼ƒç´š', r'æœ€ä¸Šç´š',
            r'å—å‹•æ…‹', r'é–¢ä¿‚ä»£åè©', r'è¤‡æ•°å½¢',
            r'ä¸‰äººç§°', r'å¦å®šæ–‡', r'ç–‘å•æ–‡', r'å‘½ä»¤æ–‡',
            r'-ingå½¢', r'-ingã€‚', r'-edå½¢',
            r'[a-zA-Z]+ã®[^ã€‚ã€]+',
            r'\w+æ–‡[ï¼ˆ(]',
            r'^[^ã€‚]*\d+ã€‚$',
            r'ã‚’ä½¿ã†ã€‚$', r'ã‚’å–ã‚‹', r'ã‚’é‡ã­ã‚‹', r'ã‚’å¤‰ãˆã‚‹',
            r'ç©´åŸ‹ã‚\d+', r'ä¸¦ã¹æ›¿ãˆ\d+',
        ]
    
    def analyze_file(self, file_path: Path) -> Dict:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æ"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
        except Exception as e:
            return {'error': str(e)}
        
        file_stats = {
            'filename': file_path.name,
            'enabled': data.get('enabled', True),
            'question_count': 0,
            'issues': [],
        }
        
        self.stats['total_files'] += 1
        
        if data.get('enabled') is False:
            self.stats['disabled_files'] += 1
            return file_stats
        
        self.stats['enabled_files'] += 1
        
        # å•é¡Œã‚’åé›†
        questions = []
        if 'questions' in data:
            questions = data['questions']
        elif 'units' in data:
            for unit in data['units']:
                questions.extend(unit.get('questions', []))
        
        file_stats['question_count'] = len(questions)
        self.stats['total_questions'] += len(questions)
        
        # å„å•é¡Œã‚’åˆ†æ
        for q in questions:
            issues = self._analyze_question(q)
            if issues:
                file_stats['issues'].extend(issues)
                self.stats['issues_found'] += len(issues)
                for issue in issues:
                    self.stats['issue_types'][issue['type']] += 1
        
        if file_stats['issues']:
            self.stats['files_with_issues'].append(file_path.name)
        
        return file_stats
    
    def _analyze_question(self, q: Dict) -> List[Dict]:
        """å•é¡Œã‚’åˆ†æã—ã¦å•é¡Œç‚¹ã‚’ãƒªã‚¹ãƒˆåŒ–"""
        issues = []
        q_id = q.get('id', 'unknown')
        
        # 1. æ—¥æœ¬èªè¨³ã®æ–‡æ³•ç”¨èªãƒã‚§ãƒƒã‚¯
        if 'japanese' in q:
            japanese = q['japanese']
            for pattern in self.grammar_term_patterns:
                if re.search(pattern, japanese):
                    issues.append({
                        'type': 'grammar_term_in_japanese',
                        'question_id': q_id,
                        'description': f"æ—¥æœ¬èªè¨³ã«æ–‡æ³•ç”¨èªãŒå«ã¾ã‚Œã¦ã„ã‚‹: {japanese}",
                        'severity': 'high'
                    })
                    break
        
        # 2. ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼è‹±æ–‡ãƒã‚§ãƒƒã‚¯
        if 'sentence' in q:
            sentence = q['sentence']
            if 'Example sentence' in sentence or '____ blank' in sentence:
                issues.append({
                    'type': 'placeholder_sentence',
                    'question_id': q_id,
                    'description': f"ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼è‹±æ–‡: {sentence}",
                    'severity': 'high'
                })
        
        # 3. ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼é¸æŠè‚¢ãƒã‚§ãƒƒã‚¯
        if 'choices' in q:
            placeholder_choices = [c for c in q['choices'] if c in ['choice1', 'choice2', 'choice3']]
            if placeholder_choices:
                issues.append({
                    'type': 'placeholder_choices',
                    'question_id': q_id,
                    'description': f"ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼é¸æŠè‚¢: {placeholder_choices}",
                    'severity': 'high'
                })
        
        # 4. é¸æŠè‚¢ã¨æ­£è§£ã®ä¸ä¸€è‡´
        if 'correctAnswer' in q and 'choices' in q:
            if q['correctAnswer'] not in q['choices']:
                issues.append({
                    'type': 'answer_not_in_choices',
                    'question_id': q_id,
                    'description': f"æ­£è§£ãŒé¸æŠè‚¢ã«å«ã¾ã‚Œã¦ã„ãªã„: {q['correctAnswer']}",
                    'severity': 'critical'
                })
        
        # 5. beå‹•è©ã®ä¸»èªä¸ä¸€è‡´
        if 'sentence' in q and 'correctAnswer' in q:
            if q['correctAnswer'] in ['was', 'were']:
                match = re.match(r'^(\w+)\s+_{2,}', q['sentence'])
                if match:
                    subject = match.group(1)
                    if subject in ['I', 'He', 'She', 'It'] and q['correctAnswer'] == 'were':
                        issues.append({
                            'type': 'be_verb_mismatch',
                            'question_id': q_id,
                            'description': f"ä¸»èª{subject}ã«wereã¯ä¸æ­£",
                            'severity': 'high'
                        })
                    elif subject in ['You', 'We', 'They'] and q['correctAnswer'] == 'was':
                        issues.append({
                            'type': 'be_verb_mismatch',
                            'question_id': q_id,
                            'description': f"ä¸»èª{subject}ã«wasã¯ä¸æ­£",
                            'severity': 'high'
                        })
        
        # 6. ä¸å®šè©å•é¡Œã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
        if 'sentence' in q and 'correctAnswer' in q:
            if re.match(r'^To\s+_{2,}', q['sentence']):
                if q['correctAnswer'].lower().startswith('to '):
                    issues.append({
                        'type': 'infinitive_pattern_error',
                        'question_id': q_id,
                        'description': f"ä¸å®šè©å•é¡Œã§æ­£è§£ãŒ'to'ã‹ã‚‰å§‹ã¾ã‚‹: {q['correctAnswer']}",
                        'severity': 'high'
                    })
        
        return issues
    
    def generate_report(self) -> str:
        """å“è³ªãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        report = []
        report.append("=" * 80)
        report.append("æ–‡æ³•å•é¡Œãƒ‡ãƒ¼ã‚¿å“è³ªãƒ¬ãƒãƒ¼ãƒˆ")
        report.append("=" * 80)
        report.append("")
        
        # ã‚µãƒãƒªãƒ¼
        report.append("ğŸ“Š çµ±è¨ˆã‚µãƒãƒªãƒ¼")
        report.append("-" * 80)
        report.append(f"  ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {self.stats['total_files']}")
        report.append(f"  æœ‰åŠ¹ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {self.stats['enabled_files']}")
        report.append(f"  ç„¡åŠ¹ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {self.stats['disabled_files']}")
        report.append(f"  ç·å•é¡Œæ•°: {self.stats['total_questions']}")
        report.append(f"  æ¤œå‡ºã•ã‚ŒãŸå•é¡Œ: {self.stats['issues_found']}")
        report.append("")
        
        # å“è³ªã‚¹ã‚³ã‚¢
        if self.stats['total_questions'] > 0:
            quality_score = (1 - self.stats['issues_found'] / self.stats['total_questions']) * 100
            report.append(f"âœ¨ å“è³ªã‚¹ã‚³ã‚¢: {quality_score:.2f}%")
            report.append("")
        
        # å•é¡Œã‚¿ã‚¤ãƒ—åˆ¥ã®å†…è¨³
        if self.stats['issue_types']:
            report.append("ğŸ” å•é¡Œã‚¿ã‚¤ãƒ—åˆ¥å†…è¨³")
            report.append("-" * 80)
            for issue_type, count in sorted(self.stats['issue_types'].items(), key=lambda x: -x[1]):
                report.append(f"  {issue_type}: {count}ä»¶")
            report.append("")
        
        # å•é¡Œã®ã‚ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«
        if self.stats['files_with_issues']:
            report.append("âš ï¸  å•é¡Œã®ã‚ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«")
            report.append("-" * 80)
            for filename in self.stats['files_with_issues']:
                report.append(f"  â€¢ {filename}")
            report.append("")
        
        # çµè«–
        report.append("=" * 80)
        if self.stats['issues_found'] == 0:
            report.append("âœ… å…¨ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒå“è³ªåŸºæº–ã‚’æº€ãŸã—ã¦ã„ã¾ã™!")
        else:
            report.append(f"âŒ {self.stats['issues_found']}ä»¶ã®å•é¡ŒãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚")
            report.append("   ä¿®æ­£ãŒå¿…è¦ã§ã™ã€‚")
        report.append("=" * 80)
        
        return "\n".join(report)


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    analyzer = GrammarDataQualityAnalyzer()
    
    base_path = Path(__file__).parent.parent / 'public' / 'data' / 'grammar'
    
    print("ğŸ” æ–‡æ³•å•é¡Œãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æä¸­...\n")
    
    for file_path in sorted(base_path.glob('grammar_grade*.json')):
        if file_path.exists():
            file_stats = analyzer.analyze_file(file_path)
            if file_stats.get('issues'):
                print(f"âš ï¸  {file_path.name}: {len(file_stats['issues'])}ä»¶ã®å•é¡Œ")
    
    print("\n")
    print(analyzer.generate_report())
    
    # ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    report_dir = Path(__file__).parent.parent / 'docs' / 'quality'
    report_dir.mkdir(exist_ok=True)
    
    report_path = report_dir / 'grammar_quality_report.md'
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(analyzer.generate_report())
    
    print(f"\nğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {report_path}")


if __name__ == '__main__':
    main()
