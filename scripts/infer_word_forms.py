#!/usr/bin/env python3
"""
ç¬¬2æ®µéš: æ´»ç”¨å½¢ãƒ»æ´¾ç”Ÿèªã®è‡ªå‹•æ¨è«–

æ—¢ã«è¾æ›¸ã«åŸå½¢ãŒã‚ã‚‹å˜èªã®æ´»ç”¨å½¢ã‚’è‡ªå‹•ç”Ÿæˆ
- è¤‡æ•°å½¢: -s, -es, -ies
- éå»å½¢: -ed, -ied  
- ç¾åœ¨åˆ†è©: -ing
- å‰¯è©å½¢: -ly
"""

import json
from pathlib import Path
from collections import defaultdict
import re


def find_base_word(word, dictionary):
    """æ´»ç”¨å½¢ã‹ã‚‰åŸå½¢ã‚’æ¨æ¸¬"""
    word_lower = word.lower()
    
    # ãã®ã¾ã¾ã®å½¢ãŒè¾æ›¸ã«ã‚ã‚‹ã‹
    if word_lower in dictionary and dictionary[word_lower].get('meaning') not in ['(è¦ç¢ºèª)', '(æœªç™»éŒ²)', '(å›ºæœ‰åè©)']:
        return None  # æ—¢ã«æ„å‘³ãŒã‚ã‚‹
    
    candidates = []
    
    # è¤‡æ•°å½¢ -s
    if word_lower.endswith('s') and len(word_lower) > 2:
        base = word_lower[:-1]
        if base in dictionary and dictionary[base].get('meaning') not in ['(è¦ç¢ºèª)', '(æœªç™»éŒ²)', '(å›ºæœ‰åè©)']:
            candidates.append((base, 'plural_s', dictionary[base].get('meaning', '')))
    
    # è¤‡æ•°å½¢ -es
    if word_lower.endswith('es') and len(word_lower) > 3:
        base = word_lower[:-2]
        if base in dictionary and dictionary[base].get('meaning') not in ['(è¦ç¢ºèª)', '(æœªç™»éŒ²)', '(å›ºæœ‰åè©)']:
            candidates.append((base, 'plural_es', dictionary[base].get('meaning', '')))
    
    # è¤‡æ•°å½¢ -ies (y -> ies)
    if word_lower.endswith('ies') and len(word_lower) > 4:
        base = word_lower[:-3] + 'y'
        if base in dictionary and dictionary[base].get('meaning') not in ['(è¦ç¢ºèª)', '(æœªç™»éŒ²)', '(å›ºæœ‰åè©)']:
            candidates.append((base, 'plural_ies', dictionary[base].get('meaning', '')))
    
    # éå»å½¢ -ed
    if word_lower.endswith('ed') and len(word_lower) > 3:
        # é€šå¸¸ã® -ed
        base = word_lower[:-2]
        if base in dictionary and dictionary[base].get('meaning') not in ['(è¦ç¢ºèª)', '(æœªç™»éŒ²)', '(å›ºæœ‰åè©)']:
            candidates.append((base, 'past_ed', dictionary[base].get('meaning', '')))
        
        # -e + d (hope -> hoped)
        base_e = word_lower[:-1]
        if base_e in dictionary and dictionary[base_e].get('meaning') not in ['(è¦ç¢ºèª)', '(æœªç™»éŒ²)', '(å›ºæœ‰åè©)']:
            candidates.append((base_e, 'past_e_d', dictionary[base_e].get('meaning', '')))
        
        # å­éŸ³å­—é‡è¤‡ (stop -> stopped)
        if len(word_lower) > 4 and word_lower[-3] == word_lower[-4]:
            base_double = word_lower[:-3]
            if base_double in dictionary and dictionary[base_double].get('meaning') not in ['(è¦ç¢ºèª)', '(æœªç™»éŒ²)', '(å›ºæœ‰åè©)']:
                candidates.append((base_double, 'past_double', dictionary[base_double].get('meaning', '')))
    
    # éå»å½¢ -ied (y -> ied)
    if word_lower.endswith('ied') and len(word_lower) > 4:
        base = word_lower[:-3] + 'y'
        if base in dictionary and dictionary[base].get('meaning') not in ['(è¦ç¢ºèª)', '(æœªç™»éŒ²)', '(å›ºæœ‰åè©)']:
            candidates.append((base, 'past_ied', dictionary[base].get('meaning', '')))
    
    # ç¾åœ¨åˆ†è© -ing
    if word_lower.endswith('ing') and len(word_lower) > 4:
        # é€šå¸¸ã® -ing
        base = word_lower[:-3]
        if base in dictionary and dictionary[base].get('meaning') not in ['(è¦ç¢ºèª)', '(æœªç™»éŒ²)', '(å›ºæœ‰åè©)']:
            candidates.append((base, 'ing', dictionary[base].get('meaning', '')))
        
        # -eå‰Šé™¤ + ing (make -> making)
        base_e = word_lower[:-3] + 'e'
        if base_e in dictionary and dictionary[base_e].get('meaning') not in ['(è¦ç¢ºèª)', '(æœªç™»éŒ²)', '(å›ºæœ‰åè©)']:
            candidates.append((base_e, 'ing_e', dictionary[base_e].get('meaning', '')))
        
        # å­éŸ³å­—é‡è¤‡ (run -> running)
        if len(word_lower) > 5 and word_lower[-4] == word_lower[-5]:
            base_double = word_lower[:-4]
            if base_double in dictionary and dictionary[base_double].get('meaning') not in ['(è¦ç¢ºèª)', '(æœªç™»éŒ²)', '(å›ºæœ‰åè©)']:
                candidates.append((base_double, 'ing_double', dictionary[base_double].get('meaning', '')))
    
    # å‰¯è©å½¢ -ly
    if word_lower.endswith('ly') and len(word_lower) > 3:
        base = word_lower[:-2]
        if base in dictionary and dictionary[base].get('meaning') not in ['(è¦ç¢ºèª)', '(æœªç™»éŒ²)', '(å›ºæœ‰åè©)']:
            candidates.append((base, 'adverb_ly', dictionary[base].get('meaning', '')))
        
        # -y -> ily (happy -> happily)
        base_y = word_lower[:-3] + 'y'
        if base_y in dictionary and dictionary[base_y].get('meaning') not in ['(è¦ç¢ºèª)', '(æœªç™»éŒ²)', '(å›ºæœ‰åè©)']:
            candidates.append((base_y, 'adverb_ily', dictionary[base_y].get('meaning', '')))
    
    # æœ€ã‚‚é•·ã„åŸå½¢ã‚’é¸æŠï¼ˆã‚ˆã‚Šå…·ä½“çš„ãªå˜èªã‚’å„ªå…ˆï¼‰
    if candidates:
        candidates.sort(key=lambda x: len(x[0]), reverse=True)
        return candidates[0]
    
    return None


def generate_meaning(base_word, base_meaning, form_type):
    """æ´»ç”¨å½¢ã«å¿œã˜ãŸæ„å‘³ã‚’ç”Ÿæˆ"""
    if form_type in ['plural_s', 'plural_es', 'plural_ies']:
        # è¤‡æ•°å½¢
        if base_meaning.endswith('ã“ã¨'):
            return base_meaning  # å‹•åè©ãªã©ã¯ãã®ã¾ã¾
        return base_meaning + 'ï¼ˆè¤‡æ•°å½¢ï¼‰'
    
    elif form_type in ['past_ed', 'past_e_d', 'past_double', 'past_ied']:
        # éå»å½¢ãƒ»éå»åˆ†è©
        return base_meaning + 'ãŸãƒ»ã•ã‚ŒãŸ'
    
    elif form_type in ['ing', 'ing_e', 'ing_double']:
        # ç¾åœ¨åˆ†è©ãƒ»å‹•åè©
        return base_meaning + 'ã“ã¨ãƒ»ã—ã¦ã„ã‚‹'
    
    elif form_type in ['adverb_ly', 'adverb_ily']:
        # å‰¯è©å½¢
        # å½¢å®¹è©ã®æ„å‘³ã‹ã‚‰å‰¯è©ã®æ„å‘³ã‚’æ¨æ¸¬
        if 'ã€œãª' in base_meaning or 'ã€œã„' in base_meaning:
            return base_meaning.replace('ã€œãª', 'ã€œã«').replace('ã€œã„', 'ã€œã')
        return base_meaning + 'ã«'
    
    return base_meaning


def main():
    # ãƒ‘ã‚¹ã®è¨­å®š
    dict_path = Path('public/data/dictionaries/reading-passages-dictionary.json')
    passages_dir = Path('public/data/passages-phrase-learning')
    
    # è¾æ›¸ã‚’èª­ã¿è¾¼ã¿
    print("ğŸ“– è¾æ›¸ã‚’èª­ã¿è¾¼ã¿ä¸­...")
    with open(dict_path, 'r', encoding='utf-8') as f:
        dictionary = json.load(f)
    
    # ãƒ‘ãƒƒã‚»ãƒ¼ã‚¸ãƒ•ã‚¡ã‚¤ãƒ«å†…ã®(è¦ç¢ºèª)å˜èªã‚’é›†è¨ˆ
    print("ğŸ“Š (è¦ç¢ºèª)å˜èªã‚’é›†è¨ˆä¸­...")
    unconfirmed_words = defaultdict(int)
    
    for passage_file in passages_dir.glob('*.json'):
        with open(passage_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        for phrase in data.get('phrases', []):
            for segment in phrase.get('segments', []):
                word = segment.get('word', '')
                meaning = segment.get('meaning', '')
                
                if meaning == '(è¦ç¢ºèª)' and word:
                    unconfirmed_words[word] += 1
    
    print(f"  è¦‹ã¤ã‹ã£ãŸ(è¦ç¢ºèª)å˜èª: {len(unconfirmed_words)}ç¨®é¡")
    
    # æ´»ç”¨å½¢ã‹ã‚‰åŸå½¢ã‚’æ¨æ¸¬
    print("\nğŸ” æ´»ç”¨å½¢ã‚’åˆ†æä¸­...")
    inferred_words = {}
    
    for word, count in unconfirmed_words.items():
        result = find_base_word(word, dictionary)
        if result:
            base_word, form_type, base_meaning = result
            meaning = generate_meaning(base_word, base_meaning, form_type)
            inferred_words[word.lower()] = {
                'meaning': meaning,
                'base_word': base_word,
                'form_type': form_type,
                'count': count
            }
    
    print(f"  æ¨è«–å¯èƒ½ãªå˜èª: {len(inferred_words)}èª")
    print(f"  ç·å‡ºç¾å›æ•°: {sum(w['count'] for w in inferred_words.values())}å›")
    
    if not inferred_words:
        print("\næ¨è«–ã§ãã‚‹å˜èªãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    # è¾æ›¸ã‚’æ›´æ–°
    print("\nğŸ“ è¾æ›¸ã‚’æ›´æ–°ä¸­...")
    updated_count = 0
    for word_lower, info in inferred_words.items():
        if word_lower in dictionary:
            if dictionary[word_lower].get('meaning') == '(è¦ç¢ºèª)':
                dictionary[word_lower]['meaning'] = info['meaning']
                dictionary[word_lower]['source'] = 'word-form-inference'
                dictionary[word_lower]['baseWord'] = info['base_word']
                updated_count += 1
    
    # è¾æ›¸ã‚’ä¿å­˜
    with open(dict_path, 'w', encoding='utf-8') as f:
        json.dump(dictionary, f, ensure_ascii=False, indent=2)
    
    print(f"  è¾æ›¸æ›´æ–°: {updated_count}èª")
    
    # ãƒ‘ãƒƒã‚»ãƒ¼ã‚¸ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°
    print("\nğŸ“ ãƒ‘ãƒƒã‚»ãƒ¼ã‚¸ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°ä¸­...")
    total_updated = 0
    
    for passage_file in sorted(passages_dir.glob('*.json')):
        with open(passage_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        file_updated = 0
        for phrase in data.get('phrases', []):
            for segment in phrase.get('segments', []):
                word = segment.get('word', '')
                word_lower = word.lower()
                
                if word_lower in inferred_words and segment.get('meaning') == '(è¦ç¢ºèª)':
                    segment['meaning'] = inferred_words[word_lower]['meaning']
                    file_updated += 1
        
        if file_updated > 0:
            with open(passage_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            print(f"  {passage_file.name}: {file_updated}ç®‡æ‰€æ›´æ–°")
            total_updated += file_updated
    
    print(f"\nâœ… å®Œäº†!")
    print(f"  æ¨è«–ã—ãŸå˜èª: {len(inferred_words)}èª")
    print(f"  æ›´æ–°ã—ãŸç®‡æ‰€: {total_updated}ç®‡æ‰€")
    
    # ã‚µãƒ³ãƒ—ãƒ«ã‚’è¡¨ç¤º
    print("\nğŸ“Š æ¨è«–ä¾‹ï¼ˆå‡ºç¾é »åº¦ä¸Šä½20ï¼‰:")
    sorted_inferred = sorted(inferred_words.items(), key=lambda x: x[1]['count'], reverse=True)
    for i, (word, info) in enumerate(sorted_inferred[:20], 1):
        print(f"  {i}. {word} â† {info['base_word']}: {info['meaning']} ({info['count']}å›)")


if __name__ == '__main__':
    main()
