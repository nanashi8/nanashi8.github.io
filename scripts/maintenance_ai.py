#!/usr/bin/env python3
"""
å®šæœŸãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹AI

ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å„è¦æ‰€ã‚’å®šæœŸçš„ã«ãƒã‚§ãƒƒã‚¯ã—ã€å•é¡Œã‚’è‡ªå‹•æ¤œå‡ºãƒ»ä¿®æ­£ã—ã¾ã™ã€‚

ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹å¯¾è±¡:
1. ãƒ‡ãƒ¼ã‚¿å“è³ª (Grammar, Vocabulary, Pronunciation)
2. ã‚³ãƒ¼ãƒ‰å“è³ª (TypeScript, Tests)
3. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ (README, ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³)
4. ä¾å­˜é–¢ä¿‚ (npm packages)
5. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ (ãƒ“ãƒ«ãƒ‰ã‚µã‚¤ã‚º, ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“)
"""

import json
import os
import re
import subprocess
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional
import argparse

class MaintenanceAI:
    """å®šæœŸãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹AI"""

    def __init__(self, base_dir: Path, verbose: bool = False):
        self.base_dir = base_dir
        self.verbose = verbose
        self.issues: List[Dict[str, Any]] = []
        self.auto_fixes: List[Dict[str, Any]] = []

    def log(self, message: str, level: str = "INFO"):
        """ãƒ­ã‚°å‡ºåŠ›"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        prefix = {
            "INFO": "â„¹ï¸ ",
            "SUCCESS": "âœ…",
            "WARNING": "âš ï¸ ",
            "ERROR": "âŒ",
            "FIX": "ğŸ”§"
        }.get(level, "  ")

        if self.verbose or level in ["WARNING", "ERROR", "FIX"]:
            print(f"[{timestamp}] {prefix} {message}")

    def add_issue(self, category: str, severity: str, description: str,
                  file_path: Optional[str] = None, auto_fix: bool = False):
        """å•é¡Œã‚’è¨˜éŒ²"""
        issue = {
            "category": category,
            "severity": severity,  # CRITICAL, WARNING, INFO
            "description": description,
            "file_path": file_path,
            "auto_fix": auto_fix,
            "timestamp": datetime.now().isoformat()
        }
        self.issues.append(issue)

        level = "ERROR" if severity == "CRITICAL" else "WARNING"
        self.log(f"[{category}] {description}", level)

    def check_data_quality(self):
        """ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯"""
        self.log("=" * 60)
        self.log("ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯é–‹å§‹", "INFO")
        self.log("=" * 60)

        # å“è³ªç¥çµŒç³»çµ±ã‚’å®Ÿè¡Œï¼ˆJSONå‡ºåŠ›ã‚’æœ‰åŠ¹åŒ–ï¼‰
        try:
            env = os.environ.copy()
            env["EXPORT_JSON"] = "1"

            result = subprocess.run(
                ["python3", "scripts/quality_nervous_system.py"],
                cwd=self.base_dir,
                capture_output=True,
                text=True,
                timeout=300,
                env=env
            )

            # JSONãƒ¬ãƒãƒ¼ãƒˆã‚’èª­ã¿è¾¼ã¿
            report_path = self.base_dir / "tools" / "data" / "quality_nervous_system_report.json"
            if report_path.exists():
                try:
                    with open(report_path, "r", encoding="utf-8") as f:
                        quality_report = json.load(f)

                    # è©³ç´°ãªå•é¡Œã‚’å€‹åˆ¥ã«è¨˜éŒ²
                    for issue in quality_report.get("issues", []):
                        self.add_issue(
                            "data_quality",
                            issue.get("severity", "WARNING"),
                            f"{Path(issue.get('file_path', '')).name}: {issue['description']}",
                            file_path=issue.get("file_path"),
                            auto_fix=False
                        )

                    # ã‚µãƒãƒªãƒ¼ãƒ­ã‚°
                    if quality_report.get("critical_issues", 0) > 0:
                        self.log(f"CRITICALå•é¡Œ: {quality_report['critical_issues']}ä»¶", "ERROR")
                    if quality_report.get("warning_issues", 0) > 0:
                        self.log(f"WARNING: {quality_report['warning_issues']}ä»¶", "WARNING")

                    if quality_report.get("total_issues", 0) == 0:
                        self.log("å“è³ªç¥çµŒç³»çµ±ãƒã‚§ãƒƒã‚¯å®Œäº†: å•é¡Œãªã—", "SUCCESS")

                except json.JSONDecodeError:
                    self.log("JSONãƒ¬ãƒãƒ¼ãƒˆã®è§£æã«å¤±æ•—", "WARNING")

            elif result.returncode != 0:
                self.add_issue(
                    "data_quality",
                    "CRITICAL",
                    "å“è³ªç¥çµŒç³»çµ±ãŒCRITICALç•°å¸¸ã‚’æ¤œå‡º",
                    auto_fix=False
                )
                if self.verbose:
                    self.log(result.stdout, "ERROR")

        except subprocess.TimeoutExpired:
            self.add_issue(
                "data_quality",
                "WARNING",
                "å“è³ªãƒã‚§ãƒƒã‚¯ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆ5åˆ†è¶…éï¼‰",
                auto_fix=False
            )
        except FileNotFoundError:
            self.add_issue(
                "data_quality",
                "WARNING",
                "å“è³ªç¥çµŒç³»çµ±ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“",
                file_path="scripts/quality_nervous_system.py",
                auto_fix=False
            )

    def check_test_coverage(self):
        """ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ãƒã‚§ãƒƒã‚¯"""
        self.log("=" * 60)
        self.log("ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ãƒã‚§ãƒƒã‚¯é–‹å§‹", "INFO")
        self.log("=" * 60)

        try:
            # Vitestã§ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            result = subprocess.run(
                ["npx", "vitest", "run", "--coverage", "--reporter=json"],
                cwd=self.base_dir,
                capture_output=True,
                text=True,
                timeout=300
            )

            # ã‚«ãƒãƒ¬ãƒƒã‚¸ãŒä½ã„å ´åˆã¯è­¦å‘Š
            if "coverage" in result.stdout.lower():
                # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ã‚’æŠ½å‡º
                coverage_match = re.search(r"(\d+\.?\d*)%", result.stdout)
                if coverage_match:
                    coverage = float(coverage_match.group(1))
                    if coverage < 50:
                        self.add_issue(
                            "test_coverage",
                            "WARNING",
                            f"ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ãŒä½ã„: {coverage}% (ç›®æ¨™: 50%ä»¥ä¸Š)",
                            auto_fix=False
                        )
                    else:
                        self.log(f"ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸: {coverage}%", "SUCCESS")

        except subprocess.TimeoutExpired:
            self.add_issue(
                "test_coverage",
                "WARNING",
                "ãƒ†ã‚¹ãƒˆå®Ÿè¡ŒãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆ5åˆ†è¶…éï¼‰",
                auto_fix=False
            )
        except Exception as e:
            self.log(f"ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}", "WARNING")

    def check_dependencies(self):
        """ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯"""
        self.log("=" * 60)
        self.log("ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯é–‹å§‹", "INFO")
        self.log("=" * 60)

        package_json = self.base_dir / "package.json"

        if not package_json.exists():
            self.add_issue(
                "dependencies",
                "CRITICAL",
                "package.jsonãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“",
                file_path="package.json",
                auto_fix=False
            )
            return

        try:
            # npm audit ã§è„†å¼±æ€§ãƒã‚§ãƒƒã‚¯
            result = subprocess.run(
                ["npm", "audit", "--json"],
                cwd=self.base_dir,
                capture_output=True,
                text=True,
                timeout=60
            )

            if result.stdout:
                audit_data = json.loads(result.stdout)
                vulnerabilities = audit_data.get("metadata", {}).get("vulnerabilities", {})

                critical = vulnerabilities.get("critical", 0)
                high = vulnerabilities.get("high", 0)
                moderate = vulnerabilities.get("moderate", 0)

                if critical > 0:
                    self.add_issue(
                        "dependencies",
                        "CRITICAL",
                        f"Criticalè„†å¼±æ€§: {critical}ä»¶",
                        auto_fix=True
                    )
                    self.auto_fixes.append({
                        "type": "npm_audit_fix",
                        "command": "npm audit fix --force"
                    })

                if high > 0:
                    self.add_issue(
                        "dependencies",
                        "WARNING",
                        f"Highè„†å¼±æ€§: {high}ä»¶",
                        auto_fix=True
                    )

                if critical == 0 and high == 0 and moderate == 0:
                    self.log("ä¾å­˜é–¢ä¿‚ã«è„†å¼±æ€§ãªã—", "SUCCESS")

        except json.JSONDecodeError:
            self.log("npm auditçµæœã®ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼", "WARNING")
        except subprocess.TimeoutExpired:
            self.add_issue(
                "dependencies",
                "WARNING",
                "npm auditãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ",
                auto_fix=False
            )
        except Exception as e:
            self.log(f"ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}", "WARNING")

    def check_code_quality(self):
        """ã‚³ãƒ¼ãƒ‰å“è³ªãƒã‚§ãƒƒã‚¯ (ESLint, Prettier, Stylelint, Markdownlint)"""
        self.log("=" * 60)
        self.log("ã‚³ãƒ¼ãƒ‰å“è³ªãƒã‚§ãƒƒã‚¯é–‹å§‹", "INFO")
        self.log("=" * 60)

        # ESLintãƒã‚§ãƒƒã‚¯ & è‡ªå‹•ä¿®æ­£
        try:
            result = subprocess.run(
                ["npm", "run", "lint:errors-only"],
                cwd=self.base_dir,
                capture_output=True,
                text=True,
                timeout=120
            )

            if result.returncode != 0:
                error_lines = [line for line in result.stdout.split('\n') if 'error' in line.lower()]
                if error_lines:
                    self.add_issue(
                        "code_quality",
                        "WARNING",
                        f"ESLintã‚¨ãƒ©ãƒ¼: {len(error_lines)}ä»¶æ¤œå‡º",
                        auto_fix=True
                    )
                    # ESLint --fixã¯ç›´æ¥å®Ÿè¡Œ
                    self.auto_fixes.append({
                        "type": "eslint_fix",
                        "command": "npx eslint . --ext ts,tsx --fix"
                    })
            else:
                self.log("ESLintãƒã‚§ãƒƒã‚¯: å•é¡Œãªã—", "SUCCESS")
        except Exception as e:
            self.log(f"ESLintãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}", "WARNING")

        # Prettierãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãƒã‚§ãƒƒã‚¯ & è‡ªå‹•ä¿®æ­£
        try:
            result = subprocess.run(
                ["npm", "run", "format:check"],
                cwd=self.base_dir,
                capture_output=True,
                text=True,
                timeout=60
            )

            if result.returncode != 0:
                self.add_issue(
                    "code_quality",
                    "INFO",
                    "ã‚³ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ä¸æ•´åˆã‚’æ¤œå‡º",
                    auto_fix=True
                )
                self.auto_fixes.append({
                    "type": "prettier_format",
                    "command": "npm run format"
                })
            else:
                self.log("Prettierãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: å•é¡Œãªã—", "SUCCESS")
        except Exception as e:
            self.log(f"Prettierãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}", "WARNING")

        # Stylelintãƒã‚§ãƒƒã‚¯ & è‡ªå‹•ä¿®æ­£
        try:
            result = subprocess.run(
                ["npx", "stylelint", "**/*.css", "--formatter", "json"],
                cwd=self.base_dir,
                capture_output=True,
                text=True,
                timeout=60
            )

            if result.stdout:
                try:
                    stylelint_results = json.loads(result.stdout)
                    total_warnings = sum(len(r.get("warnings", [])) for r in stylelint_results)

                    if total_warnings > 0:
                        self.add_issue(
                            "code_quality",
                            "WARNING",
                            f"Stylelintã®å•é¡Œ: {total_warnings}ä»¶æ¤œå‡º",
                            auto_fix=True
                        )
                        self.auto_fixes.append({
                            "type": "stylelint_fix",
                            "command": "npx stylelint '**/*.css' --fix"
                        })
                    else:
                        self.log("Stylelintãƒã‚§ãƒƒã‚¯: å•é¡Œãªã—", "SUCCESS")
                except json.JSONDecodeError:
                    self.log("Stylelintãƒã‚§ãƒƒã‚¯: å•é¡Œãªã—", "SUCCESS")
        except Exception as e:
            self.log(f"Stylelintãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}", "WARNING")

        # Markdownlintãƒã‚§ãƒƒã‚¯ & è‡ªå‹•ä¿®æ­£
        if (self.base_dir / ".markdownlint.json").exists():
            try:
                result = subprocess.run(
                    ["npx", "markdownlint", "**/*.md", "--ignore", "node_modules", "--json"],
                    cwd=self.base_dir,
                    capture_output=True,
                    text=True,
                    timeout=60
                )

                if result.stdout:
                    try:
                        markdownlint_results = json.loads(result.stdout)
                        total_errors = sum(len(errors) for errors in markdownlint_results.values())

                        if total_errors > 0:
                            self.add_issue(
                                "documentation",
                                "WARNING",
                                f"Markdownlintã®å•é¡Œ: {total_errors}ä»¶æ¤œå‡º",
                                auto_fix=True
                            )
                            self.auto_fixes.append({
                                "type": "markdownlint_fix",
                                "command": "npx markdownlint '**/*.md' --ignore node_modules --fix"
                            })
                        else:
                            self.log("Markdownlintãƒã‚§ãƒƒã‚¯: å•é¡Œãªã—", "SUCCESS")
                    except json.JSONDecodeError:
                        self.log("Markdownlintãƒã‚§ãƒƒã‚¯: å•é¡Œãªã—", "SUCCESS")
            except Exception as e:
                self.log(f"Markdownlintãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}", "WARNING")

    def check_file_sizes(self):
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯"""
        self.log("=" * 60)
        self.log("ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯é–‹å§‹", "INFO")
        self.log("=" * 60)

        # å¤§ãã™ãã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡º (>10MB)
        large_files = []
        data_dir = self.base_dir / "public" / "data"

        if data_dir.exists():
            for file_path in data_dir.rglob("*.json"):
                size_mb = file_path.stat().st_size / (1024 * 1024)
                if size_mb > 10:
                    large_files.append((file_path, size_mb))

        if large_files:
            for file_path, size_mb in large_files:
                self.add_issue(
                    "file_size",
                    "WARNING",
                    f"å¤§ãã™ãã‚‹ãƒ•ã‚¡ã‚¤ãƒ«: {file_path.name} ({size_mb:.1f}MB)",
                    file_path=str(file_path),
                    auto_fix=False
                )
        else:
            self.log("ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒé©åˆ‡", "SUCCESS")

    def check_documentation(self):
        """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒã‚§ãƒƒã‚¯"""
        self.log("=" * 60)
        self.log("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒã‚§ãƒƒã‚¯é–‹å§‹", "INFO")
        self.log("=" * 60)

        # å¿…é ˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®å­˜åœ¨ç¢ºèª
        required_docs = [
            "README.md",
            "docs/INTEGRATED_QUALITY_PIPELINE.md",
            "docs/quality/EMERGENCY_QUALITY_NERVOUS_SYSTEM_REPORT.md",
            ".aitk/instructions/testing-guidelines.instructions.md"
        ]

        for doc_path in required_docs:
            full_path = self.base_dir / doc_path
            if not full_path.exists():
                self.add_issue(
                    "documentation",
                    "WARNING",
                    f"å¿…é ˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {doc_path}",
                    file_path=doc_path,
                    auto_fix=False
                )

        # README.mdã®æœ€çµ‚æ›´æ–°ãƒã‚§ãƒƒã‚¯
        readme = self.base_dir / "README.md"
        if readme.exists():
            mtime = datetime.fromtimestamp(readme.stat().st_mtime)
            days_old = (datetime.now() - mtime).days

            if days_old > 30:
                self.add_issue(
                    "documentation",
                    "INFO",
                    f"README.mdãŒ{days_old}æ—¥é–“æ›´æ–°ã•ã‚Œã¦ã„ã¾ã›ã‚“",
                    file_path="README.md",
                    auto_fix=False
                )

        self.log("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒã‚§ãƒƒã‚¯å®Œäº†", "SUCCESS")

    def check_performance_metrics(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ãƒã‚§ãƒƒã‚¯"""
        self.log("=" * 60)
        self.log("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒã‚§ãƒƒã‚¯", "INFO")
        self.log("=" * 60)

        # 1. ãƒ“ãƒ«ãƒ‰æ™‚é–“æ¸¬å®š
        try:
            self.log("ãƒ“ãƒ«ãƒ‰æ™‚é–“ã‚’æ¸¬å®šä¸­...", "INFO")
            start_time = datetime.now()

            result = subprocess.run(
                ["npm", "run", "build"],
                cwd=self.base_dir,
                capture_output=True,
                text=True,
                timeout=300
            )

            build_time = (datetime.now() - start_time).total_seconds()

            if result.returncode == 0:
                if build_time > 60:  # 60ç§’ä»¥ä¸Š
                    self.add_issue(
                        "performance",
                        "WARNING",
                        f"ãƒ“ãƒ«ãƒ‰æ™‚é–“ãŒé•·ã„: {build_time:.1f}ç§’ï¼ˆç›®æ¨™: <60ç§’ï¼‰",
                        auto_fix=False
                    )
                else:
                    self.log(f"ãƒ“ãƒ«ãƒ‰æ™‚é–“: {build_time:.1f}ç§’ âœ“", "SUCCESS")
            else:
                self.add_issue(
                    "performance",
                    "ERROR",
                    "ãƒ“ãƒ«ãƒ‰ãŒå¤±æ•—ã—ã¾ã—ãŸ",
                    auto_fix=False
                )

        except subprocess.TimeoutExpired:
            self.add_issue(
                "performance",
                "CRITICAL",
                "ãƒ“ãƒ«ãƒ‰ãŒ5åˆ†ä»¥å†…ã«å®Œäº†ã—ã¾ã›ã‚“",
                auto_fix=False
            )
        except FileNotFoundError:
            self.log("npm ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆãƒ“ãƒ«ãƒ‰æ™‚é–“æ¸¬å®šã‚¹ã‚­ãƒƒãƒ—ï¼‰", "WARNING")

        # 2. dist/ ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
        dist_path = self.base_dir / "dist"
        if dist_path.exists():
            try:
                total_size = sum(f.stat().st_size for f in dist_path.rglob('*') if f.is_file())
                size_mb = total_size / (1024 * 1024)

                if size_mb > 10:  # 10MBä»¥ä¸Š
                    self.add_issue(
                        "performance",
                        "WARNING",
                        f"ãƒ“ãƒ«ãƒ‰ã‚µã‚¤ã‚ºãŒå¤§ãã„: {size_mb:.1f}MBï¼ˆç›®æ¨™: <10MBï¼‰",
                        auto_fix=False
                    )
                else:
                    self.log(f"ãƒ“ãƒ«ãƒ‰ã‚µã‚¤ã‚º: {size_mb:.1f}MB âœ“", "SUCCESS")
            except Exception as e:
                self.log(f"ãƒ“ãƒ«ãƒ‰ã‚µã‚¤ã‚ºæ¸¬å®šã‚¨ãƒ©ãƒ¼: {e}", "WARNING")
        else:
            self.log("dist/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“ï¼ˆã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰", "INFO")

        # 3. å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œå‡ºï¼ˆ10MBä»¥ä¸Šï¼‰
        large_files = []
        try:
            for file_path in self.base_dir.rglob('*'):
                if file_path.is_file() and not any(
                    part.startswith('.') or part in ['node_modules', 'dist', '.git']
                    for part in file_path.parts
                ):
                    size_mb = file_path.stat().st_size / (1024 * 1024)
                    if size_mb > 10:
                        large_files.append((str(file_path.relative_to(self.base_dir)), size_mb))

            if large_files:
                for file_path, size in large_files:
                    self.add_issue(
                        "performance",
                        "WARNING",
                        f"å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«: {file_path} ({size:.1f}MB)",
                        file_path=file_path,
                        auto_fix=False
                    )
        except Exception as e:
            self.log(f"å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}", "WARNING")

        self.log("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒã‚§ãƒƒã‚¯å®Œäº†", "SUCCESS")

    def check_git_status(self):
        """Gitã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒã‚§ãƒƒã‚¯"""
        self.log("=" * 60)
        self.log("Gitã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒã‚§ãƒƒã‚¯é–‹å§‹", "INFO")
        self.log("=" * 60)

        try:
            # æœªã‚³ãƒŸãƒƒãƒˆã®å¤‰æ›´ã‚’ãƒã‚§ãƒƒã‚¯
            result = subprocess.run(
                ["git", "status", "--porcelain"],
                cwd=self.base_dir,
                capture_output=True,
                text=True,
                timeout=10
            )

            if result.stdout.strip():
                lines = result.stdout.strip().split("\n")
                self.add_issue(
                    "git",
                    "INFO",
                    f"æœªã‚³ãƒŸãƒƒãƒˆã®å¤‰æ›´: {len(lines)}ãƒ•ã‚¡ã‚¤ãƒ«",
                    auto_fix=False
                )
            else:
                self.log("ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒã‚¯ãƒªãƒ¼ãƒ³", "SUCCESS")

            # ãƒªãƒ¢ãƒ¼ãƒˆã¨ã®åŒæœŸçŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯
            result = subprocess.run(
                ["git", "rev-list", "--left-right", "--count", "HEAD...@{u}"],
                cwd=self.base_dir,
                capture_output=True,
                text=True,
                timeout=10
            )

            if result.returncode == 0 and result.stdout.strip():
                ahead, behind = map(int, result.stdout.strip().split())
                if ahead > 0:
                    self.add_issue(
                        "git",
                        "INFO",
                        f"ãƒ­ãƒ¼ã‚«ãƒ«ãŒ{ahead}ã‚³ãƒŸãƒƒãƒˆé€²ã‚“ã§ã„ã¾ã™ï¼ˆpushæ¨å¥¨ï¼‰",
                        auto_fix=False
                    )
                if behind > 0:
                    self.add_issue(
                        "git",
                        "WARNING",
                        f"ãƒªãƒ¢ãƒ¼ãƒˆãŒ{behind}ã‚³ãƒŸãƒƒãƒˆé€²ã‚“ã§ã„ã¾ã™ï¼ˆpullæ¨å¥¨ï¼‰",
                        auto_fix=False
                    )

        except subprocess.TimeoutExpired:
            self.log("Gitã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒã‚§ãƒƒã‚¯ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ", "WARNING")
        except Exception as e:
            self.log(f"Gitã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}", "WARNING")

    def apply_auto_fixes(self, dry_run: bool = True):
        """è‡ªå‹•ä¿®æ­£ã‚’é©ç”¨"""
        if not self.auto_fixes:
            self.log("è‡ªå‹•ä¿®æ­£å¯¾è±¡ãªã—", "INFO")
            return

        self.log("=" * 60)
        self.log(f"è‡ªå‹•ä¿®æ­£é©ç”¨ (dry_run={dry_run})", "FIX")
        self.log("=" * 60)

        for fix in self.auto_fixes:
            self.log(f"ä¿®æ­£ã‚¿ã‚¤ãƒ—: {fix['type']}", "FIX")
            self.log(f"ã‚³ãƒãƒ³ãƒ‰: {fix['command']}", "FIX")

            if not dry_run:
                try:
                    # ã‚·ã‚§ãƒ«ã‚³ãƒãƒ³ãƒ‰ã®å ´åˆã¯shell=Trueã‚’ä½¿ç”¨
                    use_shell = fix.get('use_shell', False)
                    cmd = fix['command'] if use_shell else fix['command'].split()

                    result = subprocess.run(
                        cmd,
                        cwd=self.base_dir,
                        capture_output=True,
                        text=True,
                        timeout=300,
                        shell=use_shell
                    )

                    if result.returncode == 0:
                        self.log(f"ä¿®æ­£æˆåŠŸ: {fix['type']}", "SUCCESS")
                    else:
                        self.log(f"ä¿®æ­£å¤±æ•—: {fix['type']}", "ERROR")
                        self.log(result.stderr[:200], "ERROR")

                except Exception as e:
                    self.log(f"ä¿®æ­£ã‚¨ãƒ©ãƒ¼: {e}", "ERROR")
            else:
                self.log("(dry_run mode - å®Ÿè¡Œã‚¹ã‚­ãƒƒãƒ—)", "INFO")

    def generate_report(self) -> Dict[str, Any]:
        """ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        self.log("=" * 60)
        self.log("ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ", "INFO")
        self.log("=" * 60)

        report = {
            "timestamp": datetime.now().isoformat(),
            "total_issues": len(self.issues),
            "critical_issues": len([i for i in self.issues if i["severity"] == "CRITICAL"]),
            "warning_issues": len([i for i in self.issues if i["severity"] == "WARNING"]),
            "info_issues": len([i for i in self.issues if i["severity"] == "INFO"]),
            "auto_fixable": len([i for i in self.issues if i["auto_fix"]]),
            "issues": self.issues,
            "auto_fixes_available": self.auto_fixes
        }

        # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
        self.log(f"ç·å•é¡Œæ•°: {report['total_issues']}", "INFO")
        self.log(f"  CRITICAL: {report['critical_issues']}", "ERROR" if report['critical_issues'] > 0 else "INFO")
        self.log(f"  WARNING: {report['warning_issues']}", "WARNING" if report['warning_issues'] > 0 else "INFO")
        self.log(f"  INFO: {report['info_issues']}", "INFO")
        self.log(f"è‡ªå‹•ä¿®æ­£å¯èƒ½: {report['auto_fixable']}", "FIX" if report['auto_fixable'] > 0 else "INFO")

        return report

    def save_report(self, report: Dict[str, Any], output_path: Optional[Path] = None):
        """ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜"""
        if output_path is None:
            output_path = self.base_dir / "tools" / "data" / "maintenance_report.json"

        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

        self.log(f"ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {output_path}", "SUCCESS")

    def run_full_maintenance(self, auto_fix: bool = False, dry_run: bool = True):
        """å®Œå…¨ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹å®Ÿè¡Œ"""
        self.log("ğŸ¤– å®šæœŸãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹AIèµ·å‹•", "INFO")
        self.log(f"å®Ÿè¡Œæ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}", "INFO")
        self.log(f"å¯¾è±¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {self.base_dir}", "INFO")
        self.log("")

        # å„ç¨®ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ
        self.check_data_quality()
        self.check_test_coverage()
        self.check_dependencies()
        self.check_code_quality()  # ğŸ†• ESLint, Prettierãƒã‚§ãƒƒã‚¯è¿½åŠ 
        self.check_file_sizes()
        self.check_documentation()
        self.check_performance_metrics()
        self.check_git_status()

        # è‡ªå‹•ä¿®æ­£é©ç”¨
        if auto_fix and self.auto_fixes:
            self.apply_auto_fixes(dry_run=dry_run)

        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆãƒ»ä¿å­˜
        report = self.generate_report()
        self.save_report(report)

        self.log("")
        self.log("ğŸ‰ ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹å®Œäº†", "SUCCESS")

        # çµ‚äº†ã‚³ãƒ¼ãƒ‰åˆ¤å®š
        if report["critical_issues"] > 0:
            return 1
        return 0

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    parser = argparse.ArgumentParser(description="å®šæœŸãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹AI")
    parser.add_argument("--base-dir", type=str, default=".",
                       help="ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")
    parser.add_argument("--auto-fix", action="store_true",
                       help="è‡ªå‹•ä¿®æ­£ã‚’æœ‰åŠ¹åŒ–")
    parser.add_argument("--no-dry-run", action="store_true",
                       help="dry_runãƒ¢ãƒ¼ãƒ‰ã‚’ç„¡åŠ¹åŒ–ï¼ˆå®Ÿéš›ã«ä¿®æ­£ã‚’é©ç”¨ï¼‰")
    parser.add_argument("--verbose", action="store_true",
                       help="è©³ç´°ãƒ­ã‚°ã‚’å‡ºåŠ›")
    parser.add_argument("--output", type=str,
                       help="ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›å…ˆ")

    args = parser.parse_args()

    base_dir = Path(args.base_dir).resolve()

    if not base_dir.exists():
        print(f"âŒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {base_dir}")
        return 1

    ai = MaintenanceAI(base_dir, verbose=args.verbose)

    exit_code = ai.run_full_maintenance(
        auto_fix=args.auto_fix,
        dry_run=not args.no_dry_run
    )

    return exit_code

if __name__ == "__main__":
    sys.exit(main())
