#!/usr/bin/env python3
"""
æ®‹å­˜ã‚¨ãƒ©ãƒ¼æ‰‹å‹•ä¿®æ­£ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

eng_to_ipaãŒèªè­˜ã§ããªã‹ã£ãŸå˜èªã®IPAã‚’æ‰‹å‹•ã§æ­£ã—ã„å€¤ã«ä¿®æ­£ã™ã‚‹ã€‚
"""

import csv
from pathlib import Path
from typing import Dict, List

# ä¿®æ­£ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆå˜èª â†’ æ­£ã—ã„IPAç™ºéŸ³ï¼‰
IPA_CORRECTIONS = {
    'affectionâ€‹ate': 'É™ËˆfÉ›kÊƒÉ™nÉ™t',  # affectionate ã®ã‚¿ã‚¤ãƒ
    'controvert': 'ËŒkÉ‘ntrÉ™ËˆvÉœrt',
    'copse': 'kÉ‘ps',
    'corpulent': 'ËˆkÉ”rpjÉ™lÉ™nt',
    'P.E.': 'piË iË',
    'p.m.': 'piË É›m',
    'toothache': 'ËˆtuÎ¸ËŒeÉªk',
}

# ã‚«ã‚¿ã‚«ãƒŠä¿®æ­£ãƒãƒƒãƒ”ãƒ³ã‚°
KATAKANA_CORRECTIONS = {
    ('P.E.', 'piË iË'): 'ãƒ”Ìãƒ¼ ã‚¢Ìã‚¤',
    ('p.m.', 'P.M.'): 'ãƒ”Ìãƒ¼ ã‚¨Ìãƒ ',
    ('TV', 'ãƒ†ãƒ¬ãƒ“'): 'ãƒ†ã‚£Ìãƒ¼ãƒ´ã‚£Ìãƒ¼',
}


def fix_csv_file(file_path: Path) -> int:
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ãƒ©ãƒ¼ã‚’ä¿®æ­£"""
    print(f"\nğŸ“ å‡¦ç†ä¸­: {file_path.name}")
    
    rows = []
    modified_count = 0
    
    # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
    with open(file_path, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        fieldnames = reader.fieldnames
        
        for row_num, row in enumerate(reader, start=2):
            # æ—¥æœ¬èªãƒ˜ãƒƒãƒ€ãƒ¼å¯¾å¿œ
            word = row.get('word', row.get('èªå¥', '')).strip()
            reading = row.get('reading', row.get('èª­ã¿', '')).strip()
            reading_field = 'èª­ã¿' if 'èª­ã¿' in row else 'reading'
            
            original_reading = reading
            
            # 1. ã‚¢ã‚¹ã‚¿ãƒªã‚¹ã‚¯ä»˜ãIPAã®ä¿®æ­£
            if '*' in reading or '\u200b' in reading:
                # ã‚¼ãƒ­å¹…ã‚¹ãƒšãƒ¼ã‚¹ã‚’é™¤å»
                clean_word = word.replace('\u200b', '')
                
                if clean_word in IPA_CORRECTIONS:
                    # æ‹¬å¼§å†…ã®ã‚«ã‚¿ã‚«ãƒŠã‚’æŠ½å‡º
                    import re
                    match = re.search(r'\(([^)]+)\)$', reading)
                    if match:
                        katakana = match.group(1)
                        new_ipa = IPA_CORRECTIONS[clean_word]
                        new_reading = f"{new_ipa} ({katakana})"
                        row[reading_field] = new_reading
                        modified_count += 1
                        print(f"  âœ… è¡Œ{row_num}: {word}")
                        print(f"      {reading} â†’ {new_reading}")
            
            # 2. ã‚«ã‚¿ã‚«ãƒŠè‹±èªæ··å…¥ã®ä¿®æ­£
            elif (word, reading.split('(')[1].rstrip(')') if '(' in reading else '') in KATAKANA_CORRECTIONS or \
                 (word, reading) in [(k[0], k[1]) for k in KATAKANA_CORRECTIONS.keys()]:
                # P.E., p.m., TV ã®ä¿®æ­£
                import re
                if word == 'P.E.' and 'piË iË' in reading:
                    new_katakana = 'ãƒ”Ìãƒ¼ ã‚¢Ìã‚¤'
                    new_reading = f"piË iË ({new_katakana})"
                    row[reading_field] = new_reading
                    modified_count += 1
                    print(f"  âœ… è¡Œ{row_num}: {word}")
                    print(f"      {reading} â†’ {new_reading}")
                
                elif word == 'p.m.' and 'P.M.' in reading:
                    new_katakana = 'ãƒ”Ìãƒ¼ ã‚¨Ìãƒ '
                    new_reading = f"piË É›m ({new_katakana})"
                    row[reading_field] = new_reading
                    modified_count += 1
                    print(f"  âœ… è¡Œ{row_num}: {word}")
                    print(f"      {reading} â†’ {new_reading}")
                
                elif word == 'TV':
                    # TVã®å ´åˆã€IPAã‚’è¿½åŠ 
                    match = re.search(r'\(([^)]+)\)$', reading)
                    if match:
                        # æ—¢ã«IPAå½¢å¼
                        katakana = match.group(1)
                        if 'ãƒ†ãƒ¬ãƒ“' in katakana:
                            new_katakana = 'ãƒ†ã‚£Ìãƒ¼ãƒ´ã‚£Ìãƒ¼'
                            ipa_part = reading.split('(')[0].strip()
                            new_reading = f"{ipa_part} ({new_katakana})"
                            row[reading_field] = new_reading
                            modified_count += 1
                            print(f"  âœ… è¡Œ{row_num}: {word}")
                            print(f"      {reading} â†’ {new_reading}")
                    else:
                        # ã‚«ã‚¿ã‚«ãƒŠã®ã¿
                        if reading == 'ãƒ†ãƒ¬ãƒ“':
                            new_reading = "tiË viË (ãƒ†ã‚£Ìãƒ¼ãƒ´ã‚£Ìãƒ¼)"
                            row[reading_field] = new_reading
                            modified_count += 1
                            print(f"  âœ… è¡Œ{row_num}: {word}")
                            print(f"      {reading} â†’ {new_reading}")
            
            rows.append(row)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿ï¼ˆå¤‰æ›´ãŒã‚ã£ãŸå ´åˆã®ã¿ï¼‰
    if modified_count > 0:
        with open(file_path, 'w', encoding='utf-8', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(rows)
        print(f"  ğŸ’¾ {modified_count}ä»¶ã‚’ä¿®æ­£ã—ã¾ã—ãŸ")
    else:
        print(f"  â­ï¸  å¤‰æ›´ãªã—")
    
    return modified_count


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("ğŸš€ æ®‹å­˜ã‚¨ãƒ©ãƒ¼æ‰‹å‹•ä¿®æ­£ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    print("="*60)
    
    vocab_dir = Path("public/data/vocabulary")
    csv_files = sorted(vocab_dir.glob("*.csv"))
    
    total_modified = 0
    for csv_file in csv_files:
        modified = fix_csv_file(csv_file)
        total_modified += modified
    
    print("\n" + "="*60)
    print(f"ğŸ“Š åˆè¨ˆä¿®æ­£: {total_modified}ä»¶")
    print("="*60)
    print("\nâœ… å®Œäº†")


if __name__ == "__main__":
    main()
