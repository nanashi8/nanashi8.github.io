#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Comprehensive JSON ã® segments å†…ã® meaning ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è¾æ›¸ã‹ã‚‰è¨­å®šã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import json
import re
from pathlib import Path

def load_json(filepath):
    """JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    with open(filepath, 'r', encoding='utf-8') as f:
        return json.load(f)

def save_json(data, filepath):
    """JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã™ã‚‹"""
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    print(f"âœ“ {filepath} ã‚’ä¿å­˜ã—ã¾ã—ãŸ")

def load_csv_dictionary(filepath):
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è¾æ›¸ã‚’èª­ã¿è¾¼ã‚€"""
    dictionary = {}
    with open(filepath, 'r', encoding='utf-8') as f:
        lines = f.readlines()
        for line in lines:
            line = line.strip()
            if not line or line.startswith('#'):
                continue
            
            parts = line.split(',')
            if len(parts) >= 7:
                word = parts[0].strip().lower()
                dictionary[word] = {
                    'word': parts[0].strip(),
                    'reading': parts[1].strip(),
                    'meaning': parts[2].strip(),
                    'etymology': parts[3].strip(),
                    'relatedWords': parts[4].strip(),
                    'relatedFields': parts[5].strip(),
                    'difficulty': parts[6].strip()
                }
    return dictionary

def get_word_meaning(word, combined_dict):
    """è¾æ›¸ã‹ã‚‰å˜èªã®æ„å‘³ã‚’å–å¾—ï¼ˆåŸå½¢å¤‰æ›ã‚’å«ã‚€ï¼‰"""
    if not word or word in ['.', ',', '!', '?', ';', ':', '"', "'", '-']:
        return None
    
    word_lower = word.lower()
    
    # ã¾ãšå…ƒã®å½¢ã§è¾æ›¸ã‚’ç¢ºèª
    if word_lower in combined_dict:
        return combined_dict[word_lower].get('meaning', '')
    
    # åŸå½¢å¤‰æ›ã‚’è©¦ã¿ã‚‹
    # -s, -es ã®é™¤å»ï¼ˆè¤‡æ•°å½¢ï¼‰
    if word_lower.endswith('ies'):
        base = word_lower[:-3] + 'y'
        if base in combined_dict:
            return combined_dict[base].get('meaning', '') + "ï¼ˆè¤‡æ•°å½¢ï¼‰"
    
    if word_lower.endswith('es'):
        base = word_lower[:-2]
        if base in combined_dict:
            return combined_dict[base].get('meaning', '') + "ï¼ˆè¤‡æ•°å½¢ï¼‰"
        # try -es -> -e
        if base + 'e' in combined_dict:
            return combined_dict[base + 'e'].get('meaning', '') + "ï¼ˆè¤‡æ•°å½¢ï¼‰"
    
    if word_lower.endswith('s'):
        base = word_lower[:-1]
        if base in combined_dict:
            return combined_dict[base].get('meaning', '') + "ï¼ˆè¤‡æ•°å½¢ãƒ»ä¸‰å˜ç¾ï¼‰"
    
    # -ing ã®é™¤å»ï¼ˆç¾åœ¨åˆ†è©ãƒ»å‹•åè©ï¼‰
    if word_lower.endswith('ing'):
        base = word_lower[:-3]
        if base in combined_dict:
            return combined_dict[base].get('meaning', '') + "ï¼ˆã€œã™ã‚‹ã“ã¨ï¼‰"
        # å­éŸ³é‡è¤‡ãƒ‘ã‚¿ãƒ¼ãƒ³ (running -> run)
        if len(base) >= 2 and base[-1] == base[-2]:
            single_base = base[:-1]
            if single_base in combined_dict:
                return combined_dict[single_base].get('meaning', '') + "ï¼ˆã€œã™ã‚‹ã“ã¨ï¼‰"
        # e-drop ãƒ‘ã‚¿ãƒ¼ãƒ³ (making -> make)
        if base + 'e' in combined_dict:
            return combined_dict[base + 'e'].get('meaning', '') + "ï¼ˆã€œã™ã‚‹ã“ã¨ï¼‰"
    
    # -ed ã®é™¤å»ï¼ˆéå»å½¢ãƒ»éå»åˆ†è©ï¼‰
    if word_lower.endswith('ed'):
        base = word_lower[:-2]
        if base in combined_dict:
            return combined_dict[base].get('meaning', '') + "ï¼ˆéå»å½¢ï¼‰"
        # å­éŸ³é‡è¤‡ãƒ‘ã‚¿ãƒ¼ãƒ³ (stopped -> stop)
        if len(base) >= 2 and base[-1] == base[-2]:
            single_base = base[:-1]
            if single_base in combined_dict:
                return combined_dict[single_base].get('meaning', '') + "ï¼ˆéå»å½¢ï¼‰"
        # e-drop ãƒ‘ã‚¿ãƒ¼ãƒ³ (moved -> move)
        if base + 'e' in combined_dict:
            return combined_dict[base + 'e'].get('meaning', '') + "ï¼ˆéå»å½¢ï¼‰"
    
    # -er, -est ã®é™¤å»ï¼ˆæ¯”è¼ƒç´šãƒ»æœ€ä¸Šç´šï¼‰
    if word_lower.endswith('est'):
        base = word_lower[:-3]
        if base in combined_dict:
            return combined_dict[base].get('meaning', '') + "ï¼ˆæœ€ä¸Šç´šï¼‰"
        if base + 'e' in combined_dict:
            return combined_dict[base + 'e'].get('meaning', '') + "ï¼ˆæœ€ä¸Šç´šï¼‰"
        # y -> i ãƒ‘ã‚¿ãƒ¼ãƒ³ (happiest -> happy)
        if base + 'y' in combined_dict:
            return combined_dict[base + 'y'].get('meaning', '') + "ï¼ˆæœ€ä¸Šç´šï¼‰"
    
    if word_lower.endswith('er'):
        base = word_lower[:-2]
        if base in combined_dict:
            return combined_dict[base].get('meaning', '') + "ï¼ˆæ¯”è¼ƒç´šï¼‰"
        if base + 'e' in combined_dict:
            return combined_dict[base + 'e'].get('meaning', '') + "ï¼ˆæ¯”è¼ƒç´šï¼‰"
        # y -> i ãƒ‘ã‚¿ãƒ¼ãƒ³ (happier -> happy)
        if base + 'y' in combined_dict:
            return combined_dict[base + 'y'].get('meaning', '') + "ï¼ˆæ¯”è¼ƒç´šï¼‰"
    
    return None

def fix_segments_meanings():
    """segmentså†…ã®meaningãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è¾æ›¸ã‹ã‚‰è¨­å®š"""
    
    # ãƒ¡ã‚¤ãƒ³è¾æ›¸ã‚’èª­ã¿è¾¼ã‚€ï¼ˆCSVï¼‰
    main_dict_path = Path('public/data/junior-high-entrance-words.csv')
    print(f"\nğŸ“– ãƒ¡ã‚¤ãƒ³è¾æ›¸ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™: {main_dict_path}")
    main_dictionary = load_csv_dictionary(main_dict_path)
    print(f"  âœ“ {len(main_dictionary)}å˜èªã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    
    # é•·æ–‡èª­è§£è¾æ›¸ã‚’èª­ã¿è¾¼ã‚€ï¼ˆJSONï¼‰
    reading_dict_path = Path('public/data/reading-passages-dictionary.json')
    print(f"\nğŸ“– é•·æ–‡èª­è§£è¾æ›¸ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™: {reading_dict_path}")
    reading_dictionary = load_json(reading_dict_path)
    print(f"  âœ“ {len(reading_dictionary)}å˜èªã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    
    # è¾æ›¸ã‚’çµ±åˆï¼ˆé•·æ–‡è¾æ›¸ãŒå„ªå…ˆï¼‰
    combined_dict = {**main_dictionary}
    for word, data in reading_dictionary.items():
        combined_dict[word.lower()] = data
    
    print(f"\n  âœ“ çµ±åˆè¾æ›¸: {len(combined_dict)}å˜èª")
    
    # Comprehensive JSONã‚’èª­ã¿è¾¼ã‚€
    comp_path = Path('public/data/reading-passages-comprehensive.json')
    print(f"\nğŸ“„ Comprehensive JSONã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™: {comp_path}")
    passages = load_json(comp_path)
    
    updated_count = 0
    not_found = set()
    
    # å…¨ãƒ‘ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡¦ç†
    for passage in passages:
        passage_id = passage.get('id', 'unknown')
        
        for phrase in passage.get('phrases', []):
            phrase_id = phrase.get('id', 'unknown')
            segments = phrase.get('segments', [])
            
            for segment in segments:
                word = segment.get('word', '')
                current_meaning = segment.get('meaning', '')
                
                # ç¾åœ¨ã®æ„å‘³ãŒ"-"ã¾ãŸã¯ç©ºã®å ´åˆã®ã¿æ›´æ–°
                if current_meaning == "-" or not current_meaning:
                    new_meaning = get_word_meaning(word, combined_dict)
                    
                    if new_meaning:
                        segment['meaning'] = new_meaning
                        updated_count += 1
                    else:
                        # å¥èª­ç‚¹ä»¥å¤–ã§è¦‹ã¤ã‹ã‚‰ãªã„å˜èªã‚’è¨˜éŒ²
                        if word not in ['.', ',', '!', '?', ';', ':', '"', "'", '-', '(', ')']:
                            not_found.add(word)
    
    # ä¿å­˜
    if updated_count > 0:
        save_json(passages, comp_path)
        print(f"\nâœ… {updated_count}å€‹ã®segment meaningã‚’æ›´æ–°ã—ã¾ã—ãŸ")
    else:
        print(f"\nâœ“ æ›´æ–°ãŒå¿…è¦ãªsegmentã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
    
    if not_found:
        print(f"\nâš  ä»¥ä¸‹ã®{len(not_found)}å€‹ã®å˜èªãŒè¾æ›¸ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ:")
        for word in sorted(not_found)[:50]:  # æœ€åˆã®50å€‹ã®ã¿è¡¨ç¤º
            print(f"  - {word}")
        if len(not_found) > 50:
            print(f"  ... ä»–{len(not_found) - 50}å€‹")

def main():
    print("=" * 60)
    print("Segments Meaning ä¿®æ­£ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    print("=" * 60)
    
    fix_segments_meanings()
    
    print("\n" + "=" * 60)
    print("âœ… å®Œäº†ã—ã¾ã—ãŸ")
    print("=" * 60)

if __name__ == '__main__':
    main()
